#!/usr/bin/env python3
"""
Plex Season Organizer - Enhanced Three-Phase System

CODING STANDARD EXCEPTION DOCUMENTATION:
This script exceeds the project's ~600-line source component guideline (currently ~1100 lines)
due to comprehensive three-phase processing requirements as specified in Sprint 9.0:

1. Consolidation Phase: File discovery, sample detection, conflict analysis (~200 lines)
2. Organization Phase: Season directory creation, file movement (~150 lines)
3. Archive Phase: Sample archiving, manifest creation, rollback capability (~150 lines)
4. Configuration System: Multi-layer config with .env support (~100 lines)
5. Enhanced CLI: Phase control, sample detection, directory exclusion (~150 lines)
6. UI/Reporting: Tiered dry-run output, phase-specific progress (~100 lines)
7. Season Detection: 19 patterns with validation (~200 lines, inherited)
8. Core Infrastructure: File locking, utilities, main entry point (~150 lines)

The script maintains zero external dependencies while providing enterprise-grade features
including sample detection, conflict resolution, rollback capability, and tiered dry-run modes.
Breaking this into multiple files would require either abandoning the zero-dependency principle
or creating complex inter-module dependencies that would reduce maintainability and portability.

This exception is explicitly approved per Sprint 9.0 requirements for comprehensive three-phase
file management transformation where functionality and zero-setup deployment are paramount.

A Python tool for organizing TV show episodes into season-specific directories with advanced
three-phase processing: consolidation, organization, and optional archiving.

Features:
- Three-phase processing: consolidation → organization → archive
- Enhanced UI with progress bars and phase tracking (v3.2.0)
- Real-time progress indicators for long operations (v3.2.0)
- System trash cleanup (.DS_Store, Thumbs.db, etc.)
- Sample file detection with configurable size threshold
- Directory exclusion with pattern matching
- Enhanced conflict resolution
- Manifest-based rollback capability
- Tiered dry-run output (basic, detailed, comprehensive)
- 19 season detection patterns with validation
- File-based locking mechanism
- Progress tracking and detailed statistics
- Cron-friendly operation
- Global configuration via .env files

Author: Media Library Tools Project
Version: 3.2.0
"""

import argparse
import json
import os
import re
import shutil
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple, Union

VERSION = "3.2.0"

# ======================================================

# ======================================================
# INJECTED MODULE - START
# Generated by build.py v3.0.0
# Source: utils.py
# ======================================================

"""
Shared Utility Module for Media Library Tools

This module provides backward compatibility by re-exporting functions from the
new modular library structure. New development should use the lib/ modules directly.

DEPRECATED: This module is maintained for backward compatibility only.
New tools should use the modular lib/ structure:
- lib/core.py: Essential utilities (locking, config, platform detection)
- lib/ui.py: User interface functions (banners, formatting, confirmations)
- lib/filesystem.py: File operations
- lib/validation.py: Input validation and error handling

Author: Media Library Tools Project
Version: 1.0.0
"""

import sys
import warnings
from pathlib import Path

# Add lib directory to path for imports
lib_path = Path(__file__).parent / "lib"
if str(lib_path) not in sys.path:
    sys.path.insert(0, str(lib_path))

# Import all functions from modular libraries
try:
    from core import (
        ConfigCache,
        FileLock,
        acquire_lock,
        debug_config_resolution,
        get_config_source,
        is_non_interactive,
        is_windows,
        read_config_bool,
        read_config_value,
        read_global_config_bool,
        read_local_env_file,
        release_lock,
        should_use_emojis,
        validate_config_setup,
    )
    from filesystem import (
        get_directory_size,
        validate_directory_path,
    )
    from ui import (
        confirm_action,
        display_banner,
        format_size,
        format_status_message,
    )
    from validation import (
        validate_path_argument,
    )
except ImportError as e:
    # Fallback warning if lib modules are not available
    warnings.warn(
        f"Could not import from lib modules: {e}. Using legacy implementations.",
        DeprecationWarning,
        stacklevel=2,
    )

    # Keep legacy implementations as fallback
    import contextlib
    import os
    import platform
    import tempfile
    from typing import Optional, Tuple

    # Platform-specific imports
    try:
        import fcntl  # Unix/Linux/macOS
    except ImportError:
        fcntl = None  # Windows

    try:
        import msvcrt  # Windows
    except ImportError:
        msvcrt = None  # Unix/Linux/macOS

    # Legacy function implementations (fallback only)
    def display_banner(
        script_name: str,
        version: str,
        description: str,
        no_banner_flag: bool = False,
        quiet_mode: bool = False,
    ) -> None:
        """
        Display standardized banner for media library tools.

        Args:
            script_name: Name of the script
            version: Version string
            description: Brief description of the script
            no_banner_flag: If True, suppress banner display
            quiet_mode: If True, suppress banner display
        """
        # Check suppression conditions (highest to lowest priority)
        if no_banner_flag or quiet_mode or is_non_interactive():
            return

        try:
            # Display standardized ASCII art
            print("┏┳┓┏━╸╺┳┓╻┏━┓╻  ╻┏┓ ┏━┓┏━┓┏━┓╻ ╻╺┳╸┏━┓┏━┓╻  ┏━┓")
            print("┃┃┃┣╸  ┃┃┃┣━┫┃  ┃┣┻┓┣┳┛┣━┫┣┳┛┗┳┛ ┃ ┃ ┃┃ ┃┃  ┗━┓")
            print("╹ ╹┗━╸╺┻┛╹╹ ╹┗━╸╹┗━┛╹┗╸╹ ╹╹┗╸ ╹  ╹ ┗━┛┗━┛┗━╸┗━┛")
            print(f"{script_name} v{version}: {description}")
            print()  # Blank line for separation
        except Exception:
            # Banner display errors should not prevent script execution
            pass

    def is_non_interactive() -> bool:
        """
        Detect if running in non-interactive environment (cron, etc.).

        Returns:
            True if non-interactive, False otherwise
        """
        # Check if stdin is not a TTY (common in cron jobs)
        if not sys.stdin.isatty():
            return True

        # Check for common non-interactive environment variables
        non_interactive_vars = ["CRON", "CI", "AUTOMATED", "NON_INTERACTIVE"]
        for var in non_interactive_vars:
            if os.environ.get(var):
                return True

        # Check if TERM is not set or is 'dumb' (common in automated environments)
        term = os.environ.get("TERM", "")
        return bool(not term or term == "dumb")

    def read_global_config_bool(var_name: str, default: bool = False) -> bool:
        """
        Read a boolean environment variable with support for .env files.

        Args:
            var_name: Name of the environment variable
            default: Default value if not found

        Returns:
            Boolean value of the environment variable
        """
        # Check environment variable directly
        value = os.environ.get(var_name)
        if value is not None:
            return value.lower() in ("true", "1", "yes", "on")

        # Check local .env file
        env_file = ".env"
        if os.path.exists(env_file):
            try:
                with open(env_file) as f:
                    for line in f:
                        line = line.strip()
                        if line.startswith(f"{var_name}="):
                            value = line.split("=", 1)[1].strip()
                            return value.lower() in ("true", "1", "yes", "on")
            except OSError:
                pass

        # Check global .env file
        global_env_path = Path.home() / ".media-library-tools" / ".env"
        if global_env_path.exists():
            try:
                with open(global_env_path) as f:
                    for line in f:
                        line = line.strip()
                        if line.startswith(f"{var_name}="):
                            value = line.split("=", 1)[1].strip()
                            return value.lower() in ("true", "1", "yes", "on")
            except OSError:
                pass

        return default

    def is_windows() -> bool:
        """
        Detect if running on Windows platform.

        Returns:
            True if running on Windows, False otherwise
        """
        return platform.system().lower() == "windows"

    def should_use_emojis() -> bool:
        """
        Determine if emojis should be used based on platform and environment.

        Returns:
            True if emojis should be used, False otherwise
        """
        # Don't use emojis on Windows to avoid encoding issues
        if is_windows():
            return False

        # Don't use emojis in non-interactive environments
        if is_non_interactive():
            return False

        # Check for explicit emoji suppression
        return not read_global_config_bool("NO_EMOJIS", False)

    def format_size(size_bytes: int) -> str:
        """
        Format size in bytes to human readable format.

        Args:
            size_bytes: Size in bytes

        Returns:
            Human readable size string
        """
        for unit in ["B", "K", "M", "G", "T"]:
            if size_bytes < 1024.0:
                if unit == "B":
                    return f"{size_bytes:.0f}{unit}"
                else:
                    return f"{size_bytes:.1f}{unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.1f}P"

    def confirm_action(message: str, skip_confirmation: bool = False) -> bool:
        """
        Ask for user confirmation unless skipped.

        Args:
            message: Confirmation message to display
            skip_confirmation: If True, automatically confirm

        Returns:
            True if confirmed, False otherwise
        """
        if skip_confirmation:
            return True

        try:
            response = input(f"{message} (y/N): ").strip().lower()
            return response in ["y", "yes"]
        except (EOFError, KeyboardInterrupt):
            print("\nOperation cancelled.")
            return False

    class FileLock:
        """
        File locking utility class for preventing concurrent executions.
        """

        def __init__(self, lock_prefix: str = "media_library_tool"):
            """
            Initialize file lock.

            Args:
                lock_prefix: Prefix for lock file name
            """
            self.lock_prefix = lock_prefix
            self.lock_file = None

        def acquire_lock(self, force: bool = False) -> bool:
            """
            Acquire file lock to prevent multiple instances.

            Args:
                force: If True, skip locking mechanism

            Returns:
                True if lock acquired successfully, False otherwise
            """
            if force:
                return True

            try:
                with tempfile.NamedTemporaryFile(
                    mode="w",
                    prefix=f"{self.lock_prefix}_",
                    suffix=".lock",
                    delete=False,
                ) as temp_file:
                    self.lock_file = temp_file

                    # Platform-specific file locking
                    if fcntl is not None:  # Unix/Linux/macOS
                        fcntl.flock(
                            self.lock_file.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB
                        )
                    elif msvcrt is not None:  # Windows
                        msvcrt.locking(self.lock_file.fileno(), msvcrt.LK_NBLCK, 1)
                    else:
                        # Fallback: no locking available, just proceed
                        pass

                    self.lock_file.write(str(os.getpid()))
                    self.lock_file.flush()
                return True
            except OSError as e:
                if self.lock_file:
                    self.lock_file.close()
                    with contextlib.suppress(OSError):
                        os.unlink(self.lock_file.name)
                    self.lock_file = None
                print(
                    "Error: Another instance is already running. Use --force to override."
                )
                print(f"Lock error: {e}")
                return False

        def release_lock(self) -> None:
            """
            Release the file lock.
            """
            if self.lock_file:
                try:
                    # Only unlock if file is still open
                    if not self.lock_file.closed:
                        # Platform-specific file unlocking
                        if fcntl is not None:  # Unix/Linux/macOS
                            fcntl.flock(self.lock_file.fileno(), fcntl.LOCK_UN)
                        elif msvcrt is not None:  # Windows
                            msvcrt.locking(self.lock_file.fileno(), msvcrt.LK_UNLCK, 1)
                        # No explicit unlock needed for fallback case

                        self.lock_file.close()
                except (OSError, ValueError):
                    # Handle both file system errors and closed file errors
                    pass

                # Always try to remove lock file if it exists
                try:
                    if os.path.exists(self.lock_file.name):
                        os.unlink(self.lock_file.name)
                except OSError:
                    pass
                finally:
                    self.lock_file = None

    # Legacy standalone functions for backward compatibility
    def acquire_lock(
        lock_prefix: str = "media_library_tool", force: bool = False
    ) -> Tuple[bool, Optional[FileLock]]:
        """
        Legacy function for acquiring file locks.

        Args:
            lock_prefix: Prefix for lock file name
            force: If True, skip locking mechanism

        Returns:
            Tuple of (success: bool, lock_instance: FileLock or None)
        """
        lock = FileLock(lock_prefix)
        success = lock.acquire_lock(force)
        return success, lock if success else None

    def release_lock(lock_instance: FileLock) -> None:
        """
        Legacy function for releasing file locks.

        Args:
            lock_instance: FileLock instance to release
        """
        if lock_instance:
            lock_instance.release_lock()

    def format_status_message(
        message: str, emoji: str = "", fallback_prefix: str = ""
    ) -> str:
        """
        Format a status message with emoji on supported platforms or fallback text.

        Args:
            message: The main message text
            emoji: The emoji to use on supported platforms
            fallback_prefix: Text prefix to use instead of emoji on unsupported platforms

        Returns:
            Formatted message string
        """
        if should_use_emojis() and emoji:
            return f"{emoji} {message}"
        elif fallback_prefix:
            return f"{fallback_prefix}: {message}"
        else:
            return message

    # Add any missing functions that might be needed for backward compatibility
    def get_directory_size(path: str) -> int:
        """Legacy fallback for directory size calculation."""
        total_size = 0
        try:
            for dirpath, _dirnames, filenames in os.walk(path):
                for filename in filenames:
                    filepath = os.path.join(dirpath, filename)
                    try:
                        total_size += os.path.getsize(filepath)
                    except OSError:
                        continue
        except OSError:
            pass
        return total_size

    def validate_directory_path(path: str) -> Tuple[bool, str]:
        """Legacy fallback for directory path validation."""
        if not path:
            return False, "Path cannot be empty"

        path_obj = Path(path)

        if not path_obj.exists():
            return False, f"Path does not exist: {path}"

        if not path_obj.is_dir():
            return False, f"Path is not a directory: {path}"

        return True, ""

    def validate_path_argument(path: str) -> Tuple[bool, str]:
        """Legacy fallback for path argument validation."""
        return validate_directory_path(path)


# ======================================================
# INJECTED MODULE - END
# Source: utils.py
# ======================================================



# ======================================================

# ======================================================
# INJECTED MODULE - START
# Generated by build.py v3.0.0
# Source: lib/cleanup.py
# ======================================================

"""
System Trash File Cleanup Module

Centralized cleanup utilities for removing system-generated trash files
that commonly cause issues with media library tools, especially files
transferred via rsync or network shares.

Common Issues Solved:
- .DS_Store files from macOS causing directory conflicts
- Thumbs.db files from Windows
- ._ AppleDouble files from macOS resource forks
- Desktop.ini files from Windows
- Other hidden system files

Author: Media Library Tools Project
Version: 1.0.0
"""

import os
from pathlib import Path
from typing import List, Optional, Set


class SystemTrashCleaner:
    """
    Handles detection and removal of system-generated trash files.

    These files are commonly created by operating systems and can cause
    conflicts during media library operations, especially after rsync
    transfers or network share access.
    """

    # System trash file patterns
    TRASH_FILES = {
        '.DS_Store',        # macOS Finder metadata
        'Thumbs.db',        # Windows thumbnail cache
        'Desktop.ini',      # Windows folder settings
        '.Spotlight-V100',  # macOS Spotlight index
        '.Trashes',         # macOS trash folder
        '.fseventsd',       # macOS file system events
        '.TemporaryItems',  # macOS temporary items
        '.localized',       # macOS localization
        'desktop.ini',      # Windows (lowercase variant)
        'thumbs.db',        # Windows (lowercase variant)
    }

    # Patterns for prefixed trash files
    TRASH_PREFIXES = {
        '._',               # macOS AppleDouble resource fork files
        '.~',               # Temporary/backup files
    }

    # Patterns for suffixed trash files
    TRASH_SUFFIXES = {
        '.tmp',             # Temporary files
        '.temp',            # Temporary files (variant)
        '~',                # Backup files
    }

    def __init__(self, verbose: bool = False, dry_run: bool = False):
        """
        Initialize the trash cleaner.

        Args:
            verbose: Enable verbose output
            dry_run: Preview mode - don't actually delete files
        """
        self.verbose = verbose
        self.dry_run = dry_run
        self.removed_files: List[Path] = []
        self.failed_removals: List[tuple] = []

    def is_trash_file(self, file_path: Path) -> bool:
        """
        Determine if a file is system trash.

        Args:
            file_path: Path to check

        Returns:
            True if file matches trash patterns
        """
        filename = file_path.name

        # Check exact matches
        if filename in self.TRASH_FILES:
            return True

        # Check prefixes
        for prefix in self.TRASH_PREFIXES:
            if filename.startswith(prefix):
                return True

        # Check suffixes
        for suffix in self.TRASH_SUFFIXES:
            if filename.endswith(suffix):
                return True

        return False

    def clean_directory(self, directory: Path, recursive: bool = False) -> int:
        """
        Clean trash files from a directory.

        Args:
            directory: Directory to clean
            recursive: Also clean subdirectories

        Returns:
            Number of files removed
        """
        if not directory.exists() or not directory.is_dir():
            if self.verbose:
                print(f"Directory does not exist or is not a directory: {directory}")
            return 0

        removed_count = 0

        try:
            if recursive:
                # Walk entire directory tree
                for root, dirs, files in os.walk(directory):
                    root_path = Path(root)

                    # Clean files in this directory
                    for filename in files:
                        file_path = root_path / filename
                        if self.is_trash_file(file_path):
                            if self._remove_file(file_path):
                                removed_count += 1

                    # Clean trash directories
                    for dirname in dirs[:]:  # Copy list to allow modification
                        dir_path = root_path / dirname
                        if dirname in self.TRASH_FILES:
                            if self._remove_directory(dir_path):
                                removed_count += 1
                                dirs.remove(dirname)  # Don't descend into removed dir
            else:
                # Only clean current directory
                for item in directory.iterdir():
                    if item.is_file() and self.is_trash_file(item):
                        if self._remove_file(item):
                            removed_count += 1
                    elif item.is_dir() and item.name in self.TRASH_FILES:
                        if self._remove_directory(item):
                            removed_count += 1

        except PermissionError as e:
            if self.verbose:
                print(f"Permission denied accessing {directory}: {e}")
        except Exception as e:
            if self.verbose:
                print(f"Error cleaning {directory}: {e}")

        return removed_count

    def _remove_file(self, file_path: Path) -> bool:
        """
        Remove a single trash file.

        Args:
            file_path: File to remove

        Returns:
            True if removed successfully
        """
        if self.dry_run:
            if self.verbose:
                print(f"[DRY RUN] Would remove: {file_path}")
            self.removed_files.append(file_path)
            return True

        try:
            os.remove(file_path)
            self.removed_files.append(file_path)
            if self.verbose:
                print(f"Removed: {file_path}")
            return True
        except OSError as e:
            self.failed_removals.append((file_path, str(e)))
            if self.verbose:
                print(f"Error removing {file_path}: {e}")
            return False

    def _remove_directory(self, dir_path: Path) -> bool:
        """
        Remove a trash directory.

        Args:
            dir_path: Directory to remove

        Returns:
            True if removed successfully
        """
        if self.dry_run:
            if self.verbose:
                print(f"[DRY RUN] Would remove directory: {dir_path}")
            self.removed_files.append(dir_path)
            return True

        try:
            import shutil
            shutil.rmtree(dir_path)
            self.removed_files.append(dir_path)
            if self.verbose:
                print(f"Removed directory: {dir_path}")
            return True
        except OSError as e:
            self.failed_removals.append((dir_path, str(e)))
            if self.verbose:
                print(f"Error removing directory {dir_path}: {e}")
            return False

    def get_stats(self) -> dict:
        """
        Get cleanup statistics.

        Returns:
            Dictionary with cleanup stats
        """
        return {
            'files_removed': len(self.removed_files),
            'failed_removals': len(self.failed_removals),
            'removed_list': [str(p) for p in self.removed_files],
            'failed_list': [(str(p), e) for p, e in self.failed_removals]
        }

    def print_summary(self) -> None:
        """Print cleanup summary."""
        stats = self.get_stats()

        if self.dry_run:
            print(f"\n[DRY RUN] Would remove {stats['files_removed']} trash files")
        else:
            print(f"\nRemoved {stats['files_removed']} trash files")

        if stats['failed_removals'] > 0:
            print(f"Failed to remove {stats['failed_removals']} files")
            if self.verbose:
                print("\nFailed removals:")
                for path, error in stats['failed_list']:
                    print(f"  {path}: {error}")


def quick_clean(directory: Path, recursive: bool = False,
                verbose: bool = False, dry_run: bool = False) -> int:
    """
    Quick cleanup function for simple use cases.

    Args:
        directory: Directory to clean
        recursive: Clean subdirectories
        verbose: Show detailed output
        dry_run: Preview mode

    Returns:
        Number of files removed

    Example:
        >>> from pathlib import Path
        >>> import lib.cleanup as cleanup
        >>> removed = cleanup.quick_clean(Path('.'), recursive=True, verbose=True)
    """
    cleaner = SystemTrashCleaner(verbose=verbose, dry_run=dry_run)
    count = cleaner.clean_directory(directory, recursive=recursive)

    if verbose:
        cleaner.print_summary()

    return count



# ======================================================
# INJECTED MODULE - END
# Source: lib/cleanup.py
# ======================================================



# ======================================================

# ======================================================
# INJECTED MODULE - START
# Generated by build.py v3.0.0
# Source: lib/ui.py
# ======================================================

"""
User Interface Module for Media Library Tools
Version: 1.0

This module contains user interface functions including:
- Banner display and application branding
- Size formatting for human-readable output  
- User confirmation prompts

This is part of the modular library structure that enables selective inclusion
in built tools while maintaining the self-contained principle.
"""

import sys
import time
import shutil
import os
from pathlib import Path
from typing import Optional, List, Dict, Set, Callable, Any
from dataclasses import dataclass

# Import dependencies from core module
try:
    from core import is_non_interactive, should_use_emojis
except ImportError:
    # Fallback for when core module is not available
    # This happens when modules are injected together during build
    def is_non_interactive():
        """Fallback implementation - will be overridden by injected core module"""
        return not sys.stdin.isatty()
    
    def should_use_emojis():
        """Fallback implementation - will be overridden by injected core module"""
        return sys.platform != "win32" and not is_non_interactive()


def display_banner(
    script_name: str,
    version: str,
    description: str,
    no_banner_flag: bool = False,
    quiet_mode: bool = False,
) -> None:
    """
    Display standardized banner for media library tools.

    Args:
        script_name: Name of the script
        version: Version string
        description: Brief description of the script
        no_banner_flag: If True, suppress banner display
        quiet_mode: If True, suppress banner display
    """
    # Check suppression conditions (highest to lowest priority)
    if no_banner_flag or quiet_mode or is_non_interactive():
        return

    try:
        # Display standardized ASCII art
        print("┏┳┓┏━╸╺┳┓╻┏━┓╻  ╻┏┓ ┏━┓┏━┓┏━┓╻ ╻╺┳╸┏━┓┏━┓╻  ┏━┓")
        print("┃┃┃┣╸  ┃┃┃┣━┫┃  ┃┣┻┓┣┳┛┣━┫┣┳┛┗┳┛ ┃ ┃ ┃┃ ┃┃  ┗━┓")
        print("╹ ╹┗━╸╺┻┛╹╹ ╹┗━╸╹┗━┛╹┗╸╹ ╹╹┗╸ ╹  ╹ ┗━┛┗━┛┗━╸┗━┛")
        print(f"{script_name} v{version}: {description}")
        print()  # Blank line for separation
    except Exception:
        # Banner display errors should not prevent script execution
        pass


def format_size(size_bytes: int) -> str:
    """
    Format size in bytes to human readable format.

    Args:
        size_bytes: Size in bytes

    Returns:
        Human readable size string
    """
    for unit in ["B", "K", "M", "G", "T"]:
        if size_bytes < 1024.0:
            if unit == "B":
                return f"{size_bytes:.0f}{unit}"
            else:
                return f"{size_bytes:.1f}{unit}"
        size_bytes /= 1024.0
    return f"{size_bytes:.1f}P"


def confirm_action(message: str, skip_confirmation: bool = False) -> bool:
    """
    Ask for user confirmation unless skipped.

    Args:
        message: Confirmation message to display
        skip_confirmation: If True, automatically confirm

    Returns:
        True if confirmed, False otherwise
    """
    if skip_confirmation:
        return True

    try:
        response = input(f"{message} (y/N): ").strip().lower()
        return response in ["y", "yes"]
    except (EOFError, KeyboardInterrupt):
        print("\nOperation cancelled.")
        return False


def format_status_message(
    message: str, emoji: str = "", fallback_prefix: str = ""
) -> str:
    """
    Format a status message with optional emoji or fallback prefix.

    Args:
        message: The message to format
        emoji: Emoji to use if emojis are supported
        fallback_prefix: Text prefix to use if emojis are not supported

    Returns:
        Formatted message string
    """
    if emoji and should_use_emojis():
        return f"{emoji} {message}"
    elif fallback_prefix:
        return f"{fallback_prefix}: {message}"
    else:
        return message


def display_item_list(items, title: str = None, numbered: bool = False, 
                     show_count: bool = True, indent: str = "  ") -> None:
    """
    Display a list of items with consistent formatting.
    
    Args:
        items: List of items to display (strings or objects with __str__)
        title: Optional title to display above the list
        numbered: Whether to number the items (default: False for bullet points)
        show_count: Whether to show total count in title (default: True)
        indent: Indentation string for list items (default: "  ")
    
    Example:
        display_item_list(['file1.mp4', 'file2.mkv'], 'Files to process', numbered=True)
        # Output:
        # Files to process (2):
        #   1. file1.mp4
        #   2. file2.mkv
    """
    if not items:
        if title:
            print(f"{title}: None found")
        return
    
    # Display title with optional count
    if title:
        count_text = f" ({len(items)})" if show_count else ""
        print(f"{title}{count_text}:")
    
    # Display items
    for i, item in enumerate(items, 1):
        if numbered:
            print(f"{indent}{i}. {item}")
        else:
            print(f"{indent}- {item}")


def display_summary_list(summary_data: dict, title: str = None) -> None:
    """
    Display a summary with categorized counts and totals.
    
    Args:
        summary_data: Dictionary with category names as keys and counts as values
        title: Optional title to display above the summary
    
    Example:
        display_summary_list({
            'Files processed': 15,
            'Files skipped': 3,
            'Errors encountered': 1
        }, 'Processing Summary')
        # Output:
        # Processing Summary:
        #   Files processed: 15
        #   Files skipped: 3
        #   Errors encountered: 1
    """
    if title:
        print(f"{title}:")
    
    # Find the longest key for alignment
    max_key_length = max(len(str(key)) for key in summary_data.keys()) if summary_data else 0
    
    for key, value in summary_data.items():
        print(f"  {str(key).ljust(max_key_length)}: {value}")


def display_progress_item(current: int, total: int, item_name: str, 
                         prefix: str = "Processing") -> None:
    """
    Display current progress for an item being processed.
    
    Args:
        current: Current item number (1-based)
        total: Total number of items
        item_name: Name of the current item being processed
        prefix: Prefix text (default: "Processing")
    
    Example:
        display_progress_item(3, 10, 'movie.mp4')
        # Output: [3/10] Processing: movie.mp4
    """
    print(f"[{current}/{total}] {prefix}: {item_name}")


def display_stats_table(stats: dict, title: str = None, 
                       value_formatter=None) -> None:
    """
    Display statistics in a formatted table with aligned columns.
    
    Args:
        stats: Dictionary with statistic names as keys and values
        title: Optional title to display above the table
        value_formatter: Optional function to format values (e.g., format_size for bytes)
    
    Example:
        display_stats_table({
            'Total files': 1250,
            'Total size': 15728640,
            'Average size': 12582
        }, 'File Statistics', format_size)
    """
    if not stats:
        return
    
    if title:
        print(f"\n{title}:")
    
    # Find the longest key for alignment
    max_key_length = max(len(str(key)) for key in stats.keys())
    
    for key, value in stats.items():
        formatted_value = value_formatter(value) if value_formatter else str(value)
        print(f"  {str(key).ljust(max_key_length)}: {formatted_value}")


@dataclass
class ColumnConfig:
    """
    Configuration for table column rendering.

    Attributes:
        align: Column alignment ('left', 'right', 'center')
        formatter: Optional function to format cell values
        max_width: Maximum width for this column (None for auto)
    """
    align: str = 'left'
    formatter: Optional[Callable[[Any], str]] = None
    max_width: Optional[int] = None


def display_results_table(data: list, headers: list, title: str = None,
                         max_width: int = 80, column_config: Optional[List[ColumnConfig]] = None,
                         sort_by: Optional[int] = None, reverse: bool = False,
                         show_totals: bool = False, border_style: str = 'ascii') -> None:
    """
    Display structured data in a formatted table with advanced configuration.

    Features:
    - Column alignment control (left, right, center)
    - Automatic width calculation based on content
    - Row sorting by column
    - Column-specific formatters (size, date, percentage)
    - Footer rows for totals/summaries
    - Maximum width enforcement with truncation
    - Border style options (ASCII, Unicode, minimal)

    Args:
        data: List of lists/tuples containing row data
        headers: List of column headers
        title: Optional title to display above the table
        max_width: Maximum width for the table (default: 80)
        column_config: Optional list of ColumnConfig objects for each column
        sort_by: Optional column index to sort by
        reverse: Reverse sort order (default: False)
        show_totals: Show totals row for numeric columns (default: False)
        border_style: Border style ('ascii', 'unicode', 'minimal')

    Example:
        from lib.ui import display_results_table, ColumnConfig

        display_results_table([
            ['file1.mp4', 1234567890, 'Processed'],
            ['file2.mkv', 987654321, 'Skipped']
        ], ['Filename', 'Size', 'Status'],
        column_config=[
            ColumnConfig(align='left'),
            ColumnConfig(align='right', formatter=format_size),
            ColumnConfig(align='center')
        ],
        sort_by=1, reverse=True, border_style='unicode')
    """
    if not data or not headers:
        if title:
            print(f"{title}: No data to display")
        return

    # Default column config if not provided
    if column_config is None:
        column_config = [ColumnConfig() for _ in headers]
    elif len(column_config) < len(headers):
        # Extend with defaults if needed
        column_config = list(column_config) + [ColumnConfig() for _ in range(len(headers) - len(column_config))]

    # Sort data if requested
    if sort_by is not None and 0 <= sort_by < len(headers):
        data = sorted(data, key=lambda row: row[sort_by] if sort_by < len(row) else '', reverse=reverse)

    # Apply formatters to data
    formatted_data = []
    for row in data:
        formatted_row = []
        for i, cell in enumerate(row):
            if i < len(column_config) and column_config[i].formatter:
                formatted_row.append(column_config[i].formatter(cell))
            else:
                formatted_row.append(str(cell))
        formatted_data.append(formatted_row)

    # Calculate column widths
    col_widths = []
    for i, header in enumerate(headers):
        # Start with header width
        max_col_width = len(header)

        # Check data column widths
        for row in formatted_data:
            if i < len(row):
                max_col_width = max(max_col_width, len(row[i]))

        # Apply column-specific max width if set
        if i < len(column_config) and column_config[i].max_width:
            max_col_width = min(max_col_width, column_config[i].max_width)
        else:
            # Apply global max width
            max_col_width = min(max_col_width, max_width // len(headers))

        col_widths.append(max_col_width)

    # Choose border characters
    if border_style == 'unicode':
        sep = " │ "
        top_left, top_mid, top_right = "┌", "┬", "┐"
        mid_left, mid_mid, mid_right = "├", "┼", "┤"
        bot_left, bot_mid, bot_right = "└", "┴", "┘"
        horiz = "─"
    elif border_style == 'minimal':
        sep = "  "
        top_left = top_mid = top_right = ""
        mid_left = mid_mid = mid_right = ""
        bot_left = bot_mid = bot_right = ""
        horiz = " "
    else:  # ascii
        sep = " | "
        top_left = top_mid = top_right = ""
        mid_left = mid_mid = mid_right = ""
        bot_left = bot_mid = bot_right = ""
        horiz = "-"

    def align_cell(cell: str, width: int, alignment: str) -> str:
        """Align cell content according to specified alignment."""
        if len(cell) > width:
            cell = cell[:width-3] + "..."
        if alignment == 'right':
            return cell.rjust(width)
        elif alignment == 'center':
            return cell.center(width)
        else:  # left
            return cell.ljust(width)

    # Display title
    if title:
        print(f"\n{title}:")

    # Build and print header
    header_cells = []
    for i, header in enumerate(headers):
        alignment = column_config[i].align if i < len(column_config) else 'left'
        header_cells.append(align_cell(header, col_widths[i], alignment))

    header_row = "  " + sep.join(header_cells)
    print(header_row)

    # Print separator
    if border_style == 'unicode':
        separator = "  " + mid_left + horiz * col_widths[0]
        for i in range(1, len(col_widths)):
            separator += mid_mid + horiz * col_widths[i]
        separator += mid_right
        print(separator)
    else:
        print("  " + horiz * (len(header_row) - 2))

    # Print data rows
    for row in formatted_data:
        row_cells = []
        for i in range(len(headers)):
            cell = row[i] if i < len(row) else ""
            alignment = column_config[i].align if i < len(column_config) else 'left'
            row_cells.append(align_cell(cell, col_widths[i], alignment))

        print("  " + sep.join(row_cells))

    # Show totals if requested
    if show_totals and data:
        # Calculate totals for numeric columns
        totals = []
        has_total = False
        for i in range(len(headers)):
            try:
                # Try to sum numeric values from original data (before formatting)
                col_values = [row[i] for row in data if i < len(row) and isinstance(row[i], (int, float))]
                if col_values:
                    total = sum(col_values)
                    # Apply formatter if available
                    if i < len(column_config) and column_config[i].formatter:
                        totals.append(column_config[i].formatter(total))
                    else:
                        totals.append(str(total))
                    has_total = True
                else:
                    totals.append("")
            except (TypeError, ValueError):
                totals.append("")

        if has_total:
            # Print separator before totals
            if border_style != 'minimal':
                print("  " + horiz * (len(header_row) - 2))

            # Print totals row
            total_cells = []
            for i in range(len(headers)):
                if i == 0 and not totals[0]:
                    cell = "TOTAL"
                else:
                    cell = totals[i] if i < len(totals) else ""
                alignment = column_config[i].align if i < len(column_config) else 'left'
                total_cells.append(align_cell(cell, col_widths[i], alignment))

            print("  " + sep.join(total_cells))

    print()  # Blank line after table


class ProgressBar:
    """
    Real-time progress bar with ETA calculation and rate display.

    Features:
    - Configurable width and style
    - ETA calculation based on current rate
    - Dynamic updates without line spam
    - Rate display (items/sec, MB/sec)
    - Memory-efficient for large operations
    - TTY detection with fallback for non-interactive environments

    Usage:
        with ProgressBar(total=1000, desc="Processing files") as pb:
            for item in items:
                process_item(item)
                pb.update(1)
    """

    def __init__(self, total: int, desc: str = "", width: int = 50,
                 unit: str = "items", show_rate: bool = True):
        """
        Initialize progress bar.

        Args:
            total: Total number of items to process
            desc: Description to display before progress bar
            width: Width of progress bar in characters (default: 50)
            unit: Unit name for rate display (default: "items")
            show_rate: Whether to show processing rate (default: True)
        """
        self.total = total
        self.desc = desc
        self.width = width
        self.unit = unit
        self.show_rate = show_rate
        self.current = 0
        self.start_time = time.time()
        self.last_update_time = self.start_time
        self.last_print_length = 0
        self.is_tty = sys.stdout.isatty() and not is_non_interactive()
        self.update_interval = 0.1  # Update display every 0.1 seconds minimum
        self.completed = False

    def update(self, increment: int = 1) -> None:
        """
        Update progress by specified increment.

        Args:
            increment: Number of items to add to progress (default: 1)
        """
        self.current = min(self.current + increment, self.total)
        current_time = time.time()

        # Only update display if enough time has passed or we're complete
        if (current_time - self.last_update_time >= self.update_interval or
            self.current >= self.total):
            self._display()
            self.last_update_time = current_time

    def _display(self) -> None:
        """Display current progress state."""
        if self.total == 0:
            return

        # Calculate metrics
        elapsed = time.time() - self.start_time
        percentage = (self.current / self.total) * 100

        # Build progress bar
        if self.is_tty:
            filled = int(self.width * self.current / self.total)
            bar = "█" * filled + "░" * (self.width - filled)

            # Calculate ETA
            if self.current > 0 and elapsed > 0:
                rate = self.current / elapsed
                remaining = self.total - self.current
                eta_seconds = remaining / rate if rate > 0 else 0
                eta_str = self._format_time(eta_seconds)

                # Build status line
                status_parts = [
                    f"{self.desc}: " if self.desc else "",
                    f"[{bar}] ",
                    f"{self.current}/{self.total} ",
                    f"({percentage:.1f}%)"
                ]

                if self.show_rate and rate > 0:
                    status_parts.append(f" - {rate:.1f} {self.unit}/sec")

                if self.current < self.total:
                    status_parts.append(f" - ETA: {eta_str}")
                else:
                    status_parts.append(" - Complete")

                status = "".join(status_parts)
            else:
                status = f"{self.desc}: [{bar}] {self.current}/{self.total} ({percentage:.1f}%)"

            # Clear previous line and print new status
            print(f"\r{' ' * self.last_print_length}\r{status}", end="", flush=True)
            self.last_print_length = len(status)

            # Print newline when complete
            if self.current >= self.total and not self.completed:
                print()
                self.completed = True
        else:
            # Non-TTY mode: only print at milestones (0%, 25%, 50%, 75%, 100%)
            milestones = [0, 25, 50, 75, 100]
            current_milestone = int(percentage / 25) * 25

            if not hasattr(self, '_last_milestone'):
                self._last_milestone = -1

            if current_milestone > self._last_milestone and current_milestone in milestones:
                prefix = f"{self.desc}: " if self.desc else ""
                print(f"{prefix}Progress: {self.current}/{self.total} ({percentage:.1f}%)")
                self._last_milestone = current_milestone

    def _format_time(self, seconds: float) -> str:
        """
        Format seconds into human-readable time string.

        Args:
            seconds: Time in seconds

        Returns:
            Formatted time string (e.g., "2m 30s")
        """
        if seconds < 60:
            return f"{int(seconds)}s"
        elif seconds < 3600:
            minutes = int(seconds / 60)
            secs = int(seconds % 60)
            return f"{minutes}m {secs}s"
        else:
            hours = int(seconds / 3600)
            minutes = int((seconds % 3600) / 60)
            return f"{hours}h {minutes}m"

    def __enter__(self):
        """Context manager entry."""
        return self

    def __exit__(self, *args):
        """Context manager exit - ensure final display."""
        if not self.completed:
            self.current = self.total
            self._display()
            if self.is_tty:
                print()


class PhaseProgressTracker:
    """
    Multi-phase operation tracking with individual progress bars.

    Features:
    - Track multiple named phases (e.g., Consolidation, Organization, Archive)
    - Per-phase progress with individual progress bars
    - Overall completion percentage
    - Phase timing and duration display
    - Phase status tracking (pending, in-progress, completed, failed)

    Usage:
        tracker = PhaseProgressTracker([
            "Phase 1: Consolidation",
            "Phase 2: Organization",
            "Phase 3: Archive"
        ])

        tracker.start_phase(0, total_items=500)
        # ... process items ...
        tracker.update_phase(0, increment=1)
        tracker.complete_phase(0)

        tracker.display_summary()
    """

    def __init__(self, phase_names: List[str]):
        """
        Initialize phase progress tracker.

        Args:
            phase_names: List of phase names in order
        """
        self.phase_names = phase_names
        self.phases: Dict[int, Dict] = {}
        self.current_phase_index: Optional[int] = None
        self.is_tty = sys.stdout.isatty() and not is_non_interactive()

        # Initialize phase data
        for i in range(len(phase_names)):
            self.phases[i] = {
                'name': phase_names[i],
                'status': 'pending',  # pending, in-progress, completed, failed
                'total': 0,
                'current': 0,
                'start_time': None,
                'end_time': None,
                'progress_bar': None
            }

    def start_phase(self, phase_index: int, total_items: int = 0) -> None:
        """
        Start a specific phase.

        Args:
            phase_index: Index of the phase to start (0-based)
            total_items: Total number of items for this phase
        """
        if phase_index not in self.phases:
            return

        self.current_phase_index = phase_index
        phase = self.phases[phase_index]
        phase['status'] = 'in-progress'
        phase['total'] = total_items
        phase['current'] = 0
        phase['start_time'] = time.time()

        # Display phase start
        print(f"\n{phase['name']}")
        if total_items > 0:
            phase['progress_bar'] = ProgressBar(
                total=total_items,
                desc="  Progress",
                width=40,
                unit="items"
            )

    def update_phase(self, phase_index: int, increment: int = 1) -> None:
        """
        Update progress for a specific phase.

        Args:
            phase_index: Index of the phase to update
            increment: Number of items to add to progress
        """
        if phase_index not in self.phases:
            return

        phase = self.phases[phase_index]
        if phase['status'] != 'in-progress':
            return

        phase['current'] = min(phase['current'] + increment, phase['total'])

        if phase['progress_bar']:
            phase['progress_bar'].update(increment)

    def complete_phase(self, phase_index: int, status: str = 'completed') -> None:
        """
        Mark a phase as complete.

        Args:
            phase_index: Index of the phase to complete
            status: Final status ('completed' or 'failed')
        """
        if phase_index not in self.phases:
            return

        phase = self.phases[phase_index]
        phase['status'] = status
        phase['end_time'] = time.time()

        # Ensure progress bar is complete
        if phase['progress_bar'] and phase['current'] < phase['total']:
            phase['progress_bar'].current = phase['total']
            phase['progress_bar']._display()
            if phase['progress_bar'].is_tty:
                print()

        # Display phase completion
        if phase['start_time']:
            duration = phase['end_time'] - phase['start_time']
            duration_str = self._format_duration(duration)
            status_text = "Complete" if status == 'completed' else "FAILED"
            print(f"  {status_text} - Duration: {duration_str}\n")

    def fail_phase(self, phase_index: int, error_message: str = "") -> None:
        """
        Mark a phase as failed.

        Args:
            phase_index: Index of the phase that failed
            error_message: Optional error message to display
        """
        if error_message:
            print(f"  Error: {error_message}")
        self.complete_phase(phase_index, status='failed')

    def display_summary(self) -> None:
        """Display summary of all phases."""
        print("\n" + "=" * 60)
        print("PHASE SUMMARY")
        print("=" * 60)

        total_duration = 0
        for i in range(len(self.phase_names)):
            phase = self.phases[i]
            status_symbol = {
                'pending': '[ ]',
                'in-progress': '[~]',
                'completed': '[✓]' if not is_non_interactive() else '[x]',
                'failed': '[✗]' if not is_non_interactive() else '[!]'
            }.get(phase['status'], '[ ]')

            duration_str = ""
            if phase['start_time'] and phase['end_time']:
                duration = phase['end_time'] - phase['start_time']
                duration_str = f" - {self._format_duration(duration)}"
                total_duration += duration

            progress_str = ""
            if phase['total'] > 0:
                progress_str = f" ({phase['current']}/{phase['total']} items)"

            print(f"{status_symbol} {phase['name']}{progress_str}{duration_str}")

        if total_duration > 0:
            print(f"\nTotal Duration: {self._format_duration(total_duration)}")
        print("=" * 60 + "\n")

    def get_overall_progress(self) -> float:
        """
        Get overall progress percentage across all phases.

        Returns:
            Overall progress percentage (0-100)
        """
        completed_phases = sum(1 for p in self.phases.values() if p['status'] == 'completed')
        return (completed_phases / len(self.phase_names)) * 100 if self.phase_names else 0

    def _format_duration(self, seconds: float) -> str:
        """
        Format duration in seconds to human-readable string.

        Args:
            seconds: Duration in seconds

        Returns:
            Formatted duration string
        """
        if seconds < 1:
            return f"{int(seconds * 1000)}ms"
        elif seconds < 60:
            return f"{seconds:.1f}s"
        elif seconds < 3600:
            minutes = int(seconds / 60)
            secs = int(seconds % 60)
            return f"{minutes}m {secs}s"
        else:
            hours = int(seconds / 3600)
            minutes = int((seconds % 3600) / 60)
            return f"{hours}h {minutes}m"


def display_directory_tree(root_path: str, max_depth: int = 3,
                          show_sizes: bool = True,
                          highlight_patterns: Optional[List[str]] = None,
                          use_unicode: Optional[bool] = None) -> None:
    """
    Display directory structure as a tree with optional size information.

    Features:
    - Configurable depth limit
    - File size display
    - Path highlighting for specific patterns
    - Unicode or ASCII symbols
    - Efficient traversal with depth limiting

    Args:
        root_path: Root directory to visualize
        max_depth: Maximum depth to traverse (default: 3)
        show_sizes: Whether to show file/directory sizes (default: True)
        highlight_patterns: List of patterns to highlight (e.g., ["Season *"])
        use_unicode: Use Unicode symbols (default: auto-detect based on platform)

    Example:
        display_directory_tree("/media/TV Shows/Show Name", max_depth=3,
                             highlight_patterns=["Season *"])
    """
    root = Path(root_path)
    if not root.exists():
        print(f"Error: Path does not exist: {root_path}")
        return

    # Auto-detect unicode support
    if use_unicode is None:
        use_unicode = sys.platform != "win32" and not is_non_interactive()

    # Tree symbols
    if use_unicode:
        PIPE = "│   "
        TEE = "├── "
        ELBOW = "└── "
        BLANK = "    "
    else:
        PIPE = "|   "
        TEE = "|-- "
        ELBOW = "`-- "
        BLANK = "    "

    # Compile highlight patterns if provided
    highlight_set: Set[str] = set()
    if highlight_patterns:
        for pattern in highlight_patterns:
            highlight_set.add(pattern.lower())

    # Track statistics
    total_size = 0
    file_count = 0
    dir_count = 0

    def should_highlight(path: Path) -> bool:
        """Check if path matches any highlight patterns."""
        if not highlight_patterns:
            return False
        path_str = path.name.lower()
        for pattern in highlight_patterns:
            pattern_lower = pattern.lower().replace("*", "")
            if pattern_lower in path_str:
                return True
        return False

    def get_size(path: Path) -> int:
        """Get size of file or directory."""
        try:
            if path.is_file():
                return path.stat().st_size
            elif path.is_dir():
                # For directories, sum all file sizes
                total = 0
                try:
                    for item in path.rglob('*'):
                        if item.is_file():
                            try:
                                total += item.stat().st_size
                            except (OSError, PermissionError):
                                pass
                except (OSError, PermissionError):
                    pass
                return total
        except (OSError, PermissionError):
            return 0
        return 0

    def format_entry(path: Path, is_last: bool, prefix: str, depth: int) -> str:
        """Format a single tree entry."""
        nonlocal total_size, file_count, dir_count

        # Choose connector
        connector = ELBOW if is_last else TEE

        # Get name and size
        name = path.name
        if path.is_dir():
            name += "/"
            dir_count += 1
        else:
            file_count += 1

        # Check for highlighting
        highlighted = should_highlight(path)
        if highlighted and use_unicode:
            name = f"→ {name}"

        # Add size if requested
        size_str = ""
        if show_sizes:
            size = get_size(path)
            total_size += size
            if size > 0:
                size_str = f" ({format_size(size)})"

        return f"{prefix}{connector}{name}{size_str}"

    def walk_tree(path: Path, prefix: str = "", depth: int = 0):
        """Recursively walk directory tree."""
        if depth > max_depth:
            return

        try:
            entries = sorted(path.iterdir(), key=lambda p: (not p.is_dir(), p.name.lower()))
        except PermissionError:
            print(f"{prefix}{TEE}[Permission Denied]")
            return
        except OSError as e:
            print(f"{prefix}{TEE}[Error: {e}]")
            return

        # Filter out hidden files for cleaner display
        entries = [e for e in entries if not e.name.startswith('.')]

        for i, entry in enumerate(entries):
            is_last = (i == len(entries) - 1)

            # Print entry
            print(format_entry(entry, is_last, prefix, depth))

            # Recurse into directories
            if entry.is_dir() and depth < max_depth:
                extension = BLANK if is_last else PIPE
                walk_tree(entry, prefix + extension, depth + 1)

    # Display root
    print(f"\n{root}/")

    # Walk tree
    walk_tree(root, "", 0)

    # Display summary
    if show_sizes and (file_count > 0 or dir_count > 0):
        print(f"\nTotal: {format_size(total_size)} across {file_count} files in {dir_count} directories")
    print()

# ======================================================
# INJECTED MODULE - END
# Source: lib/ui.py
# ======================================================



# ======================================================

# ======================================================
# INJECTED MODULE - START
# Generated by build.py v3.0.0
# Source: lib/season_detection.py
# ======================================================

"""
Season Detection Module for Media Library Tools
Version: 1.0

Shared season detection logic extracted from plex_make_seasons with advanced
multi-stage validation, confidence scoring, and comprehensive pattern matching.

Features:
- 19 season detection patterns with priority ordering
- Multi-stage validation with confidence scoring
- Pattern-specific validation for different season types
- Quality indicator detection (prevents false positives)
- Position-based validation (relative position in filename)
- Range validation (different ranges for different pattern types)
- Extended season support (S100-S2050 for long-running shows)
- Year-based seasons (1990-2099 with special handling)
- Episode/Part/Chapter/Disc/Volume patterns
- Comprehensive statistics tracking

This module provides the shared interface and logic for both plex_make_seasons
and plex_make_all_seasons scripts, eliminating code duplication while providing
advanced detection capabilities.
"""

import re
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Tuple, Any


@dataclass
class SeasonPatternDefinitions:
    """
    Centralized season pattern definitions with metadata.

    All patterns are ordered by specificity and priority to ensure
    the most accurate match is found first.
    """

    # Standard patterns (highest priority) - S01E01, Season 1
    STANDARD_PATTERNS: List[Tuple[str, str]] = field(default_factory=lambda: [
        (r'[Ss](\d{1,2})[Ee]\d{1,3}', 'S{:02d}E format'),
        (r'[Ss]eason[\s\._-]*(\d{1,2})', 'Season X format'),
    ])

    # Extended season patterns (high priority) - S100+
    EXTENDED_PATTERNS: List[Tuple[str, str]] = field(default_factory=lambda: [
        (r'[Ss](\d{3,4})[Ee]\d{1,3}', 'Extended season S###/####E## format'),
        (r'[Ss]eason[\s\._-]*(\d{3,4})', 'Extended Season #### format'),
    ])

    # Enhanced alternative patterns (medium-high priority)
    ENHANCED_ALTERNATIVE: List[Tuple[str, str]] = field(default_factory=lambda: [
        (r'(\d{1,3})x\d{1,3}', 'Enhanced season #x# format'),
        (r'[Ss](\d{1,4})\D', 'Enhanced S# format'),
    ])

    # Numeric-only patterns (medium priority)
    NUMERIC_ONLY: List[Tuple[str, str]] = field(default_factory=lambda: [
        (r'(?:ep|episode)[\s\-_.]*(\d{1,2})(?:[^\d]|$)', 'Episode-prefixed numeric format'),
        (r'(?:^|[\s\-_.])[^\d]*[\s\-_.](\d{1,2})[\s\-_.](?!\d*(?:p|fps|kbps))', 'Separated numeric format'),
    ])

    # Year-based seasons (special handling)
    YEAR_BASED: List[Tuple[str, str]] = field(default_factory=lambda: [
        (r'[\(\[]?(20\d{2})[\)\]]?', 'Year format'),
    ])

    # Episode/media patterns (various priorities)
    EPISODE_PATTERNS: List[Tuple[str, str]] = field(default_factory=lambda: [
        # Episode numbering patterns
        (r'[Ee]pisode[\s\._-]*(\d{1,3})', 'Episode X format'),
        (r'[Ee]p[\s\._-]*(\d{1,3})', 'Ep X format'),
        # Part/Chapter patterns
        (r'[Pp]art[\s\._-]*(\d{1,2})', 'Part X format'),
        (r'[Cc]hapter[\s\._-]*(\d{1,2})', 'Chapter X format'),
        # Disc patterns
        (r'[Dd]isc[\s\._-]*(\d{1,2})', 'Disc X format'),
        (r'[Dd](\d{1,2})', 'D1 format'),
        # Volume patterns
        (r'[Vv]ol[\s\._-]*(\d{1,2})', 'Vol X format'),
        (r'[Vv](\d{1,2})', 'V1 format'),
    ])

    def get_all_patterns(self) -> List[Tuple[str, str]]:
        """
        Get all patterns in priority order.

        Returns:
            List of (regex, description) tuples
        """
        return (
            self.STANDARD_PATTERNS +
            self.EXTENDED_PATTERNS +
            self.ENHANCED_ALTERNATIVE +
            self.YEAR_BASED +
            self.EPISODE_PATTERNS +
            self.NUMERIC_ONLY
        )


class SeasonValidationEngine:
    """
    Multi-stage validation engine for season detection.

    Provides sophisticated validation including:
    - Quality indicator detection
    - Position-based confidence scoring
    - Range validation by pattern type
    - Context character analysis
    """

    # Quality indicators that should be rejected
    QUALITY_PATTERNS = [
        r'720p', r'1080p', r'480p', r'2160p', r'4K',
        r'\d+kbps', r'\d+fps', r'HDR', r'DTS', r'AC3',
        r'H\.?264', r'H\.?265', r'x264', r'x265',
        r'HEVC', r'AVC', r'BluRay', r'WEBRip', r'DVDRip'
    ]

    # Positive indicators for season detection
    POSITIVE_INDICATORS = ['ep', 'episode', 'season', 'series', '-', '_', '.', ' ']

    # Negative indicators that reduce confidence
    NEGATIVE_INDICATORS = ['p', 'fps', 'kbps', 'bit', 'mb', 'gb']

    def detect_quality_indicators(self, filename: str) -> bool:
        """
        Detect if filename contains quality indicators.

        Args:
            filename: Filename to check

        Returns:
            True if quality indicators detected, False otherwise
        """
        filename_lower = filename.lower()
        for pattern in self.QUALITY_PATTERNS:
            if re.search(pattern, filename_lower, re.IGNORECASE):
                return True
        return False

    def validate_position(self, filename: str, match_pos: int) -> float:
        """
        Calculate position-based confidence adjustment.

        Args:
            filename: Full filename
            match_pos: Position of match in filename

        Returns:
            Confidence adjustment value
        """
        filename_length = len(filename)
        if filename_length == 0:
            return 0.0

        relative_position = match_pos / filename_length

        if relative_position > 0.7:  # Changed from 0.8 to 0.7 to be more strict
            return -0.5  # Late in filename, likely not season
        elif relative_position < 0.3:
            return 0.3   # Early in filename, likely season
        else:
            return 0.0   # Middle position, neutral

    def validate_range_by_pattern(self, season_num: int, pattern_desc: str) -> bool:
        """
        Validate season number range based on pattern type.

        Args:
            season_num: Season number to validate
            pattern_desc: Pattern description

        Returns:
            True if valid range, False otherwise
        """
        if 'Extended' in pattern_desc:
            return 100 <= season_num <= 2050
        elif 'numeric' in pattern_desc.lower():
            return 1 <= season_num <= 50
        elif 'Enhanced' in pattern_desc:
            if 'S#' in pattern_desc:
                return 1 <= season_num <= 2050
            elif '#x#' in pattern_desc:
                return 1 <= season_num <= 500
        elif 'Year format' in pattern_desc:
            return season_num >= 1990
        else:
            return 1 <= season_num <= 50

    def calculate_confidence_score(self, filename: str, match_text: str,
                                   season_num: int, pattern_desc: str) -> float:
        """
        Calculate comprehensive confidence score for a match.

        Args:
            filename: Full filename
            match_text: Matched text from pattern
            season_num: Extracted season number
            pattern_desc: Pattern description

        Returns:
            Confidence score (0.0-1.0)
        """
        confidence = 0.0

        # Position-based adjustment
        match_pos = filename.find(match_text)
        confidence += self.validate_position(filename, match_pos)

        # Range-based confidence boost
        if 'Extended' in pattern_desc:
            confidence += 0.4
        elif 'numeric' in pattern_desc.lower():
            confidence += 0.2
        elif 'Enhanced' in pattern_desc:
            confidence += 0.3

        # Context character analysis
        filename_length = len(filename)
        context_start = max(0, match_pos - 3)
        context_end = min(filename_length, match_pos + len(match_text) + 3)
        context = filename[context_start:context_end].lower()

        for indicator in self.POSITIVE_INDICATORS:
            if indicator in context:
                confidence += 0.1

        for indicator in self.NEGATIVE_INDICATORS:
            if indicator in context:
                confidence -= 0.2

        # Filename structure analysis
        if any(sep in filename for sep in [' - ', '.', '_', 'S0', 's0', 'Season', 'season']):
            confidence += 0.2

        # Clamp to valid range
        return max(0.0, min(1.0, confidence))

    def validate_numeric_season(self, filename: str, match_text: str,
                               season_num: int, pattern_desc: str) -> Tuple[bool, float]:
        """
        Validate that a numeric match represents a season.

        Args:
            filename: Full filename
            match_text: Matched text from pattern
            season_num: Extracted season number
            pattern_desc: Pattern description

        Returns:
            Tuple of (is_valid, confidence_score)
        """
        # Check for quality indicators first
        if self.detect_quality_indicators(filename):
            return False, 0.0

        # Validate range
        if not self.validate_range_by_pattern(season_num, pattern_desc):
            return False, 0.0

        # Calculate confidence
        confidence = self.calculate_confidence_score(filename, match_text, season_num, pattern_desc)

        # Apply minimum confidence threshold
        min_confidence = 0.3 if 'numeric' in pattern_desc.lower() else 0.2

        return confidence >= min_confidence, confidence


class BaseSeasonDetector:
    """
    Base class for season detection shared between plex scripts.

    Provides common season detection interface and functionality that can be
    inherited by script-specific organizer classes.
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        Initialize season detector with configuration.

        Args:
            config: Configuration dictionary (optional)
        """
        self.config = config or {}
        self.patterns = SeasonPatternDefinitions()
        self.validator = SeasonValidationEngine()
        self.season_patterns = self.patterns.get_all_patterns()

        # Statistics tracking
        self.stats = {
            'season_patterns_found': {},
            'validation_results': {},
            'confidence_scores': []
        }

    def extract_season_info(self, filename: str) -> Tuple[Optional[int], str, str]:
        """
        Extract season information from filename.

        Args:
            filename: Filename to analyze

        Returns:
            Tuple of (season_number, pattern_description, matched_text)
            Returns (None, "No pattern matched", "") if no match found
        """
        for pattern, description in self.season_patterns:
            match = re.search(pattern, filename, re.IGNORECASE)
            if match:
                try:
                    season_num = int(match.group(1))
                    matched_text = match.group(0)

                    # Pattern-specific validation
                    if 'Year format' in description:
                        if season_num >= 1990:
                            self._track_pattern_usage(description, True)
                            return season_num, description, matched_text
                    elif 'Extended' in description:
                        if 100 <= season_num <= 2050:
                            self._track_pattern_usage(description, True)
                            return season_num, description, matched_text
                    elif 'numeric' in description.lower():
                        is_valid, confidence = self.validator.validate_numeric_season(
                            filename, matched_text, season_num, description)
                        if is_valid:
                            self._track_pattern_usage(description, True)
                            self.stats['confidence_scores'].append(confidence)
                            return season_num, description, matched_text
                    elif 'Enhanced' in description:
                        if 'S#' in description and 1 <= season_num <= 2050:
                            self._track_pattern_usage(description, True)
                            return season_num, description, matched_text
                        elif '#x#' in description and 1 <= season_num <= 500:
                            self._track_pattern_usage(description, True)
                            return season_num, description, matched_text
                    elif 1 <= season_num <= 50:
                        self._track_pattern_usage(description, True)
                        return season_num, description, matched_text

                except (ValueError, IndexError):
                    continue

        self._track_pattern_usage("No pattern matched", False)
        return None, "No pattern matched", ""

    def generate_season_directory_name(self, season_num: int, pattern_desc: str) -> str:
        """
        Generate season directory name based on season number and pattern.

        Args:
            season_num: Season number
            pattern_desc: Pattern description

        Returns:
            Season directory name (e.g., "Season 01" or "Season 100")
        """
        if 'Year format' in pattern_desc:
            return f"Season {season_num}"
        elif 'Extended' in pattern_desc or season_num >= 100:
            return f"Season {season_num}"
        else:
            return f"Season {season_num:02d}"

    def get_season_patterns(self) -> List[Tuple[str, str]]:
        """
        Get all season patterns.

        Returns:
            List of (regex, description) tuples
        """
        return self.season_patterns

    def _track_pattern_usage(self, pattern_desc: str, success: bool) -> None:
        """
        Track pattern usage for statistics.

        Args:
            pattern_desc: Pattern description
            success: Whether pattern matched successfully
        """
        if pattern_desc not in self.stats['season_patterns_found']:
            self.stats['season_patterns_found'][pattern_desc] = 0

        if success:
            self.stats['season_patterns_found'][pattern_desc] += 1

    def get_detection_stats(self) -> Dict[str, Any]:
        """
        Get comprehensive detection statistics.

        Returns:
            Dictionary of statistics
        """
        return {
            'patterns_found': dict(self.stats['season_patterns_found']),
            'total_patterns_used': len([k for k, v in self.stats['season_patterns_found'].items() if v > 0]),
            'average_confidence': (
                sum(self.stats['confidence_scores']) / len(self.stats['confidence_scores'])
                if self.stats['confidence_scores'] else 0.0
            )
        }


# ======================================================
# INJECTED MODULE - END
# Source: lib/season_detection.py
# ======================================================



# ======================================================


class Configuration:
    """Configuration management with multi-layer hierarchy support."""

    DEFAULT_DEPTH = 3
    DEFAULT_SAMPLE_THRESHOLD = 50  # MB
    DEFAULT_ARCHIVE_RETENTION = 5
    DEFAULT_DRY_RUN_LEVEL = 'basic'

    def __init__(self):
        # Core settings
        self.dry_run = True
        self.execute = False
        self.force = False
        self.yes = False
        self.verbose = False
        self.debug = False
        self.no_banner = False

        # Directory settings
        self.source_dir = Path('.')
        self.target_dir = None
        self.depth = self.DEFAULT_DEPTH
        self.ignore_dirs = []

        # Sample detection
        self.enable_sample_detection = False
        self.sample_threshold = self.DEFAULT_SAMPLE_THRESHOLD

        # Archive settings
        self.enable_archive = False
        self.archive_retention = self.DEFAULT_ARCHIVE_RETENTION

        # Cleanup settings
        self.enable_cleanup = False
        self.cleanup_recursive = True

        # Phase control
        self.phase_mode = 'full'  # 'full', 'consolidate', 'organize', 'archive'

        # Season targeting
        self.target_season = None

        # Dry-run detail level
        self.dry_run_level = self.DEFAULT_DRY_RUN_LEVEL

        # Conflict handling
        self.no_conflict_prompt = False

    def load_from_env(self, cli_args=None) -> None:
        """Load configuration from environment variables and .env files with CLI priority."""
        # AUTO_EXECUTE with CLI > ENV > Local .env > Global .env priority
        if read_config_bool('AUTO_EXECUTE', cli_args=cli_args, default=False):
            self.execute = True
            self.dry_run = False

        # AUTO_CONFIRM with CLI > ENV > Local .env > Global .env priority
        if read_config_bool('AUTO_CONFIRM', cli_args=cli_args, default=False):
            self.yes = True

        # Sample detection
        sample_env = os.getenv('PLEX_SAMPLE_DETECTION')
        if sample_env and sample_env.lower() in ('true', '1', 'yes'):
            self.enable_sample_detection = True

        # Sample threshold
        threshold_env = os.getenv('PLEX_SAMPLE_THRESHOLD')
        if threshold_env:
            try:
                self.sample_threshold = int(threshold_env)
            except ValueError:
                pass

    def validate(self) -> bool:
        """Validate configuration settings."""
        if self.sample_threshold < 1:
            print("Error: Sample threshold must be at least 1 MB", file=sys.stderr)
            return False

        if self.depth < 1:
            print("Error: Depth must be at least 1", file=sys.stderr)
            return False

        if self.archive_retention < 0:
            print("Error: Archive retention must be non-negative", file=sys.stderr)
            return False

        return True


class DirectoryExclusionMatcher:
    """Handles directory exclusion pattern matching."""

    def __init__(self, patterns: List[str]):
        """Initialize with list of exclusion patterns."""
        self.patterns = [p.strip().lower() for p in patterns if p.strip()]

    def should_exclude(self, dir_path: Path) -> bool:
        """Check if directory should be excluded based on patterns."""
        dir_name_lower = dir_path.name.lower()

        for pattern in self.patterns:
            # Case-insensitive partial matching
            if pattern in dir_name_lower:
                return True

        return False


class SeasonOrganizer(BaseSeasonDetector):
    """Enhanced season organizer with three-phase processing."""

    def __init__(self, config: Configuration):
        # Initialize base season detector
        super().__init__(config={})

        self.config = config
        self.file_lock = FileLock('plex_make_seasons')

        # Video file extensions
        self.video_extensions = {
            '.mp4', '.avi', '.mkv', '.mov', '.wmv', '.flv', '.webm', '.m4v',
            '.mpg', '.mpeg', '.3gp', '.ogv', '.ts', '.m2ts', '.vob', '.divx',
            '.xvid', '.rm', '.rmvb', '.asf', '.f4v', '.m4p'
        }

        # Statistics tracking (extends base stats)
        self.stats.update({
            'total_files': 0,
            'video_files': 0,
            'content_files': 0,
            'sample_files': 0,
            'processed_files': 0,
            'skipped_files': 0,
            'created_directories': 0,
            'seasons_detected': 0,
            'conflicts_detected': 0,
            'samples_archived': 0,
            'errors': []
        })

        # Directory exclusion matcher
        self.exclusion_matcher = DirectoryExclusionMatcher(config.ignore_dirs) if config.ignore_dirs else None

    def acquire_lock(self) -> bool:
        """Acquire file lock to prevent multiple instances."""
        return self.file_lock.acquire_lock(self.config.force)

    def release_lock(self) -> None:
        """Release the file lock."""
        self.file_lock.release_lock()

    def is_video_file(self, file_path: Path) -> bool:
        """Check if a file is a video file based on its extension."""
        return file_path.suffix.lower() in self.video_extensions

    def is_sample_file(self, file_path: Path) -> bool:
        """Determine if a file is a sample based on size threshold."""
        if not self.config.enable_sample_detection:
            return False

        try:
            file_size_mb = file_path.stat().st_size / (1024 * 1024)
            return file_size_mb < self.config.sample_threshold
        except (OSError, IOError):
            return False

    def find_video_files_with_depth(self, source_dir: Path, max_depth: int) -> Tuple[List[Path], List[Path]]:
        """Find video files up to specified depth, separating content and samples.

        Returns:
            Tuple of (content_files, sample_files)
        """
        content_files = []
        sample_files = []

        queue = [(source_dir, 1)]

        while queue:
            current_dir, current_depth = queue.pop(0)

            if current_depth > max_depth:
                continue

            # Check if directory should be excluded
            if self.exclusion_matcher and self.exclusion_matcher.should_exclude(current_dir):
                if self.config.verbose:
                    print(f"  Excluding directory: {current_dir.name}")
                continue

            try:
                for item in current_dir.iterdir():
                    if item.is_file() and self.is_video_file(item):
                        # Categorize as sample or content
                        if self.is_sample_file(item):
                            sample_files.append(item)
                        else:
                            content_files.append(item)
                    elif item.is_dir() and current_depth < max_depth:
                        queue.append((item, current_depth + 1))
            except (PermissionError, OSError) as e:
                if self.config.verbose:
                    print(f"  Warning: Cannot access directory {current_dir}: {e}")
                continue

        return content_files, sample_files

    def extract_season_info(self, filename: str) -> Tuple[Optional[int], str, str]:
        """Extract season information from filename with target season filtering.

        Extends base implementation with plex_make_seasons-specific filtering logic.
        """
        # Call base implementation
        season_num, description, matched_text = super().extract_season_info(filename)

        # Apply target season filtering if configured
        if season_num is not None and self.config.target_season is not None:
            if season_num != self.config.target_season:
                return None, "Filtered by target_season", ""

        return season_num, description, matched_text

    def handle_file_collision(self, target_file: Path) -> Path:
        """Handle file name collisions by generating unique names."""
        if not target_file.exists():
            return target_file

        base_name = target_file.stem
        extension = target_file.suffix
        parent_dir = target_file.parent

        counter = 1
        while True:
            new_name = f"{base_name}_{counter}{extension}"
            new_path = parent_dir / new_name
            if not new_path.exists():
                return new_path
            counter += 1

    def consolidate(self, source_dir: Path) -> Dict:
        """Phase 1: Consolidation - File discovery and analysis."""
        result = {
            'content_files': [],
            'sample_files': [],
            'season_groups': {},
            'conflicts': [],
            'stats': {},
            'cleanup_stats': {}
        }

        if self.config.verbose:
            print("\n==> PHASE 1: CONSOLIDATION")
            print(f"Discovering video files (depth: {self.config.depth})...")

        # Step 0: System trash cleanup (if enabled)
        if self.config.enable_cleanup:
            if self.config.verbose:
                print("Cleaning system trash files...")

            cleaner = SystemTrashCleaner(
                verbose=self.config.verbose,
                dry_run=self.config.dry_run
            )
            cleanup_count = cleaner.clean_directory(
                source_dir,
                recursive=self.config.cleanup_recursive
            )
            result['cleanup_stats'] = cleaner.get_stats()

            if self.config.verbose:
                if self.config.dry_run:
                    print(f"Would remove {cleanup_count} trash files")
                else:
                    print(f"Removed {cleanup_count} trash files")

        # Find all video files
        content_files, sample_files = self.find_video_files_with_depth(source_dir, self.config.depth)

        result['content_files'] = content_files
        result['sample_files'] = sample_files

        self.stats['total_files'] = len(content_files) + len(sample_files)
        self.stats['content_files'] = len(content_files)
        self.stats['sample_files'] = len(sample_files)

        # Group content files by season
        season_groups = {}
        no_season_count = 0

        for file_path in content_files:
            season_num, pattern_desc, matched_text = self.extract_season_info(file_path.name)

            if season_num is None:
                no_season_count += 1
                continue

            if season_num not in season_groups:
                season_groups[season_num] = []

            season_groups[season_num].append({
                'path': file_path,
                'season': season_num,
                'pattern': pattern_desc,
                'matched': matched_text
            })

            # Track pattern usage
            if pattern_desc not in self.stats['season_patterns_found']:
                self.stats['season_patterns_found'][pattern_desc] = 0
            self.stats['season_patterns_found'][pattern_desc] += 1

        result['season_groups'] = season_groups
        self.stats['seasons_detected'] = len(season_groups)
        self.stats['skipped_files'] = no_season_count

        # Detect conflicts (duplicate filenames in same season)
        conflicts = []
        for season_num, files in season_groups.items():
            filenames = {}
            for file_info in files:
                filename = file_info['path'].name
                if filename not in filenames:
                    filenames[filename] = []
                filenames[filename].append(file_info['path'])

            for filename, paths in filenames.items():
                if len(paths) > 1:
                    conflicts.append({
                        'season': season_num,
                        'filename': filename,
                        'paths': paths
                    })

        result['conflicts'] = conflicts
        self.stats['conflicts_detected'] = len(conflicts)

        result['stats'] = dict(self.stats)

        return result

    def organize(self, consolidation_result: Dict, target_dir: Path) -> Dict:
        """Phase 2: Organization - Season directory creation and file movement."""
        result = {
            'moved_files': [],
            'created_directories': set(),
            'resolved_conflicts': [],
            'failed_operations': [],
            'stats': {}
        }

        if self.config.verbose:
            print("\n==> PHASE 2: ORGANIZATION")
            print("Creating season directories and organizing files...")

        season_groups = consolidation_result['season_groups']

        for season_num, files in season_groups.items():
            # Generate season directory name
            pattern_desc = files[0]['pattern'] if files else ''
            season_dir_name = self.generate_season_directory_name(season_num, pattern_desc)
            season_dir = target_dir / season_dir_name

            # Create season directory
            if not self.config.dry_run:
                try:
                    season_dir.mkdir(exist_ok=True)
                    result['created_directories'].add(season_dir)
                except OSError as e:
                    result['failed_operations'].append({
                        'type': 'mkdir',
                        'path': season_dir,
                        'error': str(e)
                    })
                    continue

            # Move files
            for file_info in files:
                source_path = file_info['path']
                target_file = season_dir / source_path.name
                final_target = self.handle_file_collision(target_file)

                if final_target != target_file:
                    result['resolved_conflicts'].append({
                        'original': target_file,
                        'renamed': final_target
                    })

                if not self.config.dry_run:
                    try:
                        shutil.move(str(source_path), str(final_target))
                        result['moved_files'].append({
                            'source': source_path,
                            'destination': final_target,
                            'season': season_num
                        })
                    except (OSError, IOError) as e:
                        result['failed_operations'].append({
                            'type': 'move',
                            'source': source_path,
                            'destination': final_target,
                            'error': str(e)
                        })
                else:
                    # Dry-run tracking
                    result['moved_files'].append({
                        'source': source_path,
                        'destination': final_target,
                        'season': season_num
                    })

        self.stats['processed_files'] = len(result['moved_files'])
        self.stats['created_directories'] = len(result['created_directories'])

        result['stats'] = dict(self.stats)

        return result

    def archive(self, consolidation_result: Dict, target_dir: Path) -> Dict:
        """Phase 3: Archive - Sample file archiving and manifest creation."""
        result = {
            'archived_samples': [],
            'archive_directory': None,
            'manifest_file': None,
            'stats': {}
        }

        if not self.config.enable_archive:
            result['stats'] = {'archive_skipped': True}
            return result

        if self.config.verbose:
            print("\n==> PHASE 3: ARCHIVE")
            print("Archiving sample files...")

        sample_files = consolidation_result['sample_files']

        if not sample_files:
            if self.config.verbose:
                print("No sample files to archive.")
            return result

        # Create archive directory
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        archive_dir = target_dir / '.plex_make_seasons_archive' / timestamp

        if not self.config.dry_run:
            try:
                archive_dir.mkdir(parents=True, exist_ok=True)
                result['archive_directory'] = archive_dir
            except OSError as e:
                if self.config.verbose:
                    print(f"Error creating archive directory: {e}")
                return result
        else:
            result['archive_directory'] = archive_dir

        # Archive sample files
        for sample_file in sample_files:
            target_path = archive_dir / sample_file.name

            if not self.config.dry_run:
                try:
                    shutil.move(str(sample_file), str(target_path))
                    result['archived_samples'].append(target_path)
                except (OSError, IOError) as e:
                    if self.config.verbose:
                        print(f"Error archiving {sample_file.name}: {e}")
            else:
                result['archived_samples'].append(target_path)

        self.stats['samples_archived'] = len(result['archived_samples'])

        # Create manifest
        manifest_path = archive_dir / 'manifest.json'
        manifest_data = {
            'version': '1.0',
            'timestamp': timestamp,
            'configuration': {
                'source_dir': str(self.config.source_dir),
                'target_dir': str(target_dir),
                'sample_threshold': self.config.sample_threshold,
                'depth': self.config.depth
            },
            'samples_archived': len(result['archived_samples']),
            'sample_files': [str(p) for p in result['archived_samples']]
        }

        if not self.config.dry_run:
            try:
                with open(manifest_path, 'w') as f:
                    json.dump(manifest_data, f, indent=2)
                result['manifest_file'] = manifest_path
            except (OSError, IOError) as e:
                if self.config.verbose:
                    print(f"Error creating manifest: {e}")
        else:
            result['manifest_file'] = manifest_path

        result['stats'] = dict(self.stats)

        return result

    def process_directory(self, source_dir: Path) -> bool:
        """Execute full three-phase processing workflow with progress tracking."""
        if not source_dir.exists():
            print(f"Error: Directory '{source_dir}' does not exist.")
            return False

        if not source_dir.is_dir():
            print(f"Error: '{source_dir}' is not a directory.")
            return False

        # Determine target directory
        target_dir = self.config.target_dir if self.config.target_dir else source_dir

        print(f"Processing video files in: {source_dir}")
        if target_dir != source_dir:
            print(f"Target directory: {target_dir}")
        print(f"Search depth: {self.config.depth}")
        if self.config.enable_sample_detection:
            print(f"Sample detection: enabled (threshold: {self.config.sample_threshold} MB)")
        if self.config.ignore_dirs:
            print(f"Excluding directories: {', '.join(self.config.ignore_dirs)}")
        print()

        try:
            # Initialize phase progress tracker for execute mode
            phase_tracker = None
            if not self.config.dry_run:
                phases = ["Phase 1: Consolidation", "Phase 2: Organization"]
                if self.config.enable_archive:
                    phases.append("Phase 3: Archive")
                phase_tracker = PhaseProgressTracker(phases)

            # Phase 1: Consolidation
            if phase_tracker:
                phase_tracker.start_phase(0)

            consolidation_result = self.consolidate(source_dir)

            if phase_tracker:
                phase_tracker.complete_phase(0)

            if self.config.dry_run:
                self.print_dry_run_preview(consolidation_result)
                return True

            self.print_consolidation_summary(consolidation_result)

            if not consolidation_result['content_files']:
                print("\nNo content files to organize.")
                if phase_tracker:
                    phase_tracker.display_summary()
                return True

            # Phase 2: Organization
            if phase_tracker:
                phase_tracker.start_phase(1, total_items=len(consolidation_result['content_files']))

            organization_result = self.organize(consolidation_result, target_dir)

            if phase_tracker:
                phase_tracker.complete_phase(1)

            self.print_organization_summary(organization_result)

            # Phase 3: Archive (if enabled)
            archive_result = None
            if self.config.enable_archive:
                if phase_tracker:
                    sample_count = len(consolidation_result.get('sample_files', []))
                    phase_tracker.start_phase(2, total_items=sample_count)

                archive_result = self.archive(consolidation_result, target_dir)

                if phase_tracker:
                    phase_tracker.complete_phase(2)

                self.print_archive_summary(archive_result)

            # Display phase summary
            if phase_tracker:
                phase_tracker.display_summary()

            # Final summary
            self.print_final_summary(consolidation_result, organization_result, archive_result)

            return True

        except Exception as e:
            print(f"Error during processing: {e}")
            if self.config.debug:
                import traceback
                traceback.print_exc()
            return False

    def print_dry_run_preview(self, consolidation_result: Dict) -> None:
        """Print dry-run preview based on configured detail level."""
        print("\n" + "=" * 60)
        print(f"DRY-RUN PREVIEW ({self.config.dry_run_level.upper()})")
        print("=" * 60)

        if self.config.dry_run_level == 'basic':
            self.print_basic_dry_run(consolidation_result)
        elif self.config.dry_run_level == 'detailed':
            self.print_detailed_dry_run(consolidation_result)
        elif self.config.dry_run_level == 'comprehensive':
            self.print_comprehensive_dry_run(consolidation_result)

    def print_basic_dry_run(self, consolidation_result: Dict) -> None:
        """Basic dry-run: Show what files would be moved."""
        season_groups = consolidation_result['season_groups']

        if not season_groups:
            print("No files would be moved (no seasons detected)")
            return

        total_files = sum(len(files) for files in season_groups.values())
        print(f"\nTotal files to organize: {total_files}")
        print(f"Season directories to create: {len(season_groups)}")

        print("\nFiles per season:")
        for season_num in sorted(season_groups.keys()):
            file_count = len(season_groups[season_num])
            season_name = self.generate_season_directory_name(
                season_num, season_groups[season_num][0]['pattern'] if season_groups[season_num] else '')
            print(f"  {season_name}: {file_count} files")

    def print_detailed_dry_run(self, consolidation_result: Dict) -> None:
        """Detailed dry-run: Include sample detection and conflict analysis."""
        print(f"Total files found: {consolidation_result['stats']['total_files']}")

        if self.config.enable_sample_detection:
            print(f"Sample files detected: {consolidation_result['stats']['sample_files']}")
            print(f"Content files: {consolidation_result['stats']['content_files']}")

        print(f"Seasons detected: {consolidation_result['stats']['seasons_detected']}")

        if consolidation_result['conflicts']:
            print(f"\nConflicts detected: {len(consolidation_result['conflicts'])}")
            for conflict in consolidation_result['conflicts'][:5]:
                print(f"  - {conflict['filename']} ({len(conflict['paths'])} copies in Season {conflict['season']})")

        print("\nSeason Organization Plan:")
        season_groups = consolidation_result['season_groups']
        for season_num in sorted(season_groups.keys()):
            files = season_groups[season_num]
            season_name = self.generate_season_directory_name(
                season_num, files[0]['pattern'] if files else '')
            print(f"\n  {season_name} ({len(files)} files):")

            for file_info in files[:3]:
                print(f"    - {file_info['path'].name}")

            if len(files) > 3:
                print(f"    ... and {len(files) - 3} more files")

    def print_comprehensive_dry_run(self, consolidation_result: Dict) -> None:
        """Comprehensive dry-run: Full three-phase simulation."""
        print("\nPHASE 1: CONSOLIDATION")
        print("-" * 40)
        print(f"Files discovered: {consolidation_result['stats']['total_files']}")

        if self.config.enable_sample_detection:
            print(f"Sample files: {consolidation_result['stats']['sample_files']}")
            print(f"Content files: {consolidation_result['stats']['content_files']}")

        print(f"Seasons detected: {consolidation_result['stats']['seasons_detected']}")
        print(f"Conflicts found: {consolidation_result['stats']['conflicts_detected']}")

        print("\nPHASE 2: ORGANIZATION")
        print("-" * 40)
        season_groups = consolidation_result['season_groups']
        print(f"Directories to create: {len(season_groups)}")
        print(f"Files to move: {sum(len(files) for files in season_groups.values())}")
        print(f"Conflicts to resolve: {len(consolidation_result['conflicts'])}")

        if self.config.enable_archive:
            print("\nPHASE 3: ARCHIVE")
            print("-" * 40)
            if consolidation_result['sample_files']:
                print(f"Samples to archive: {len(consolidation_result['sample_files'])}")
                print("Manifest file: Would be created for rollback capability")
            else:
                print("No samples to archive")
        else:
            print("\nPHASE 3: ARCHIVE - SKIPPED")
            print("-" * 40)
            print("Archiving disabled in configuration")

        print("\n" + "=" * 60)
        print("To execute these operations, run with --execute flag")
        print("=" * 60)

    def print_consolidation_summary(self, consolidation_result: Dict) -> None:
        """Display consolidation phase results."""
        print("\n" + "=" * 60)
        print("CONSOLIDATION PHASE COMPLETE")
        print("=" * 60)

        print(f"Total files discovered: {consolidation_result['stats']['total_files']}")

        if self.config.enable_sample_detection:
            print(f"Sample files (< {self.config.sample_threshold}MB): {consolidation_result['stats']['sample_files']}")
            print(f"Content files (>= {self.config.sample_threshold}MB): {consolidation_result['stats']['content_files']}")
        else:
            print(f"Content files: {consolidation_result['stats']['content_files']}")

        print(f"Seasons detected: {consolidation_result['stats']['seasons_detected']}")

        if consolidation_result['stats'].get('skipped_files', 0) > 0:
            print(f"Files without season info: {consolidation_result['stats']['skipped_files']}")

        if consolidation_result['conflicts']:
            print(f"Conflicts detected: {len(consolidation_result['conflicts'])}")

        # Season breakdown
        season_groups = consolidation_result['season_groups']
        if season_groups:
            print("\nSeason Breakdown:")
            for season_num in sorted(season_groups.keys()):
                file_count = len(season_groups[season_num])
                season_name = self.generate_season_directory_name(
                    season_num, season_groups[season_num][0]['pattern'] if season_groups[season_num] else '')
                print(f"  {season_name}: {file_count} files")

    def print_organization_summary(self, organization_result: Dict) -> None:
        """Display organization phase results."""
        print("\n" + "=" * 60)
        print("ORGANIZATION PHASE COMPLETE")
        print("=" * 60)

        print(f"Directories created: {len(organization_result['created_directories'])}")
        print(f"Files moved: {len(organization_result['moved_files'])}")

        if organization_result['resolved_conflicts']:
            print(f"Conflicts resolved: {len(organization_result['resolved_conflicts'])}")

        if organization_result['failed_operations']:
            print(f"Failed operations: {len(organization_result['failed_operations'])}")

    def print_archive_summary(self, archive_result: Dict) -> None:
        """Display archive phase results."""
        print("\n" + "=" * 60)
        print("ARCHIVE PHASE COMPLETE")
        print("=" * 60)

        if archive_result['stats'].get('archive_skipped'):
            print("Archive phase skipped (archiving disabled)")
            return

        print(f"Samples archived: {len(archive_result['archived_samples'])}")

        if archive_result['archive_directory']:
            print(f"Archive location: {archive_result['archive_directory']}")

        if archive_result['manifest_file']:
            print(f"Manifest created: {archive_result['manifest_file']}")
            print("\nRollback capability enabled via manifest file")

    def print_final_summary(self, consolidation_result: Dict, organization_result: Dict, archive_result: Optional[Dict]) -> None:
        """Display final summary of all three phases."""
        print("\n" + "=" * 60)
        print("FINAL SUMMARY")
        print("=" * 60)

        total_discovered = consolidation_result['stats']['total_files']
        total_moved = len(organization_result['moved_files'])
        total_archived = len(archive_result['archived_samples']) if archive_result else 0

        print(f"Files discovered: {total_discovered}")
        print(f"Files organized: {total_moved}")

        if total_archived > 0:
            print(f"Samples archived: {total_archived}")

        # Pattern statistics
        if self.stats['season_patterns_found']:
            print("\nSeason Patterns Detected:")
            for pattern, count in sorted(self.stats['season_patterns_found'].items()):
                print(f"  {pattern}: {count} files")

        if organization_result['failed_operations']:
            print("\nWARNING: Season organization completed with errors")
            print("Failed operations:")
            for op in organization_result['failed_operations']:
                print(f"  - {op['type']}: {op.get('path', op.get('source'))}: {op['error']}")
        else:
            print("\nSUCCESS: Season organization completed successfully")


def main():
    """Main function with argument parsing and execution."""
    parser = argparse.ArgumentParser(
        description="Plex Season Organizer - Enhanced Three-Phase System",
        epilog="""
Examples:
  %(prog)s                                      # Preview changes in current directory (dry-run default)
  %(prog)s /path/to/tv/show                     # Preview changes in specific directory
  %(prog)s --execute                            # Actually organize current directory episodes
  %(prog)s --execute -y                         # Organize without confirmation
  %(prog)s --sample-detect --sample-threshold 75 --execute  # Enable sample detection with custom threshold
  %(prog)s --ignore-dir "Extras,Samples" --execute          # Exclude specific directories
  %(prog)s --cleanup --execute                  # Clean .DS_Store and system trash files
  %(prog)s --archive --execute                  # Enable sample archiving
  %(prog)s --season 1 --execute                 # Process only Season 1 files
  %(prog)s --dry-run-level detailed             # Show detailed dry-run preview
  %(prog)s --depth 3 --execute                  # Search 3 levels deep
  %(prog)s --verbose --cleanup --execute        # Show verbose output with cleanup

Cron Usage:
  # Run daily at 3 AM with cleanup (non-interactive)
  0 3 * * * /usr/local/bin/plex_make_seasons /path/to/tv/downloads --cleanup --execute -y
        """,
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument(
        'directory',
        nargs='?',
        default='.',
        help='Directory containing video files to organize (default: current directory)'
    )
    parser.add_argument(
        '--target',
        metavar='DIR',
        help='Target directory for organized files (default: same as source)'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        default=True,
        help='Show what would be done without making changes (default)'
    )
    parser.add_argument(
        '--execute',
        action='store_true',
        help='Actually perform operations (overrides --dry-run)'
    )
    parser.add_argument(
        '--sample-detect',
        action='store_true',
        help='Enable sample file detection'
    )
    parser.add_argument(
        '--sample-threshold',
        type=int,
        metavar='N',
        help='Sample file size threshold in MB (default: 50)'
    )
    parser.add_argument(
        '--ignore-dir',
        metavar='DIRS',
        help='Comma-separated list of directory names to exclude'
    )
    parser.add_argument(
        '-s', '--season',
        type=int,
        metavar='N',
        help='Process only specified season number'
    )
    parser.add_argument(
        '--archive',
        action='store_true',
        help='Enable sample file archiving'
    )
    parser.add_argument(
        '--cleanup',
        action='store_true',
        help='Clean system trash files (.DS_Store, Thumbs.db, etc.) before processing'
    )
    parser.add_argument(
        '--dry-run-level',
        choices=['basic', 'detailed', 'comprehensive'],
        default='basic',
        help='Dry-run output detail level (default: basic)'
    )
    parser.add_argument(
        '--depth',
        type=int,
        default=3,
        help='Depth level for searching video files (default: 3)'
    )
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='Show verbose output'
    )
    parser.add_argument(
        '--debug',
        action='store_true',
        help='Show detailed debug output'
    )
    parser.add_argument(
        '--force',
        action='store_true',
        help='Force execution even if another instance is running'
    )
    parser.add_argument(
        '-y', '--yes',
        action='store_true',
        help='Skip confirmation prompts (for non-interactive use)'
    )
    parser.add_argument(
        '--list-patterns',
        action='store_true',
        help='List all supported season detection patterns and exit'
    )
    parser.add_argument(
        '--no-banner',
        action='store_true',
        help='Suppress banner display'
    )
    parser.add_argument(
        '--version',
        action='version',
        version=f'%(prog)s v{VERSION}'
    )

    args = parser.parse_args()

    # Create configuration
    config = Configuration()

    # Handle debug mode (enables verbose)
    if args.debug:
        config.debug = True
        config.verbose = True
        args.verbose = True
    elif args.verbose:
        config.verbose = True

    # Load configuration from environment with CLI priority
    config.load_from_env(cli_args=args)

    # Apply CLI arguments (override environment)
    config.source_dir = Path(args.directory).resolve()
    config.target_dir = Path(args.target).resolve() if args.target else None
    config.force = args.force
    config.yes = args.yes
    config.no_banner = args.no_banner
    config.depth = args.depth
    config.dry_run_level = args.dry_run_level

    # Handle dry-run vs execute mode
    if args.execute:
        config.execute = True
        config.dry_run = False
    else:
        # Explicitly set dry_run based on the argument (default is True)
        config.dry_run = args.dry_run

    if args.sample_detect:
        config.enable_sample_detection = True

    if args.sample_threshold:
        config.sample_threshold = args.sample_threshold

    if args.ignore_dir:
        config.ignore_dirs = [d.strip() for d in args.ignore_dir.split(',')]

    if args.season:
        config.target_season = args.season

    if args.archive:
        config.enable_archive = True

    if args.cleanup:
        config.enable_cleanup = True

    # Validate configuration
    if not config.validate():
        sys.exit(1)

    # Handle --list-patterns
    if args.list_patterns:
        quiet_mode = read_config_bool('QUIET_MODE', cli_args=args, default=False)
        display_banner("plex_make_seasons", VERSION,
                      "three-phase TV show season organizer",
                      config.no_banner, quiet_mode)

        organizer = SeasonOrganizer(config)
        print("Supported season detection patterns:")
        for pattern, description in organizer.season_patterns:
            print(f"  {description}: {pattern}")
        print("\nExample matches:")
        examples = [
            "Show.S01E01.Episode.Name.mkv",
            "Show.1x01.Episode.Name.mp4",
            "Show.Season.1.Episode.1.avi",
            "Show.2023.Episode.Name.mp4",
            "Show.Episode.01.mkv",
            "Show.Part.1.mp4"
        ]
        for example in examples:
            season_num, pattern_desc, matched = organizer.extract_season_info(example)
            if season_num:
                print(f"  '{example}' → Season {season_num:02d} ({pattern_desc})")
        sys.exit(0)

    # Validate arguments
    if config.yes and config.dry_run:
        print("Warning: -y/--yes flag has no effect in dry-run mode", file=sys.stderr)

    # Display banner
    quiet_mode = read_config_bool('QUIET_MODE', cli_args=args, default=False)
    display_banner("plex_make_seasons", VERSION,
                  "three-phase TV show season organizer",
                  config.no_banner, quiet_mode)

    if config.dry_run:
        print("DRY-RUN MODE: No changes will be made")
    else:
        print("EXECUTE MODE: Changes will be made")

    if config.debug:
        print("Debug: ENABLED")
    elif config.verbose:
        print("Verbose: ENABLED")
    print()

    # Create organizer instance
    organizer = SeasonOrganizer(config)

    # Confirmation logic for non-interactive environments
    if not config.dry_run:
        if not config.yes and not is_non_interactive():
            print(f"About to organize video files in: {config.source_dir}")
            if config.target_dir and config.target_dir != config.source_dir:
                print(f"Files will be moved to: {config.target_dir}")

            response = input("\nProceed with file organization? [y/N]: ")
            if response.lower() not in ['y', 'yes']:
                print("Operation cancelled.")
                sys.exit(0)
        elif config.yes or is_non_interactive():
            print(f"Proceeding with file organization in: {config.source_dir}")
            if config.target_dir and config.target_dir != config.source_dir:
                print(f"Files will be moved to: {config.target_dir}")

    try:
        # Acquire lock
        if not organizer.acquire_lock():
            sys.exit(1)

        # Process directory
        success = organizer.process_directory(config.source_dir)

        sys.exit(0 if success else 1)

    except KeyboardInterrupt:
        print("\nOperation cancelled by user.")
        sys.exit(1)
    except Exception as e:
        print(f"Error: {e}")
        if config.debug:
            import traceback
            traceback.print_exc()
        sys.exit(1)
    finally:
        organizer.release_lock()


if __name__ == '__main__':
    main()