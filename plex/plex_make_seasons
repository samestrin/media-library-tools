#!/usr/bin/env python3
"""
Plex Season Organizer - Enhanced Three-Phase System

CODING STANDARD EXCEPTION DOCUMENTATION:
This script exceeds the project's ~600-line source component guideline (currently ~1100 lines)
due to comprehensive three-phase processing requirements as specified in Sprint 9.0:

1. Consolidation Phase: File discovery, sample detection, conflict analysis (~200 lines)
2. Organization Phase: Season directory creation, file movement (~150 lines)
3. Archive Phase: Sample archiving, manifest creation, rollback capability (~150 lines)
4. Configuration System: Multi-layer config with .env support (~100 lines)
5. Enhanced CLI: Phase control, sample detection, directory exclusion (~150 lines)
6. UI/Reporting: Tiered dry-run output, phase-specific progress (~100 lines)
7. Season Detection: 19 patterns with validation (~200 lines, inherited)
8. Core Infrastructure: File locking, utilities, main entry point (~150 lines)

The script maintains zero external dependencies while providing enterprise-grade features
including sample detection, conflict resolution, rollback capability, and tiered dry-run modes.
Breaking this into multiple files would require either abandoning the zero-dependency principle
or creating complex inter-module dependencies that would reduce maintainability and portability.

This exception is explicitly approved per Sprint 9.0 requirements for comprehensive three-phase
file management transformation where functionality and zero-setup deployment are paramount.

A Python tool for organizing TV show episodes into season-specific directories with advanced
three-phase processing: consolidation, organization, and optional archiving.

Features:
- Three-phase processing: consolidation → organization → archive
- Sample file detection with configurable size threshold
- Directory exclusion with pattern matching
- Enhanced conflict resolution
- Manifest-based rollback capability
- Tiered dry-run output (basic, detailed, comprehensive)
- 19 season detection patterns with validation
- File-based locking mechanism
- Progress tracking and detailed statistics
- Cron-friendly operation
- Global configuration via .env files

Author: Media Library Tools Project
Version: 3.0.0
"""

import argparse
import json
import os
import re
import shutil
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple, Union

VERSION = "3.0.0"

# ======================================================

# ======================================================
# INJECTED MODULE - START
# Generated by build.py v3.0.0
# Source: utils.py
# ======================================================

"""
Shared Utility Module for Media Library Tools

This module provides backward compatibility by re-exporting functions from the
new modular library structure. New development should use the lib/ modules directly.

DEPRECATED: This module is maintained for backward compatibility only.
New tools should use the modular lib/ structure:
- lib/core.py: Essential utilities (locking, config, platform detection)
- lib/ui.py: User interface functions (banners, formatting, confirmations)
- lib/filesystem.py: File operations
- lib/validation.py: Input validation and error handling

Author: Media Library Tools Project
Version: 1.0.0
"""

import sys
import warnings
from pathlib import Path

# Add lib directory to path for imports
lib_path = Path(__file__).parent / "lib"
if str(lib_path) not in sys.path:
    sys.path.insert(0, str(lib_path))

# Import all functions from modular libraries
try:
    from core import (
        FileLock,
        acquire_lock,
        is_non_interactive,
        is_windows,
        read_global_config_bool,
        release_lock,
        should_use_emojis,
    )
    from filesystem import (
        get_directory_size,
        validate_directory_path,
    )
    from ui import (
        confirm_action,
        display_banner,
        format_size,
        format_status_message,
    )
    from validation import (
        validate_path_argument,
    )
except ImportError as e:
    # Fallback warning if lib modules are not available
    warnings.warn(
        f"Could not import from lib modules: {e}. Using legacy implementations.",
        DeprecationWarning,
        stacklevel=2,
    )

    # Keep legacy implementations as fallback
    import contextlib
    import os
    import platform
    import tempfile
    from typing import Optional, Tuple

    # Platform-specific imports
    try:
        import fcntl  # Unix/Linux/macOS
    except ImportError:
        fcntl = None  # Windows

    try:
        import msvcrt  # Windows
    except ImportError:
        msvcrt = None  # Unix/Linux/macOS

    # Legacy function implementations (fallback only)
    def display_banner(
        script_name: str,
        version: str,
        description: str,
        no_banner_flag: bool = False,
        quiet_mode: bool = False,
    ) -> None:
        """
        Display standardized banner for media library tools.

        Args:
            script_name: Name of the script
            version: Version string
            description: Brief description of the script
            no_banner_flag: If True, suppress banner display
            quiet_mode: If True, suppress banner display
        """
        # Check suppression conditions (highest to lowest priority)
        if no_banner_flag or quiet_mode or is_non_interactive():
            return

        try:
            # Display standardized ASCII art
            print("┏┳┓┏━╸╺┳┓╻┏━┓╻  ╻┏┓ ┏━┓┏━┓┏━┓╻ ╻╺┳╸┏━┓┏━┓╻  ┏━┓")
            print("┃┃┃┣╸  ┃┃┃┣━┫┃  ┃┣┻┓┣┳┛┣━┫┣┳┛┗┳┛ ┃ ┃ ┃┃ ┃┃  ┗━┓")
            print("╹ ╹┗━╸╺┻┛╹╹ ╹┗━╸╹┗━┛╹┗╸╹ ╹╹┗╸ ╹  ╹ ┗━┛┗━┛┗━╸┗━┛")
            print(f"{script_name} v{version}: {description}")
            print()  # Blank line for separation
        except Exception:
            # Banner display errors should not prevent script execution
            pass

    def is_non_interactive() -> bool:
        """
        Detect if running in non-interactive environment (cron, etc.).

        Returns:
            True if non-interactive, False otherwise
        """
        # Check if stdin is not a TTY (common in cron jobs)
        if not sys.stdin.isatty():
            return True

        # Check for common non-interactive environment variables
        non_interactive_vars = ["CRON", "CI", "AUTOMATED", "NON_INTERACTIVE"]
        for var in non_interactive_vars:
            if os.environ.get(var):
                return True

        # Check if TERM is not set or is 'dumb' (common in automated environments)
        term = os.environ.get("TERM", "")
        return bool(not term or term == "dumb")

    def read_global_config_bool(var_name: str, default: bool = False) -> bool:
        """
        Read a boolean environment variable with support for .env files.

        Args:
            var_name: Name of the environment variable
            default: Default value if not found

        Returns:
            Boolean value of the environment variable
        """
        # Check environment variable directly
        value = os.environ.get(var_name)
        if value is not None:
            return value.lower() in ("true", "1", "yes", "on")

        # Check local .env file
        env_file = ".env"
        if os.path.exists(env_file):
            try:
                with open(env_file) as f:
                    for line in f:
                        line = line.strip()
                        if line.startswith(f"{var_name}="):
                            value = line.split("=", 1)[1].strip()
                            return value.lower() in ("true", "1", "yes", "on")
            except OSError:
                pass

        # Check global .env file
        global_env_path = Path.home() / ".media-library-tools" / ".env"
        if global_env_path.exists():
            try:
                with open(global_env_path) as f:
                    for line in f:
                        line = line.strip()
                        if line.startswith(f"{var_name}="):
                            value = line.split("=", 1)[1].strip()
                            return value.lower() in ("true", "1", "yes", "on")
            except OSError:
                pass

        return default

    def is_windows() -> bool:
        """
        Detect if running on Windows platform.

        Returns:
            True if running on Windows, False otherwise
        """
        return platform.system().lower() == "windows"

    def should_use_emojis() -> bool:
        """
        Determine if emojis should be used based on platform and environment.

        Returns:
            True if emojis should be used, False otherwise
        """
        # Don't use emojis on Windows to avoid encoding issues
        if is_windows():
            return False

        # Don't use emojis in non-interactive environments
        if is_non_interactive():
            return False

        # Check for explicit emoji suppression
        return not read_global_config_bool("NO_EMOJIS", False)

    def format_size(size_bytes: int) -> str:
        """
        Format size in bytes to human readable format.

        Args:
            size_bytes: Size in bytes

        Returns:
            Human readable size string
        """
        for unit in ["B", "K", "M", "G", "T"]:
            if size_bytes < 1024.0:
                if unit == "B":
                    return f"{size_bytes:.0f}{unit}"
                else:
                    return f"{size_bytes:.1f}{unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.1f}P"

    def confirm_action(message: str, skip_confirmation: bool = False) -> bool:
        """
        Ask for user confirmation unless skipped.

        Args:
            message: Confirmation message to display
            skip_confirmation: If True, automatically confirm

        Returns:
            True if confirmed, False otherwise
        """
        if skip_confirmation:
            return True

        try:
            response = input(f"{message} (y/N): ").strip().lower()
            return response in ["y", "yes"]
        except (EOFError, KeyboardInterrupt):
            print("\nOperation cancelled.")
            return False

    class FileLock:
        """
        File locking utility class for preventing concurrent executions.
        """

        def __init__(self, lock_prefix: str = "media_library_tool"):
            """
            Initialize file lock.

            Args:
                lock_prefix: Prefix for lock file name
            """
            self.lock_prefix = lock_prefix
            self.lock_file = None

        def acquire_lock(self, force: bool = False) -> bool:
            """
            Acquire file lock to prevent multiple instances.

            Args:
                force: If True, skip locking mechanism

            Returns:
                True if lock acquired successfully, False otherwise
            """
            if force:
                return True

            try:
                with tempfile.NamedTemporaryFile(
                    mode="w",
                    prefix=f"{self.lock_prefix}_",
                    suffix=".lock",
                    delete=False,
                ) as temp_file:
                    self.lock_file = temp_file

                    # Platform-specific file locking
                    if fcntl is not None:  # Unix/Linux/macOS
                        fcntl.flock(
                            self.lock_file.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB
                        )
                    elif msvcrt is not None:  # Windows
                        msvcrt.locking(self.lock_file.fileno(), msvcrt.LK_NBLCK, 1)
                    else:
                        # Fallback: no locking available, just proceed
                        pass

                    self.lock_file.write(str(os.getpid()))
                    self.lock_file.flush()
                return True
            except OSError as e:
                if self.lock_file:
                    self.lock_file.close()
                    with contextlib.suppress(OSError):
                        os.unlink(self.lock_file.name)
                    self.lock_file = None
                print(
                    "Error: Another instance is already running. Use --force to override."
                )
                print(f"Lock error: {e}")
                return False

        def release_lock(self) -> None:
            """
            Release the file lock.
            """
            if self.lock_file:
                try:
                    # Only unlock if file is still open
                    if not self.lock_file.closed:
                        # Platform-specific file unlocking
                        if fcntl is not None:  # Unix/Linux/macOS
                            fcntl.flock(self.lock_file.fileno(), fcntl.LOCK_UN)
                        elif msvcrt is not None:  # Windows
                            msvcrt.locking(self.lock_file.fileno(), msvcrt.LK_UNLCK, 1)
                        # No explicit unlock needed for fallback case

                        self.lock_file.close()
                except (OSError, ValueError):
                    # Handle both file system errors and closed file errors
                    pass

                # Always try to remove lock file if it exists
                try:
                    if os.path.exists(self.lock_file.name):
                        os.unlink(self.lock_file.name)
                except OSError:
                    pass
                finally:
                    self.lock_file = None

    # Legacy standalone functions for backward compatibility
    def acquire_lock(
        lock_prefix: str = "media_library_tool", force: bool = False
    ) -> Tuple[bool, Optional[FileLock]]:
        """
        Legacy function for acquiring file locks.

        Args:
            lock_prefix: Prefix for lock file name
            force: If True, skip locking mechanism

        Returns:
            Tuple of (success: bool, lock_instance: FileLock or None)
        """
        lock = FileLock(lock_prefix)
        success = lock.acquire_lock(force)
        return success, lock if success else None

    def release_lock(lock_instance: FileLock) -> None:
        """
        Legacy function for releasing file locks.

        Args:
            lock_instance: FileLock instance to release
        """
        if lock_instance:
            lock_instance.release_lock()

    def format_status_message(
        message: str, emoji: str = "", fallback_prefix: str = ""
    ) -> str:
        """
        Format a status message with emoji on supported platforms or fallback text.

        Args:
            message: The main message text
            emoji: The emoji to use on supported platforms
            fallback_prefix: Text prefix to use instead of emoji on unsupported platforms

        Returns:
            Formatted message string
        """
        if should_use_emojis() and emoji:
            return f"{emoji} {message}"
        elif fallback_prefix:
            return f"{fallback_prefix}: {message}"
        else:
            return message

    # Add any missing functions that might be needed for backward compatibility
    def get_directory_size(path: str) -> int:
        """Legacy fallback for directory size calculation."""
        total_size = 0
        try:
            for dirpath, _dirnames, filenames in os.walk(path):
                for filename in filenames:
                    filepath = os.path.join(dirpath, filename)
                    try:
                        total_size += os.path.getsize(filepath)
                    except OSError:
                        continue
        except OSError:
            pass
        return total_size

    def validate_directory_path(path: str) -> Tuple[bool, str]:
        """Legacy fallback for directory path validation."""
        if not path:
            return False, "Path cannot be empty"

        path_obj = Path(path)

        if not path_obj.exists():
            return False, f"Path does not exist: {path}"

        if not path_obj.is_dir():
            return False, f"Path is not a directory: {path}"

        return True, ""

    def validate_path_argument(path: str) -> Tuple[bool, str]:
        """Legacy fallback for path argument validation."""
        return validate_directory_path(path)


# ======================================================
# INJECTED MODULE - END
# Source: utils.py
# ======================================================



# ======================================================


class Configuration:
    """Configuration management with multi-layer hierarchy support."""

    DEFAULT_DEPTH = 3
    DEFAULT_SAMPLE_THRESHOLD = 50  # MB
    DEFAULT_ARCHIVE_RETENTION = 5
    DEFAULT_DRY_RUN_LEVEL = 'basic'

    def __init__(self):
        # Core settings
        self.dry_run = True
        self.execute = False
        self.force = False
        self.yes = False
        self.verbose = False
        self.debug = False
        self.no_banner = False

        # Directory settings
        self.source_dir = Path('.')
        self.target_dir = None
        self.depth = self.DEFAULT_DEPTH
        self.ignore_dirs = []

        # Sample detection
        self.enable_sample_detection = False
        self.sample_threshold = self.DEFAULT_SAMPLE_THRESHOLD

        # Archive settings
        self.enable_archive = False
        self.archive_retention = self.DEFAULT_ARCHIVE_RETENTION

        # Phase control
        self.phase_mode = 'full'  # 'full', 'consolidate', 'organize', 'archive'

        # Season targeting
        self.target_season = None

        # Dry-run detail level
        self.dry_run_level = self.DEFAULT_DRY_RUN_LEVEL

        # Conflict handling
        self.no_conflict_prompt = False

    def load_from_env(self) -> None:
        """Load configuration from environment variables and .env files."""
        # AUTO_EXECUTE
        if read_global_config_bool('AUTO_EXECUTE', False):
            self.execute = True
            self.dry_run = False

        # AUTO_CONFIRM
        if read_global_config_bool('AUTO_CONFIRM', False):
            self.yes = True

        # Sample detection
        sample_env = os.getenv('PLEX_SAMPLE_DETECTION')
        if sample_env and sample_env.lower() in ('true', '1', 'yes'):
            self.enable_sample_detection = True

        # Sample threshold
        threshold_env = os.getenv('PLEX_SAMPLE_THRESHOLD')
        if threshold_env:
            try:
                self.sample_threshold = int(threshold_env)
            except ValueError:
                pass

    def validate(self) -> bool:
        """Validate configuration settings."""
        if self.sample_threshold < 1:
            print("Error: Sample threshold must be at least 1 MB", file=sys.stderr)
            return False

        if self.depth < 1:
            print("Error: Depth must be at least 1", file=sys.stderr)
            return False

        if self.archive_retention < 0:
            print("Error: Archive retention must be non-negative", file=sys.stderr)
            return False

        return True


class DirectoryExclusionMatcher:
    """Handles directory exclusion pattern matching."""

    def __init__(self, patterns: List[str]):
        """Initialize with list of exclusion patterns."""
        self.patterns = [p.strip().lower() for p in patterns if p.strip()]

    def should_exclude(self, dir_path: Path) -> bool:
        """Check if directory should be excluded based on patterns."""
        dir_name_lower = dir_path.name.lower()

        for pattern in self.patterns:
            # Case-insensitive partial matching
            if pattern in dir_name_lower:
                return True

        return False


class SeasonOrganizer:
    """Enhanced season organizer with three-phase processing."""

    def __init__(self, config: Configuration):
        self.config = config
        self.file_lock = FileLock('plex_make_seasons')

        # Video file extensions
        self.video_extensions = {
            '.mp4', '.avi', '.mkv', '.mov', '.wmv', '.flv', '.webm', '.m4v',
            '.mpg', '.mpeg', '.3gp', '.ogv', '.ts', '.m2ts', '.vob', '.divx',
            '.xvid', '.rm', '.rmvb', '.asf', '.f4v', '.m4p'
        }

        # Season detection patterns (ordered by specificity)
        self.season_patterns = [
            # Standard patterns: S01E01, S1E1, etc. (highest priority)
            (r'[Ss](\d{1,2})[Ee]\d{1,3}', 'S{:02d}E format'),
            (r'[Ss]eason[\s\._-]*(\d{1,2})', 'Season X format'),

            # Extended season patterns (high priority)
            (r'[Ss](\d{3,4})[Ee]\d{1,3}', 'Extended season S###/####E## format'),
            (r'[Ss]eason[\s\._-]*(\d{3,4})', 'Extended Season #### format'),

            # Enhanced alternative patterns (medium-high priority)
            (r'(\d{1,3})x\d{1,3}', 'Enhanced season #x# format'),
            (r'[Ss](\d{1,4})\D', 'Enhanced S# format'),

            # Numeric-only patterns (medium priority)
            (r'(?:ep|episode)[\s\-_.]*(\d{1,2})(?:[^\d]|$)', 'Episode-prefixed numeric format'),
            (r'(?:^|[\s\-_.])[^\d]*[\s\-_.](\d{1,2})[\s\-_.](?!\d*(?:p|fps|kbps))', 'Separated numeric format'),

            # Year-based seasons (for some shows)
            (r'[\(\[]?(20\d{2})[\)\]]?', 'Year format'),

            # Episode numbering patterns
            (r'[Ee]pisode[\s\._-]*(\d{1,3})', 'Episode X format'),
            (r'[Ee]p[\s\._-]*(\d{1,3})', 'Ep X format'),

            # Part/Chapter patterns
            (r'[Pp]art[\s\._-]*(\d{1,2})', 'Part X format'),
            (r'[Cc]hapter[\s\._-]*(\d{1,2})', 'Chapter X format'),

            # Disc patterns
            (r'[Dd]isc[\s\._-]*(\d{1,2})', 'Disc X format'),
            (r'[Dd](\d{1,2})', 'D1 format'),

            # Volume patterns
            (r'[Vv]ol[\s\._-]*(\d{1,2})', 'Vol X format'),
            (r'[Vv](\d{1,2})', 'V1 format'),
        ]

        # Statistics tracking
        self.stats = {
            'total_files': 0,
            'video_files': 0,
            'content_files': 0,
            'sample_files': 0,
            'processed_files': 0,
            'skipped_files': 0,
            'created_directories': 0,
            'seasons_detected': 0,
            'conflicts_detected': 0,
            'samples_archived': 0,
            'season_patterns_found': {},
            'errors': []
        }

        # Directory exclusion matcher
        self.exclusion_matcher = DirectoryExclusionMatcher(config.ignore_dirs) if config.ignore_dirs else None

    def acquire_lock(self) -> bool:
        """Acquire file lock to prevent multiple instances."""
        return self.file_lock.acquire_lock(self.config.force)

    def release_lock(self) -> None:
        """Release the file lock."""
        self.file_lock.release_lock()

    def is_video_file(self, file_path: Path) -> bool:
        """Check if a file is a video file based on its extension."""
        return file_path.suffix.lower() in self.video_extensions

    def is_sample_file(self, file_path: Path) -> bool:
        """Determine if a file is a sample based on size threshold."""
        if not self.config.enable_sample_detection:
            return False

        try:
            file_size_mb = file_path.stat().st_size / (1024 * 1024)
            return file_size_mb < self.config.sample_threshold
        except (OSError, IOError):
            return False

    def find_video_files_with_depth(self, source_dir: Path, max_depth: int) -> Tuple[List[Path], List[Path]]:
        """Find video files up to specified depth, separating content and samples.

        Returns:
            Tuple of (content_files, sample_files)
        """
        content_files = []
        sample_files = []

        queue = [(source_dir, 1)]

        while queue:
            current_dir, current_depth = queue.pop(0)

            if current_depth > max_depth:
                continue

            # Check if directory should be excluded
            if self.exclusion_matcher and self.exclusion_matcher.should_exclude(current_dir):
                if self.config.verbose:
                    print(f"  Excluding directory: {current_dir.name}")
                continue

            try:
                for item in current_dir.iterdir():
                    if item.is_file() and self.is_video_file(item):
                        # Categorize as sample or content
                        if self.is_sample_file(item):
                            sample_files.append(item)
                        else:
                            content_files.append(item)
                    elif item.is_dir() and current_depth < max_depth:
                        queue.append((item, current_depth + 1))
            except (PermissionError, OSError) as e:
                if self.config.verbose:
                    print(f"  Warning: Cannot access directory {current_dir}: {e}")
                continue

        return content_files, sample_files

    def validate_numeric_season(self, filename: str, match_text: str, season_num: int,
                              pattern_desc: str) -> Tuple[bool, float]:
        """Validate that a numeric match represents a season."""
        confidence = 0.0

        # Quality indicator detection
        quality_patterns = [
            r'720p', r'1080p', r'480p', r'2160p', r'4K',
            r'\d+kbps', r'\d+fps', r'HDR', r'DTS', r'AC3',
            r'H\.?264', r'H\.?265', r'x264', r'x265',
            r'HEVC', r'AVC', r'BluRay', r'WEBRip', r'DVDRip'
        ]

        filename_lower = filename.lower()
        for pattern in quality_patterns:
            if re.search(pattern, filename_lower, re.IGNORECASE):
                return False, 0.0

        # Position validation
        match_pos = filename.find(match_text)
        filename_length = len(filename)
        relative_position = match_pos / filename_length if filename_length > 0 else 0

        if relative_position > 0.8:
            confidence -= 0.5
        elif relative_position < 0.3:
            confidence += 0.3

        # Range validation
        if 'Extended' in pattern_desc:
            if not (100 <= season_num <= 2050):
                return False, 0.0
            confidence += 0.4
        elif 'numeric' in pattern_desc.lower():
            if not (1 <= season_num <= 50):
                return False, 0.0
            confidence += 0.2
        elif 'Enhanced' in pattern_desc:
            if not (1 <= season_num <= 500):
                return False, 0.0
            confidence += 0.3

        # Context character analysis
        context_start = max(0, match_pos - 3)
        context_end = min(filename_length, match_pos + len(match_text) + 3)
        context = filename[context_start:context_end].lower()

        positive_indicators = ['ep', 'episode', 'season', 'series', '-', '_', '.', ' ']
        negative_indicators = ['p', 'fps', 'kbps', 'bit', 'mb', 'gb']

        for indicator in positive_indicators:
            if indicator in context:
                confidence += 0.1

        for indicator in negative_indicators:
            if indicator in context:
                confidence -= 0.2

        # Filename structure analysis
        if any(sep in filename for sep in [' - ', '.', '_', 'S0', 's0', 'Season', 'season']):
            confidence += 0.2

        confidence = max(0.0, min(1.0, confidence))

        min_confidence = 0.3 if 'numeric' in pattern_desc.lower() else 0.2

        return confidence >= min_confidence, confidence

    def extract_season_info(self, filename: str) -> Tuple[Optional[int], str, str]:
        """Extract season information from filename."""
        for pattern, description in self.season_patterns:
            match = re.search(pattern, filename, re.IGNORECASE)
            if match:
                try:
                    season_num = int(match.group(1))
                    matched_text = match.group(0)

                    # Season filtering if target_season is set
                    if self.config.target_season is not None:
                        if season_num != self.config.target_season:
                            continue  # Skip non-matching seasons

                    # Pattern-specific validation
                    if 'Year format' in description:
                        if season_num >= 1990:
                            return season_num, description, matched_text
                    elif 'Extended' in description:
                        if 100 <= season_num <= 2050:
                            return season_num, description, matched_text
                    elif 'numeric' in description.lower():
                        is_valid, confidence = self.validate_numeric_season(
                            filename, matched_text, season_num, description)
                        if is_valid:
                            return season_num, description, matched_text
                    elif 'Enhanced' in description:
                        if 'S#' in description and 1 <= season_num <= 2050:
                            return season_num, description, matched_text
                        elif '#x#' in description and 1 <= season_num <= 500:
                            return season_num, description, matched_text
                    elif 1 <= season_num <= 50:
                        return season_num, description, matched_text

                except (ValueError, IndexError):
                    continue

        return None, "No pattern matched", ""

    def generate_season_directory_name(self, season_num: int, pattern_desc: str) -> str:
        """Generate season directory name based on season number and pattern."""
        if 'Year format' in pattern_desc:
            return f"Season {season_num}"
        elif 'Extended' in pattern_desc or season_num >= 100:
            return f"Season {season_num}"
        else:
            return f"Season {season_num:02d}"

    def handle_file_collision(self, target_file: Path) -> Path:
        """Handle file name collisions by generating unique names."""
        if not target_file.exists():
            return target_file

        base_name = target_file.stem
        extension = target_file.suffix
        parent_dir = target_file.parent

        counter = 1
        while True:
            new_name = f"{base_name}_{counter}{extension}"
            new_path = parent_dir / new_name
            if not new_path.exists():
                return new_path
            counter += 1

    def consolidate(self, source_dir: Path) -> Dict:
        """Phase 1: Consolidation - File discovery and analysis."""
        result = {
            'content_files': [],
            'sample_files': [],
            'season_groups': {},
            'conflicts': [],
            'stats': {}
        }

        if self.config.verbose:
            print("\n==> PHASE 1: CONSOLIDATION")
            print(f"Discovering video files (depth: {self.config.depth})...")

        # Find all video files
        content_files, sample_files = self.find_video_files_with_depth(source_dir, self.config.depth)

        result['content_files'] = content_files
        result['sample_files'] = sample_files

        self.stats['total_files'] = len(content_files) + len(sample_files)
        self.stats['content_files'] = len(content_files)
        self.stats['sample_files'] = len(sample_files)

        # Group content files by season
        season_groups = {}
        no_season_count = 0

        for file_path in content_files:
            season_num, pattern_desc, matched_text = self.extract_season_info(file_path.name)

            if season_num is None:
                no_season_count += 1
                continue

            if season_num not in season_groups:
                season_groups[season_num] = []

            season_groups[season_num].append({
                'path': file_path,
                'season': season_num,
                'pattern': pattern_desc,
                'matched': matched_text
            })

            # Track pattern usage
            if pattern_desc not in self.stats['season_patterns_found']:
                self.stats['season_patterns_found'][pattern_desc] = 0
            self.stats['season_patterns_found'][pattern_desc] += 1

        result['season_groups'] = season_groups
        self.stats['seasons_detected'] = len(season_groups)
        self.stats['skipped_files'] = no_season_count

        # Detect conflicts (duplicate filenames in same season)
        conflicts = []
        for season_num, files in season_groups.items():
            filenames = {}
            for file_info in files:
                filename = file_info['path'].name
                if filename not in filenames:
                    filenames[filename] = []
                filenames[filename].append(file_info['path'])

            for filename, paths in filenames.items():
                if len(paths) > 1:
                    conflicts.append({
                        'season': season_num,
                        'filename': filename,
                        'paths': paths
                    })

        result['conflicts'] = conflicts
        self.stats['conflicts_detected'] = len(conflicts)

        result['stats'] = dict(self.stats)

        return result

    def organize(self, consolidation_result: Dict, target_dir: Path) -> Dict:
        """Phase 2: Organization - Season directory creation and file movement."""
        result = {
            'moved_files': [],
            'created_directories': set(),
            'resolved_conflicts': [],
            'failed_operations': [],
            'stats': {}
        }

        if self.config.verbose:
            print("\n==> PHASE 2: ORGANIZATION")
            print("Creating season directories and organizing files...")

        season_groups = consolidation_result['season_groups']

        for season_num, files in season_groups.items():
            # Generate season directory name
            pattern_desc = files[0]['pattern'] if files else ''
            season_dir_name = self.generate_season_directory_name(season_num, pattern_desc)
            season_dir = target_dir / season_dir_name

            # Create season directory
            if not self.config.dry_run:
                try:
                    season_dir.mkdir(exist_ok=True)
                    result['created_directories'].add(season_dir)
                except OSError as e:
                    result['failed_operations'].append({
                        'type': 'mkdir',
                        'path': season_dir,
                        'error': str(e)
                    })
                    continue

            # Move files
            for file_info in files:
                source_path = file_info['path']
                target_file = season_dir / source_path.name
                final_target = self.handle_file_collision(target_file)

                if final_target != target_file:
                    result['resolved_conflicts'].append({
                        'original': target_file,
                        'renamed': final_target
                    })

                if not self.config.dry_run:
                    try:
                        shutil.move(str(source_path), str(final_target))
                        result['moved_files'].append({
                            'source': source_path,
                            'destination': final_target,
                            'season': season_num
                        })
                    except (OSError, IOError) as e:
                        result['failed_operations'].append({
                            'type': 'move',
                            'source': source_path,
                            'destination': final_target,
                            'error': str(e)
                        })
                else:
                    # Dry-run tracking
                    result['moved_files'].append({
                        'source': source_path,
                        'destination': final_target,
                        'season': season_num
                    })

        self.stats['processed_files'] = len(result['moved_files'])
        self.stats['created_directories'] = len(result['created_directories'])

        result['stats'] = dict(self.stats)

        return result

    def archive(self, consolidation_result: Dict, target_dir: Path) -> Dict:
        """Phase 3: Archive - Sample file archiving and manifest creation."""
        result = {
            'archived_samples': [],
            'archive_directory': None,
            'manifest_file': None,
            'stats': {}
        }

        if not self.config.enable_archive:
            result['stats'] = {'archive_skipped': True}
            return result

        if self.config.verbose:
            print("\n==> PHASE 3: ARCHIVE")
            print("Archiving sample files...")

        sample_files = consolidation_result['sample_files']

        if not sample_files:
            if self.config.verbose:
                print("No sample files to archive.")
            return result

        # Create archive directory
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        archive_dir = target_dir / '.plex_make_seasons_archive' / timestamp

        if not self.config.dry_run:
            try:
                archive_dir.mkdir(parents=True, exist_ok=True)
                result['archive_directory'] = archive_dir
            except OSError as e:
                if self.config.verbose:
                    print(f"Error creating archive directory: {e}")
                return result
        else:
            result['archive_directory'] = archive_dir

        # Archive sample files
        for sample_file in sample_files:
            target_path = archive_dir / sample_file.name

            if not self.config.dry_run:
                try:
                    shutil.move(str(sample_file), str(target_path))
                    result['archived_samples'].append(target_path)
                except (OSError, IOError) as e:
                    if self.config.verbose:
                        print(f"Error archiving {sample_file.name}: {e}")
            else:
                result['archived_samples'].append(target_path)

        self.stats['samples_archived'] = len(result['archived_samples'])

        # Create manifest
        manifest_path = archive_dir / 'manifest.json'
        manifest_data = {
            'version': '1.0',
            'timestamp': timestamp,
            'configuration': {
                'source_dir': str(self.config.source_dir),
                'target_dir': str(target_dir),
                'sample_threshold': self.config.sample_threshold,
                'depth': self.config.depth
            },
            'samples_archived': len(result['archived_samples']),
            'sample_files': [str(p) for p in result['archived_samples']]
        }

        if not self.config.dry_run:
            try:
                with open(manifest_path, 'w') as f:
                    json.dump(manifest_data, f, indent=2)
                result['manifest_file'] = manifest_path
            except (OSError, IOError) as e:
                if self.config.verbose:
                    print(f"Error creating manifest: {e}")
        else:
            result['manifest_file'] = manifest_path

        result['stats'] = dict(self.stats)

        return result

    def process_directory(self, source_dir: Path) -> bool:
        """Execute full three-phase processing workflow."""
        if not source_dir.exists():
            print(f"Error: Directory '{source_dir}' does not exist.")
            return False

        if not source_dir.is_dir():
            print(f"Error: '{source_dir}' is not a directory.")
            return False

        # Determine target directory
        target_dir = self.config.target_dir if self.config.target_dir else source_dir

        print(f"Processing video files in: {source_dir}")
        if target_dir != source_dir:
            print(f"Target directory: {target_dir}")
        print(f"Search depth: {self.config.depth}")
        if self.config.enable_sample_detection:
            print(f"Sample detection: enabled (threshold: {self.config.sample_threshold} MB)")
        if self.config.ignore_dirs:
            print(f"Excluding directories: {', '.join(self.config.ignore_dirs)}")
        print()

        try:
            # Phase 1: Consolidation
            consolidation_result = self.consolidate(source_dir)

            if self.config.dry_run:
                self.print_dry_run_preview(consolidation_result)
                return True

            self.print_consolidation_summary(consolidation_result)

            if not consolidation_result['content_files']:
                print("\nNo content files to organize.")
                return True

            # Phase 2: Organization
            organization_result = self.organize(consolidation_result, target_dir)
            self.print_organization_summary(organization_result)

            # Phase 3: Archive (if enabled)
            archive_result = None
            if self.config.enable_archive:
                archive_result = self.archive(consolidation_result, target_dir)
                self.print_archive_summary(archive_result)

            # Final summary
            self.print_final_summary(consolidation_result, organization_result, archive_result)

            return True

        except Exception as e:
            print(f"Error during processing: {e}")
            if self.config.debug:
                import traceback
                traceback.print_exc()
            return False

    def print_dry_run_preview(self, consolidation_result: Dict) -> None:
        """Print dry-run preview based on configured detail level."""
        print("\n" + "=" * 60)
        print(f"DRY-RUN PREVIEW ({self.config.dry_run_level.upper()})")
        print("=" * 60)

        if self.config.dry_run_level == 'basic':
            self.print_basic_dry_run(consolidation_result)
        elif self.config.dry_run_level == 'detailed':
            self.print_detailed_dry_run(consolidation_result)
        elif self.config.dry_run_level == 'comprehensive':
            self.print_comprehensive_dry_run(consolidation_result)

    def print_basic_dry_run(self, consolidation_result: Dict) -> None:
        """Basic dry-run: Show what files would be moved."""
        season_groups = consolidation_result['season_groups']

        if not season_groups:
            print("No files would be moved (no seasons detected)")
            return

        total_files = sum(len(files) for files in season_groups.values())
        print(f"\nTotal files to organize: {total_files}")
        print(f"Season directories to create: {len(season_groups)}")

        print("\nFiles per season:")
        for season_num in sorted(season_groups.keys()):
            file_count = len(season_groups[season_num])
            season_name = self.generate_season_directory_name(
                season_num, season_groups[season_num][0]['pattern'] if season_groups[season_num] else '')
            print(f"  {season_name}: {file_count} files")

    def print_detailed_dry_run(self, consolidation_result: Dict) -> None:
        """Detailed dry-run: Include sample detection and conflict analysis."""
        print(f"Total files found: {consolidation_result['stats']['total_files']}")

        if self.config.enable_sample_detection:
            print(f"Sample files detected: {consolidation_result['stats']['sample_files']}")
            print(f"Content files: {consolidation_result['stats']['content_files']}")

        print(f"Seasons detected: {consolidation_result['stats']['seasons_detected']}")

        if consolidation_result['conflicts']:
            print(f"\nConflicts detected: {len(consolidation_result['conflicts'])}")
            for conflict in consolidation_result['conflicts'][:5]:
                print(f"  - {conflict['filename']} ({len(conflict['paths'])} copies in Season {conflict['season']})")

        print("\nSeason Organization Plan:")
        season_groups = consolidation_result['season_groups']
        for season_num in sorted(season_groups.keys()):
            files = season_groups[season_num]
            season_name = self.generate_season_directory_name(
                season_num, files[0]['pattern'] if files else '')
            print(f"\n  {season_name} ({len(files)} files):")

            for file_info in files[:3]:
                print(f"    - {file_info['path'].name}")

            if len(files) > 3:
                print(f"    ... and {len(files) - 3} more files")

    def print_comprehensive_dry_run(self, consolidation_result: Dict) -> None:
        """Comprehensive dry-run: Full three-phase simulation."""
        print("\nPHASE 1: CONSOLIDATION")
        print("-" * 40)
        print(f"Files discovered: {consolidation_result['stats']['total_files']}")

        if self.config.enable_sample_detection:
            print(f"Sample files: {consolidation_result['stats']['sample_files']}")
            print(f"Content files: {consolidation_result['stats']['content_files']}")

        print(f"Seasons detected: {consolidation_result['stats']['seasons_detected']}")
        print(f"Conflicts found: {consolidation_result['stats']['conflicts_detected']}")

        print("\nPHASE 2: ORGANIZATION")
        print("-" * 40)
        season_groups = consolidation_result['season_groups']
        print(f"Directories to create: {len(season_groups)}")
        print(f"Files to move: {sum(len(files) for files in season_groups.values())}")
        print(f"Conflicts to resolve: {len(consolidation_result['conflicts'])}")

        if self.config.enable_archive:
            print("\nPHASE 3: ARCHIVE")
            print("-" * 40)
            if consolidation_result['sample_files']:
                print(f"Samples to archive: {len(consolidation_result['sample_files'])}")
                print("Manifest file: Would be created for rollback capability")
            else:
                print("No samples to archive")
        else:
            print("\nPHASE 3: ARCHIVE - SKIPPED")
            print("-" * 40)
            print("Archiving disabled in configuration")

        print("\n" + "=" * 60)
        print("To execute these operations, run with --execute flag")
        print("=" * 60)

    def print_consolidation_summary(self, consolidation_result: Dict) -> None:
        """Display consolidation phase results."""
        print("\n" + "=" * 60)
        print("CONSOLIDATION PHASE COMPLETE")
        print("=" * 60)

        print(f"Total files discovered: {consolidation_result['stats']['total_files']}")

        if self.config.enable_sample_detection:
            print(f"Sample files (< {self.config.sample_threshold}MB): {consolidation_result['stats']['sample_files']}")
            print(f"Content files (>= {self.config.sample_threshold}MB): {consolidation_result['stats']['content_files']}")
        else:
            print(f"Content files: {consolidation_result['stats']['content_files']}")

        print(f"Seasons detected: {consolidation_result['stats']['seasons_detected']}")

        if consolidation_result['stats'].get('skipped_files', 0) > 0:
            print(f"Files without season info: {consolidation_result['stats']['skipped_files']}")

        if consolidation_result['conflicts']:
            print(f"Conflicts detected: {len(consolidation_result['conflicts'])}")

        # Season breakdown
        season_groups = consolidation_result['season_groups']
        if season_groups:
            print("\nSeason Breakdown:")
            for season_num in sorted(season_groups.keys()):
                file_count = len(season_groups[season_num])
                season_name = self.generate_season_directory_name(
                    season_num, season_groups[season_num][0]['pattern'] if season_groups[season_num] else '')
                print(f"  {season_name}: {file_count} files")

    def print_organization_summary(self, organization_result: Dict) -> None:
        """Display organization phase results."""
        print("\n" + "=" * 60)
        print("ORGANIZATION PHASE COMPLETE")
        print("=" * 60)

        print(f"Directories created: {len(organization_result['created_directories'])}")
        print(f"Files moved: {len(organization_result['moved_files'])}")

        if organization_result['resolved_conflicts']:
            print(f"Conflicts resolved: {len(organization_result['resolved_conflicts'])}")

        if organization_result['failed_operations']:
            print(f"Failed operations: {len(organization_result['failed_operations'])}")

    def print_archive_summary(self, archive_result: Dict) -> None:
        """Display archive phase results."""
        print("\n" + "=" * 60)
        print("ARCHIVE PHASE COMPLETE")
        print("=" * 60)

        if archive_result['stats'].get('archive_skipped'):
            print("Archive phase skipped (archiving disabled)")
            return

        print(f"Samples archived: {len(archive_result['archived_samples'])}")

        if archive_result['archive_directory']:
            print(f"Archive location: {archive_result['archive_directory']}")

        if archive_result['manifest_file']:
            print(f"Manifest created: {archive_result['manifest_file']}")
            print("\nRollback capability enabled via manifest file")

    def print_final_summary(self, consolidation_result: Dict, organization_result: Dict, archive_result: Optional[Dict]) -> None:
        """Display final summary of all three phases."""
        print("\n" + "=" * 60)
        print("FINAL SUMMARY")
        print("=" * 60)

        total_discovered = consolidation_result['stats']['total_files']
        total_moved = len(organization_result['moved_files'])
        total_archived = len(archive_result['archived_samples']) if archive_result else 0

        print(f"Files discovered: {total_discovered}")
        print(f"Files organized: {total_moved}")

        if total_archived > 0:
            print(f"Samples archived: {total_archived}")

        # Pattern statistics
        if self.stats['season_patterns_found']:
            print("\nSeason Patterns Detected:")
            for pattern, count in sorted(self.stats['season_patterns_found'].items()):
                print(f"  {pattern}: {count} files")

        if organization_result['failed_operations']:
            print("\nWARNING: Season organization completed with errors")
            print("Failed operations:")
            for op in organization_result['failed_operations']:
                print(f"  - {op['type']}: {op.get('path', op.get('source'))}: {op['error']}")
        else:
            print("\nSUCCESS: Season organization completed successfully")


def main():
    """Main function with argument parsing and execution."""
    parser = argparse.ArgumentParser(
        description="Plex Season Organizer - Enhanced Three-Phase System",
        epilog="""
Examples:
  %(prog)s                                      # Preview changes in current directory (dry-run default)
  %(prog)s /path/to/tv/show                     # Preview changes in specific directory
  %(prog)s --execute                            # Actually organize current directory episodes
  %(prog)s --execute -y                         # Organize without confirmation
  %(prog)s --sample-detect --sample-threshold 75 --execute  # Enable sample detection with custom threshold
  %(prog)s --ignore-dir "Extras,Samples" --execute          # Exclude specific directories
  %(prog)s --archive --execute                  # Enable sample archiving
  %(prog)s --season 1 --execute                 # Process only Season 1 files
  %(prog)s --dry-run-level detailed             # Show detailed dry-run preview
  %(prog)s --depth 3 --execute                  # Search 3 levels deep
  %(prog)s --verbose --execute                  # Show verbose output

Cron Usage:
  # Run daily at 3 AM (non-interactive)
  0 3 * * * /usr/local/bin/plex_make_seasons /path/to/tv/downloads --execute -y
        """,
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument(
        'directory',
        nargs='?',
        default='.',
        help='Directory containing video files to organize (default: current directory)'
    )
    parser.add_argument(
        '--target',
        metavar='DIR',
        help='Target directory for organized files (default: same as source)'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        default=True,
        help='Show what would be done without making changes (default)'
    )
    parser.add_argument(
        '--execute',
        action='store_true',
        help='Actually perform operations (overrides --dry-run)'
    )
    parser.add_argument(
        '--sample-detect',
        action='store_true',
        help='Enable sample file detection'
    )
    parser.add_argument(
        '--sample-threshold',
        type=int,
        metavar='N',
        help='Sample file size threshold in MB (default: 50)'
    )
    parser.add_argument(
        '--ignore-dir',
        metavar='DIRS',
        help='Comma-separated list of directory names to exclude'
    )
    parser.add_argument(
        '-s', '--season',
        type=int,
        metavar='N',
        help='Process only specified season number'
    )
    parser.add_argument(
        '--archive',
        action='store_true',
        help='Enable sample file archiving'
    )
    parser.add_argument(
        '--dry-run-level',
        choices=['basic', 'detailed', 'comprehensive'],
        default='basic',
        help='Dry-run output detail level (default: basic)'
    )
    parser.add_argument(
        '--depth',
        type=int,
        default=3,
        help='Depth level for searching video files (default: 3)'
    )
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='Show verbose output'
    )
    parser.add_argument(
        '--debug',
        action='store_true',
        help='Show detailed debug output'
    )
    parser.add_argument(
        '--force',
        action='store_true',
        help='Force execution even if another instance is running'
    )
    parser.add_argument(
        '-y', '--yes',
        action='store_true',
        help='Skip confirmation prompts (for non-interactive use)'
    )
    parser.add_argument(
        '--list-patterns',
        action='store_true',
        help='List all supported season detection patterns and exit'
    )
    parser.add_argument(
        '--no-banner',
        action='store_true',
        help='Suppress banner display'
    )
    parser.add_argument(
        '--version',
        action='version',
        version=f'%(prog)s v{VERSION}'
    )

    args = parser.parse_args()

    # Create configuration
    config = Configuration()

    # Handle debug mode (enables verbose)
    if args.debug:
        config.debug = True
        config.verbose = True
        args.verbose = True
    elif args.verbose:
        config.verbose = True

    # Load configuration from environment
    config.load_from_env()

    # Apply CLI arguments (override environment)
    config.source_dir = Path(args.directory).resolve()
    config.target_dir = Path(args.target).resolve() if args.target else None
    config.force = args.force
    config.yes = args.yes
    config.no_banner = args.no_banner
    config.depth = args.depth
    config.dry_run_level = args.dry_run_level

    if args.execute:
        config.execute = True
        config.dry_run = False

    if args.sample_detect:
        config.enable_sample_detection = True

    if args.sample_threshold:
        config.sample_threshold = args.sample_threshold

    if args.ignore_dir:
        config.ignore_dirs = [d.strip() for d in args.ignore_dir.split(',')]

    if args.season:
        config.target_season = args.season

    if args.archive:
        config.enable_archive = True

    # Validate configuration
    if not config.validate():
        sys.exit(1)

    # Handle --list-patterns
    if args.list_patterns:
        quiet_mode = read_global_config_bool('QUIET_MODE', False)
        display_banner("plex_make_seasons", VERSION,
                      "three-phase TV show season organizer",
                      config.no_banner, quiet_mode)

        organizer = SeasonOrganizer(config)
        print("Supported season detection patterns:")
        for pattern, description in organizer.season_patterns:
            print(f"  {description}: {pattern}")
        print("\nExample matches:")
        examples = [
            "Show.S01E01.Episode.Name.mkv",
            "Show.1x01.Episode.Name.mp4",
            "Show.Season.1.Episode.1.avi",
            "Show.2023.Episode.Name.mp4",
            "Show.Episode.01.mkv",
            "Show.Part.1.mp4"
        ]
        for example in examples:
            season_num, pattern_desc, matched = organizer.extract_season_info(example)
            if season_num:
                print(f"  '{example}' → Season {season_num:02d} ({pattern_desc})")
        sys.exit(0)

    # Validate arguments
    if config.yes and config.dry_run:
        print("Warning: -y/--yes flag has no effect in dry-run mode", file=sys.stderr)

    # Display banner
    quiet_mode = read_global_config_bool('QUIET_MODE', False)
    display_banner("plex_make_seasons", VERSION,
                  "three-phase TV show season organizer",
                  config.no_banner, quiet_mode)

    if config.dry_run:
        print("DRY-RUN MODE: No changes will be made")
    else:
        print("EXECUTE MODE: Changes will be made")

    if config.debug:
        print("Debug: ENABLED")
    elif config.verbose:
        print("Verbose: ENABLED")
    print()

    # Create organizer instance
    organizer = SeasonOrganizer(config)

    # Confirmation logic for non-interactive environments
    if not config.dry_run:
        if not config.yes and not is_non_interactive():
            print(f"About to organize video files in: {config.source_dir}")
            if config.target_dir and config.target_dir != config.source_dir:
                print(f"Files will be moved to: {config.target_dir}")

            response = input("\nProceed with file organization? [y/N]: ")
            if response.lower() not in ['y', 'yes']:
                print("Operation cancelled.")
                sys.exit(0)
        elif config.yes or is_non_interactive():
            print(f"Proceeding with file organization in: {config.source_dir}")
            if config.target_dir and config.target_dir != config.source_dir:
                print(f"Files will be moved to: {config.target_dir}")

    try:
        # Acquire lock
        if not organizer.acquire_lock():
            sys.exit(1)

        # Process directory
        success = organizer.process_directory(config.source_dir)

        sys.exit(0 if success else 1)

    except KeyboardInterrupt:
        print("\nOperation cancelled by user.")
        sys.exit(1)
    except Exception as e:
        print(f"Error: {e}")
        if config.debug:
            import traceback
            traceback.print_exc()
        sys.exit(1)
    finally:
        organizer.release_lock()


if __name__ == '__main__':
    main()