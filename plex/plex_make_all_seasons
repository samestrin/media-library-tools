#!/usr/bin/env python3
"""
Plex Season Organizer (Batch)

A comprehensive tool for organizing TV show episodes into season directories across
multiple show directories. This script processes all subdirectories in a target
directory and organizes video files into proper season structures.

Features:
- Batch processing of multiple TV show directories
- System trash cleanup (.DS_Store, Thumbs.db, etc.)
- Parallel processing for improved performance
- Progress tracking and detailed reporting
- File-based locking mechanism
- Comprehensive error handling and recovery
- Dry-run mode for safe testing
- Cron-friendly operation

Author: Media Library Tools Project
Version: 2.2.0
"""

import argparse
import concurrent.futures
import os
import re
import shutil
import sys
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union

VERSION = "2.2.0"

# ======================================================

# ======================================================
# INJECTED MODULE - START
# Generated by build.py v3.0.0
# Source: utils.py
# ======================================================

"""
Shared Utility Module for Media Library Tools

This module provides backward compatibility by re-exporting functions from the
new modular library structure. New development should use the lib/ modules directly.

DEPRECATED: This module is maintained for backward compatibility only.
New tools should use the modular lib/ structure:
- lib/core.py: Essential utilities (locking, config, platform detection)
- lib/ui.py: User interface functions (banners, formatting, confirmations)
- lib/filesystem.py: File operations
- lib/validation.py: Input validation and error handling

Author: Media Library Tools Project
Version: 1.0.0
"""

import sys
import warnings
from pathlib import Path

# Add lib directory to path for imports
lib_path = Path(__file__).parent / "lib"
if str(lib_path) not in sys.path:
    sys.path.insert(0, str(lib_path))

# Import all functions from modular libraries
try:
    from core import (
        FileLock,
        acquire_lock,
        is_non_interactive,
        is_windows,
        read_global_config_bool,
        release_lock,
        should_use_emojis,
    )
    from filesystem import (
        get_directory_size,
        validate_directory_path,
    )
    from ui import (
        confirm_action,
        display_banner,
        format_size,
        format_status_message,
    )
    from validation import (
        validate_path_argument,
    )
except ImportError as e:
    # Fallback warning if lib modules are not available
    warnings.warn(
        f"Could not import from lib modules: {e}. Using legacy implementations.",
        DeprecationWarning,
        stacklevel=2,
    )

    # Keep legacy implementations as fallback
    import contextlib
    import os
    import platform
    import tempfile
    from typing import Optional, Tuple

    # Platform-specific imports
    try:
        import fcntl  # Unix/Linux/macOS
    except ImportError:
        fcntl = None  # Windows

    try:
        import msvcrt  # Windows
    except ImportError:
        msvcrt = None  # Unix/Linux/macOS

    # Legacy function implementations (fallback only)
    def display_banner(
        script_name: str,
        version: str,
        description: str,
        no_banner_flag: bool = False,
        quiet_mode: bool = False,
    ) -> None:
        """
        Display standardized banner for media library tools.

        Args:
            script_name: Name of the script
            version: Version string
            description: Brief description of the script
            no_banner_flag: If True, suppress banner display
            quiet_mode: If True, suppress banner display
        """
        # Check suppression conditions (highest to lowest priority)
        if no_banner_flag or quiet_mode or is_non_interactive():
            return

        try:
            # Display standardized ASCII art
            print("┏┳┓┏━╸╺┳┓╻┏━┓╻  ╻┏┓ ┏━┓┏━┓┏━┓╻ ╻╺┳╸┏━┓┏━┓╻  ┏━┓")
            print("┃┃┃┣╸  ┃┃┃┣━┫┃  ┃┣┻┓┣┳┛┣━┫┣┳┛┗┳┛ ┃ ┃ ┃┃ ┃┃  ┗━┓")
            print("╹ ╹┗━╸╺┻┛╹╹ ╹┗━╸╹┗━┛╹┗╸╹ ╹╹┗╸ ╹  ╹ ┗━┛┗━┛┗━╸┗━┛")
            print(f"{script_name} v{version}: {description}")
            print()  # Blank line for separation
        except Exception:
            # Banner display errors should not prevent script execution
            pass

    def is_non_interactive() -> bool:
        """
        Detect if running in non-interactive environment (cron, etc.).

        Returns:
            True if non-interactive, False otherwise
        """
        # Check if stdin is not a TTY (common in cron jobs)
        if not sys.stdin.isatty():
            return True

        # Check for common non-interactive environment variables
        non_interactive_vars = ["CRON", "CI", "AUTOMATED", "NON_INTERACTIVE"]
        for var in non_interactive_vars:
            if os.environ.get(var):
                return True

        # Check if TERM is not set or is 'dumb' (common in automated environments)
        term = os.environ.get("TERM", "")
        return bool(not term or term == "dumb")

    def read_global_config_bool(var_name: str, default: bool = False) -> bool:
        """
        Read a boolean environment variable with support for .env files.

        Args:
            var_name: Name of the environment variable
            default: Default value if not found

        Returns:
            Boolean value of the environment variable
        """
        # Check environment variable directly
        value = os.environ.get(var_name)
        if value is not None:
            return value.lower() in ("true", "1", "yes", "on")

        # Check local .env file
        env_file = ".env"
        if os.path.exists(env_file):
            try:
                with open(env_file) as f:
                    for line in f:
                        line = line.strip()
                        if line.startswith(f"{var_name}="):
                            value = line.split("=", 1)[1].strip()
                            return value.lower() in ("true", "1", "yes", "on")
            except OSError:
                pass

        # Check global .env file
        global_env_path = Path.home() / ".media-library-tools" / ".env"
        if global_env_path.exists():
            try:
                with open(global_env_path) as f:
                    for line in f:
                        line = line.strip()
                        if line.startswith(f"{var_name}="):
                            value = line.split("=", 1)[1].strip()
                            return value.lower() in ("true", "1", "yes", "on")
            except OSError:
                pass

        return default

    def is_windows() -> bool:
        """
        Detect if running on Windows platform.

        Returns:
            True if running on Windows, False otherwise
        """
        return platform.system().lower() == "windows"

    def should_use_emojis() -> bool:
        """
        Determine if emojis should be used based on platform and environment.

        Returns:
            True if emojis should be used, False otherwise
        """
        # Don't use emojis on Windows to avoid encoding issues
        if is_windows():
            return False

        # Don't use emojis in non-interactive environments
        if is_non_interactive():
            return False

        # Check for explicit emoji suppression
        return not read_global_config_bool("NO_EMOJIS", False)

    def format_size(size_bytes: int) -> str:
        """
        Format size in bytes to human readable format.

        Args:
            size_bytes: Size in bytes

        Returns:
            Human readable size string
        """
        for unit in ["B", "K", "M", "G", "T"]:
            if size_bytes < 1024.0:
                if unit == "B":
                    return f"{size_bytes:.0f}{unit}"
                else:
                    return f"{size_bytes:.1f}{unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.1f}P"

    def confirm_action(message: str, skip_confirmation: bool = False) -> bool:
        """
        Ask for user confirmation unless skipped.

        Args:
            message: Confirmation message to display
            skip_confirmation: If True, automatically confirm

        Returns:
            True if confirmed, False otherwise
        """
        if skip_confirmation:
            return True

        try:
            response = input(f"{message} (y/N): ").strip().lower()
            return response in ["y", "yes"]
        except (EOFError, KeyboardInterrupt):
            print("\nOperation cancelled.")
            return False

    class FileLock:
        """
        File locking utility class for preventing concurrent executions.
        """

        def __init__(self, lock_prefix: str = "media_library_tool"):
            """
            Initialize file lock.

            Args:
                lock_prefix: Prefix for lock file name
            """
            self.lock_prefix = lock_prefix
            self.lock_file = None

        def acquire_lock(self, force: bool = False) -> bool:
            """
            Acquire file lock to prevent multiple instances.

            Args:
                force: If True, skip locking mechanism

            Returns:
                True if lock acquired successfully, False otherwise
            """
            if force:
                return True

            try:
                with tempfile.NamedTemporaryFile(
                    mode="w",
                    prefix=f"{self.lock_prefix}_",
                    suffix=".lock",
                    delete=False,
                ) as temp_file:
                    self.lock_file = temp_file

                    # Platform-specific file locking
                    if fcntl is not None:  # Unix/Linux/macOS
                        fcntl.flock(
                            self.lock_file.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB
                        )
                    elif msvcrt is not None:  # Windows
                        msvcrt.locking(self.lock_file.fileno(), msvcrt.LK_NBLCK, 1)
                    else:
                        # Fallback: no locking available, just proceed
                        pass

                    self.lock_file.write(str(os.getpid()))
                    self.lock_file.flush()
                return True
            except OSError as e:
                if self.lock_file:
                    self.lock_file.close()
                    with contextlib.suppress(OSError):
                        os.unlink(self.lock_file.name)
                    self.lock_file = None
                print(
                    "Error: Another instance is already running. Use --force to override."
                )
                print(f"Lock error: {e}")
                return False

        def release_lock(self) -> None:
            """
            Release the file lock.
            """
            if self.lock_file:
                try:
                    # Only unlock if file is still open
                    if not self.lock_file.closed:
                        # Platform-specific file unlocking
                        if fcntl is not None:  # Unix/Linux/macOS
                            fcntl.flock(self.lock_file.fileno(), fcntl.LOCK_UN)
                        elif msvcrt is not None:  # Windows
                            msvcrt.locking(self.lock_file.fileno(), msvcrt.LK_UNLCK, 1)
                        # No explicit unlock needed for fallback case

                        self.lock_file.close()
                except (OSError, ValueError):
                    # Handle both file system errors and closed file errors
                    pass

                # Always try to remove lock file if it exists
                try:
                    if os.path.exists(self.lock_file.name):
                        os.unlink(self.lock_file.name)
                except OSError:
                    pass
                finally:
                    self.lock_file = None

    # Legacy standalone functions for backward compatibility
    def acquire_lock(
        lock_prefix: str = "media_library_tool", force: bool = False
    ) -> Tuple[bool, Optional[FileLock]]:
        """
        Legacy function for acquiring file locks.

        Args:
            lock_prefix: Prefix for lock file name
            force: If True, skip locking mechanism

        Returns:
            Tuple of (success: bool, lock_instance: FileLock or None)
        """
        lock = FileLock(lock_prefix)
        success = lock.acquire_lock(force)
        return success, lock if success else None

    def release_lock(lock_instance: FileLock) -> None:
        """
        Legacy function for releasing file locks.

        Args:
            lock_instance: FileLock instance to release
        """
        if lock_instance:
            lock_instance.release_lock()

    def format_status_message(
        message: str, emoji: str = "", fallback_prefix: str = ""
    ) -> str:
        """
        Format a status message with emoji on supported platforms or fallback text.

        Args:
            message: The main message text
            emoji: The emoji to use on supported platforms
            fallback_prefix: Text prefix to use instead of emoji on unsupported platforms

        Returns:
            Formatted message string
        """
        if should_use_emojis() and emoji:
            return f"{emoji} {message}"
        elif fallback_prefix:
            return f"{fallback_prefix}: {message}"
        else:
            return message

    # Add any missing functions that might be needed for backward compatibility
    def get_directory_size(path: str) -> int:
        """Legacy fallback for directory size calculation."""
        total_size = 0
        try:
            for dirpath, _dirnames, filenames in os.walk(path):
                for filename in filenames:
                    filepath = os.path.join(dirpath, filename)
                    try:
                        total_size += os.path.getsize(filepath)
                    except OSError:
                        continue
        except OSError:
            pass
        return total_size

    def validate_directory_path(path: str) -> Tuple[bool, str]:
        """Legacy fallback for directory path validation."""
        if not path:
            return False, "Path cannot be empty"

        path_obj = Path(path)

        if not path_obj.exists():
            return False, f"Path does not exist: {path}"

        if not path_obj.is_dir():
            return False, f"Path is not a directory: {path}"

        return True, ""

    def validate_path_argument(path: str) -> Tuple[bool, str]:
        """Legacy fallback for path argument validation."""
        return validate_directory_path(path)


# ======================================================
# INJECTED MODULE - END
# Source: utils.py
# ======================================================



# ======================================================

# ======================================================
# INJECTED MODULE - START
# Generated by build.py v3.0.0
# Source: lib/cleanup.py
# ======================================================

"""
System Trash File Cleanup Module

Centralized cleanup utilities for removing system-generated trash files
that commonly cause issues with media library tools, especially files
transferred via rsync or network shares.

Common Issues Solved:
- .DS_Store files from macOS causing directory conflicts
- Thumbs.db files from Windows
- ._ AppleDouble files from macOS resource forks
- Desktop.ini files from Windows
- Other hidden system files

Author: Media Library Tools Project
Version: 1.0.0
"""

import os
from pathlib import Path
from typing import List, Optional, Set


class SystemTrashCleaner:
    """
    Handles detection and removal of system-generated trash files.

    These files are commonly created by operating systems and can cause
    conflicts during media library operations, especially after rsync
    transfers or network share access.
    """

    # System trash file patterns
    TRASH_FILES = {
        '.DS_Store',        # macOS Finder metadata
        'Thumbs.db',        # Windows thumbnail cache
        'Desktop.ini',      # Windows folder settings
        '.Spotlight-V100',  # macOS Spotlight index
        '.Trashes',         # macOS trash folder
        '.fseventsd',       # macOS file system events
        '.TemporaryItems',  # macOS temporary items
        '.localized',       # macOS localization
        'desktop.ini',      # Windows (lowercase variant)
        'thumbs.db',        # Windows (lowercase variant)
    }

    # Patterns for prefixed trash files
    TRASH_PREFIXES = {
        '._',               # macOS AppleDouble resource fork files
        '.~',               # Temporary/backup files
    }

    # Patterns for suffixed trash files
    TRASH_SUFFIXES = {
        '.tmp',             # Temporary files
        '.temp',            # Temporary files (variant)
        '~',                # Backup files
    }

    def __init__(self, verbose: bool = False, dry_run: bool = False):
        """
        Initialize the trash cleaner.

        Args:
            verbose: Enable verbose output
            dry_run: Preview mode - don't actually delete files
        """
        self.verbose = verbose
        self.dry_run = dry_run
        self.removed_files: List[Path] = []
        self.failed_removals: List[tuple] = []

    def is_trash_file(self, file_path: Path) -> bool:
        """
        Determine if a file is system trash.

        Args:
            file_path: Path to check

        Returns:
            True if file matches trash patterns
        """
        filename = file_path.name

        # Check exact matches
        if filename in self.TRASH_FILES:
            return True

        # Check prefixes
        for prefix in self.TRASH_PREFIXES:
            if filename.startswith(prefix):
                return True

        # Check suffixes
        for suffix in self.TRASH_SUFFIXES:
            if filename.endswith(suffix):
                return True

        return False

    def clean_directory(self, directory: Path, recursive: bool = False) -> int:
        """
        Clean trash files from a directory.

        Args:
            directory: Directory to clean
            recursive: Also clean subdirectories

        Returns:
            Number of files removed
        """
        if not directory.exists() or not directory.is_dir():
            if self.verbose:
                print(f"Directory does not exist or is not a directory: {directory}")
            return 0

        removed_count = 0

        try:
            if recursive:
                # Walk entire directory tree
                for root, dirs, files in os.walk(directory):
                    root_path = Path(root)

                    # Clean files in this directory
                    for filename in files:
                        file_path = root_path / filename
                        if self.is_trash_file(file_path):
                            if self._remove_file(file_path):
                                removed_count += 1

                    # Clean trash directories
                    for dirname in dirs[:]:  # Copy list to allow modification
                        dir_path = root_path / dirname
                        if dirname in self.TRASH_FILES:
                            if self._remove_directory(dir_path):
                                removed_count += 1
                                dirs.remove(dirname)  # Don't descend into removed dir
            else:
                # Only clean current directory
                for item in directory.iterdir():
                    if item.is_file() and self.is_trash_file(item):
                        if self._remove_file(item):
                            removed_count += 1
                    elif item.is_dir() and item.name in self.TRASH_FILES:
                        if self._remove_directory(item):
                            removed_count += 1

        except PermissionError as e:
            if self.verbose:
                print(f"Permission denied accessing {directory}: {e}")
        except Exception as e:
            if self.verbose:
                print(f"Error cleaning {directory}: {e}")

        return removed_count

    def _remove_file(self, file_path: Path) -> bool:
        """
        Remove a single trash file.

        Args:
            file_path: File to remove

        Returns:
            True if removed successfully
        """
        if self.dry_run:
            if self.verbose:
                print(f"[DRY RUN] Would remove: {file_path}")
            self.removed_files.append(file_path)
            return True

        try:
            os.remove(file_path)
            self.removed_files.append(file_path)
            if self.verbose:
                print(f"Removed: {file_path}")
            return True
        except OSError as e:
            self.failed_removals.append((file_path, str(e)))
            if self.verbose:
                print(f"Error removing {file_path}: {e}")
            return False

    def _remove_directory(self, dir_path: Path) -> bool:
        """
        Remove a trash directory.

        Args:
            dir_path: Directory to remove

        Returns:
            True if removed successfully
        """
        if self.dry_run:
            if self.verbose:
                print(f"[DRY RUN] Would remove directory: {dir_path}")
            self.removed_files.append(dir_path)
            return True

        try:
            import shutil
            shutil.rmtree(dir_path)
            self.removed_files.append(dir_path)
            if self.verbose:
                print(f"Removed directory: {dir_path}")
            return True
        except OSError as e:
            self.failed_removals.append((dir_path, str(e)))
            if self.verbose:
                print(f"Error removing directory {dir_path}: {e}")
            return False

    def get_stats(self) -> dict:
        """
        Get cleanup statistics.

        Returns:
            Dictionary with cleanup stats
        """
        return {
            'files_removed': len(self.removed_files),
            'failed_removals': len(self.failed_removals),
            'removed_list': [str(p) for p in self.removed_files],
            'failed_list': [(str(p), e) for p, e in self.failed_removals]
        }

    def print_summary(self) -> None:
        """Print cleanup summary."""
        stats = self.get_stats()

        if self.dry_run:
            print(f"\n[DRY RUN] Would remove {stats['files_removed']} trash files")
        else:
            print(f"\nRemoved {stats['files_removed']} trash files")

        if stats['failed_removals'] > 0:
            print(f"Failed to remove {stats['failed_removals']} files")
            if self.verbose:
                print("\nFailed removals:")
                for path, error in stats['failed_list']:
                    print(f"  {path}: {error}")


def quick_clean(directory: Path, recursive: bool = False,
                verbose: bool = False, dry_run: bool = False) -> int:
    """
    Quick cleanup function for simple use cases.

    Args:
        directory: Directory to clean
        recursive: Clean subdirectories
        verbose: Show detailed output
        dry_run: Preview mode

    Returns:
        Number of files removed

    Example:
        >>> from pathlib import Path
        >>> import lib.cleanup as cleanup
        >>> removed = cleanup.quick_clean(Path('.'), recursive=True, verbose=True)
    """
    cleaner = SystemTrashCleaner(verbose=verbose, dry_run=dry_run)
    count = cleaner.clean_directory(directory, recursive=recursive)

    if verbose:
        cleaner.print_summary()

    return count



# ======================================================
# INJECTED MODULE - END
# Source: lib/cleanup.py
# ======================================================



# ======================================================

# ======================================================
# INJECTED MODULE - START
# Generated by build.py v3.0.0
# Source: lib/season_detection.py
# ======================================================

"""
Season Detection Module for Media Library Tools
Version: 1.0

Shared season detection logic extracted from plex_make_seasons with advanced
multi-stage validation, confidence scoring, and comprehensive pattern matching.

Features:
- 19 season detection patterns with priority ordering
- Multi-stage validation with confidence scoring
- Pattern-specific validation for different season types
- Quality indicator detection (prevents false positives)
- Position-based validation (relative position in filename)
- Range validation (different ranges for different pattern types)
- Extended season support (S100-S2050 for long-running shows)
- Year-based seasons (1990-2099 with special handling)
- Episode/Part/Chapter/Disc/Volume patterns
- Comprehensive statistics tracking

This module provides the shared interface and logic for both plex_make_seasons
and plex_make_all_seasons scripts, eliminating code duplication while providing
advanced detection capabilities.
"""

import re
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Tuple, Any


@dataclass
class SeasonPatternDefinitions:
    """
    Centralized season pattern definitions with metadata.

    All patterns are ordered by specificity and priority to ensure
    the most accurate match is found first.
    """

    # Standard patterns (highest priority) - S01E01, Season 1
    STANDARD_PATTERNS: List[Tuple[str, str]] = field(default_factory=lambda: [
        (r'[Ss](\d{1,2})[Ee]\d{1,3}', 'S{:02d}E format'),
        (r'[Ss]eason[\s\._-]*(\d{1,2})', 'Season X format'),
    ])

    # Extended season patterns (high priority) - S100+
    EXTENDED_PATTERNS: List[Tuple[str, str]] = field(default_factory=lambda: [
        (r'[Ss](\d{3,4})[Ee]\d{1,3}', 'Extended season S###/####E## format'),
        (r'[Ss]eason[\s\._-]*(\d{3,4})', 'Extended Season #### format'),
    ])

    # Enhanced alternative patterns (medium-high priority)
    ENHANCED_ALTERNATIVE: List[Tuple[str, str]] = field(default_factory=lambda: [
        (r'(\d{1,3})x\d{1,3}', 'Enhanced season #x# format'),
        (r'[Ss](\d{1,4})\D', 'Enhanced S# format'),
    ])

    # Numeric-only patterns (medium priority)
    NUMERIC_ONLY: List[Tuple[str, str]] = field(default_factory=lambda: [
        (r'(?:ep|episode)[\s\-_.]*(\d{1,2})(?:[^\d]|$)', 'Episode-prefixed numeric format'),
        (r'(?:^|[\s\-_.])[^\d]*[\s\-_.](\d{1,2})[\s\-_.](?!\d*(?:p|fps|kbps))', 'Separated numeric format'),
    ])

    # Year-based seasons (special handling)
    YEAR_BASED: List[Tuple[str, str]] = field(default_factory=lambda: [
        (r'[\(\[]?(20\d{2})[\)\]]?', 'Year format'),
    ])

    # Episode/media patterns (various priorities)
    EPISODE_PATTERNS: List[Tuple[str, str]] = field(default_factory=lambda: [
        # Episode numbering patterns
        (r'[Ee]pisode[\s\._-]*(\d{1,3})', 'Episode X format'),
        (r'[Ee]p[\s\._-]*(\d{1,3})', 'Ep X format'),
        # Part/Chapter patterns
        (r'[Pp]art[\s\._-]*(\d{1,2})', 'Part X format'),
        (r'[Cc]hapter[\s\._-]*(\d{1,2})', 'Chapter X format'),
        # Disc patterns
        (r'[Dd]isc[\s\._-]*(\d{1,2})', 'Disc X format'),
        (r'[Dd](\d{1,2})', 'D1 format'),
        # Volume patterns
        (r'[Vv]ol[\s\._-]*(\d{1,2})', 'Vol X format'),
        (r'[Vv](\d{1,2})', 'V1 format'),
    ])

    def get_all_patterns(self) -> List[Tuple[str, str]]:
        """
        Get all patterns in priority order.

        Returns:
            List of (regex, description) tuples
        """
        return (
            self.STANDARD_PATTERNS +
            self.EXTENDED_PATTERNS +
            self.ENHANCED_ALTERNATIVE +
            self.YEAR_BASED +
            self.EPISODE_PATTERNS +
            self.NUMERIC_ONLY
        )


class SeasonValidationEngine:
    """
    Multi-stage validation engine for season detection.

    Provides sophisticated validation including:
    - Quality indicator detection
    - Position-based confidence scoring
    - Range validation by pattern type
    - Context character analysis
    """

    # Quality indicators that should be rejected
    QUALITY_PATTERNS = [
        r'720p', r'1080p', r'480p', r'2160p', r'4K',
        r'\d+kbps', r'\d+fps', r'HDR', r'DTS', r'AC3',
        r'H\.?264', r'H\.?265', r'x264', r'x265',
        r'HEVC', r'AVC', r'BluRay', r'WEBRip', r'DVDRip'
    ]

    # Positive indicators for season detection
    POSITIVE_INDICATORS = ['ep', 'episode', 'season', 'series', '-', '_', '.', ' ']

    # Negative indicators that reduce confidence
    NEGATIVE_INDICATORS = ['p', 'fps', 'kbps', 'bit', 'mb', 'gb']

    def detect_quality_indicators(self, filename: str) -> bool:
        """
        Detect if filename contains quality indicators.

        Args:
            filename: Filename to check

        Returns:
            True if quality indicators detected, False otherwise
        """
        filename_lower = filename.lower()
        for pattern in self.QUALITY_PATTERNS:
            if re.search(pattern, filename_lower, re.IGNORECASE):
                return True
        return False

    def validate_position(self, filename: str, match_pos: int) -> float:
        """
        Calculate position-based confidence adjustment.

        Args:
            filename: Full filename
            match_pos: Position of match in filename

        Returns:
            Confidence adjustment value
        """
        filename_length = len(filename)
        if filename_length == 0:
            return 0.0

        relative_position = match_pos / filename_length

        if relative_position > 0.7:  # Changed from 0.8 to 0.7 to be more strict
            return -0.5  # Late in filename, likely not season
        elif relative_position < 0.3:
            return 0.3   # Early in filename, likely season
        else:
            return 0.0   # Middle position, neutral

    def validate_range_by_pattern(self, season_num: int, pattern_desc: str) -> bool:
        """
        Validate season number range based on pattern type.

        Args:
            season_num: Season number to validate
            pattern_desc: Pattern description

        Returns:
            True if valid range, False otherwise
        """
        if 'Extended' in pattern_desc:
            return 100 <= season_num <= 2050
        elif 'numeric' in pattern_desc.lower():
            return 1 <= season_num <= 50
        elif 'Enhanced' in pattern_desc:
            if 'S#' in pattern_desc:
                return 1 <= season_num <= 2050
            elif '#x#' in pattern_desc:
                return 1 <= season_num <= 500
        elif 'Year format' in pattern_desc:
            return season_num >= 1990
        else:
            return 1 <= season_num <= 50

    def calculate_confidence_score(self, filename: str, match_text: str,
                                   season_num: int, pattern_desc: str) -> float:
        """
        Calculate comprehensive confidence score for a match.

        Args:
            filename: Full filename
            match_text: Matched text from pattern
            season_num: Extracted season number
            pattern_desc: Pattern description

        Returns:
            Confidence score (0.0-1.0)
        """
        confidence = 0.0

        # Position-based adjustment
        match_pos = filename.find(match_text)
        confidence += self.validate_position(filename, match_pos)

        # Range-based confidence boost
        if 'Extended' in pattern_desc:
            confidence += 0.4
        elif 'numeric' in pattern_desc.lower():
            confidence += 0.2
        elif 'Enhanced' in pattern_desc:
            confidence += 0.3

        # Context character analysis
        filename_length = len(filename)
        context_start = max(0, match_pos - 3)
        context_end = min(filename_length, match_pos + len(match_text) + 3)
        context = filename[context_start:context_end].lower()

        for indicator in self.POSITIVE_INDICATORS:
            if indicator in context:
                confidence += 0.1

        for indicator in self.NEGATIVE_INDICATORS:
            if indicator in context:
                confidence -= 0.2

        # Filename structure analysis
        if any(sep in filename for sep in [' - ', '.', '_', 'S0', 's0', 'Season', 'season']):
            confidence += 0.2

        # Clamp to valid range
        return max(0.0, min(1.0, confidence))

    def validate_numeric_season(self, filename: str, match_text: str,
                               season_num: int, pattern_desc: str) -> Tuple[bool, float]:
        """
        Validate that a numeric match represents a season.

        Args:
            filename: Full filename
            match_text: Matched text from pattern
            season_num: Extracted season number
            pattern_desc: Pattern description

        Returns:
            Tuple of (is_valid, confidence_score)
        """
        # Check for quality indicators first
        if self.detect_quality_indicators(filename):
            return False, 0.0

        # Validate range
        if not self.validate_range_by_pattern(season_num, pattern_desc):
            return False, 0.0

        # Calculate confidence
        confidence = self.calculate_confidence_score(filename, match_text, season_num, pattern_desc)

        # Apply minimum confidence threshold
        min_confidence = 0.3 if 'numeric' in pattern_desc.lower() else 0.2

        return confidence >= min_confidence, confidence


class BaseSeasonDetector:
    """
    Base class for season detection shared between plex scripts.

    Provides common season detection interface and functionality that can be
    inherited by script-specific organizer classes.
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        Initialize season detector with configuration.

        Args:
            config: Configuration dictionary (optional)
        """
        self.config = config or {}
        self.patterns = SeasonPatternDefinitions()
        self.validator = SeasonValidationEngine()
        self.season_patterns = self.patterns.get_all_patterns()

        # Statistics tracking
        self.stats = {
            'season_patterns_found': {},
            'validation_results': {},
            'confidence_scores': []
        }

    def extract_season_info(self, filename: str) -> Tuple[Optional[int], str, str]:
        """
        Extract season information from filename.

        Args:
            filename: Filename to analyze

        Returns:
            Tuple of (season_number, pattern_description, matched_text)
            Returns (None, "No pattern matched", "") if no match found
        """
        for pattern, description in self.season_patterns:
            match = re.search(pattern, filename, re.IGNORECASE)
            if match:
                try:
                    season_num = int(match.group(1))
                    matched_text = match.group(0)

                    # Pattern-specific validation
                    if 'Year format' in description:
                        if season_num >= 1990:
                            self._track_pattern_usage(description, True)
                            return season_num, description, matched_text
                    elif 'Extended' in description:
                        if 100 <= season_num <= 2050:
                            self._track_pattern_usage(description, True)
                            return season_num, description, matched_text
                    elif 'numeric' in description.lower():
                        is_valid, confidence = self.validator.validate_numeric_season(
                            filename, matched_text, season_num, description)
                        if is_valid:
                            self._track_pattern_usage(description, True)
                            self.stats['confidence_scores'].append(confidence)
                            return season_num, description, matched_text
                    elif 'Enhanced' in description:
                        if 'S#' in description and 1 <= season_num <= 2050:
                            self._track_pattern_usage(description, True)
                            return season_num, description, matched_text
                        elif '#x#' in description and 1 <= season_num <= 500:
                            self._track_pattern_usage(description, True)
                            return season_num, description, matched_text
                    elif 1 <= season_num <= 50:
                        self._track_pattern_usage(description, True)
                        return season_num, description, matched_text

                except (ValueError, IndexError):
                    continue

        self._track_pattern_usage("No pattern matched", False)
        return None, "No pattern matched", ""

    def generate_season_directory_name(self, season_num: int, pattern_desc: str) -> str:
        """
        Generate season directory name based on season number and pattern.

        Args:
            season_num: Season number
            pattern_desc: Pattern description

        Returns:
            Season directory name (e.g., "Season 01" or "Season 100")
        """
        if 'Year format' in pattern_desc:
            return f"Season {season_num}"
        elif 'Extended' in pattern_desc or season_num >= 100:
            return f"Season {season_num}"
        else:
            return f"Season {season_num:02d}"

    def get_season_patterns(self) -> List[Tuple[str, str]]:
        """
        Get all season patterns.

        Returns:
            List of (regex, description) tuples
        """
        return self.season_patterns

    def _track_pattern_usage(self, pattern_desc: str, success: bool) -> None:
        """
        Track pattern usage for statistics.

        Args:
            pattern_desc: Pattern description
            success: Whether pattern matched successfully
        """
        if pattern_desc not in self.stats['season_patterns_found']:
            self.stats['season_patterns_found'][pattern_desc] = 0

        if success:
            self.stats['season_patterns_found'][pattern_desc] += 1

    def get_detection_stats(self) -> Dict[str, Any]:
        """
        Get comprehensive detection statistics.

        Returns:
            Dictionary of statistics
        """
        return {
            'patterns_found': dict(self.stats['season_patterns_found']),
            'total_patterns_used': len([k for k, v in self.stats['season_patterns_found'].items() if v > 0]),
            'average_confidence': (
                sum(self.stats['confidence_scores']) / len(self.stats['confidence_scores'])
                if self.stats['confidence_scores'] else 0.0
            )
        }


# ======================================================
# INJECTED MODULE - END
# Source: lib/season_detection.py
# ======================================================



# ======================================================











class SeasonOrganizer(BaseSeasonDetector):
    """Organizes video files into season directories."""

    def __init__(self, dry_run: bool = False, depth: int = 1, enable_cleanup: bool = False, verbose: bool = False):
        # Initialize base season detector
        super().__init__(config={})

        self.dry_run = dry_run
        self.depth = depth
        self.enable_cleanup = enable_cleanup
        self.verbose = verbose
        self.video_extensions = {
            '.mp4', '.avi', '.mkv', '.mov', '.wmv', '.flv', '.webm',
            '.m4v', '.mpg', '.mpeg', '.3gp', '.ogv', '.ts', '.m2ts'
        }

        # Episode extraction patterns (for episode numbers)
        self.episode_patterns = [
            re.compile(r'[Ss]\d{1,4}[Ee](\d{1,3})', re.IGNORECASE),  # S01E05
            re.compile(r'Episode\s*(\d{1,3})', re.IGNORECASE),       # Episode 5
            re.compile(r'\d{1,3}x(\d{1,3})', re.IGNORECASE),         # 1x05
        ]
    
    def is_video_file(self, file_path: Path) -> bool:
        """Check if file is a video file based on extension."""
        return file_path.suffix.lower() in self.video_extensions
    
    def find_video_files_with_depth(self, source_dir: Path, max_depth: int) -> List[Path]:
        """Find video files up to a specified depth in the directory structure.
        
        Args:
            source_dir: The directory to search in
            max_depth: Maximum depth to search (1 = only immediate files, 2 = immediate subdirs, etc.)
            
        Returns:
            List of Path objects for video files found within the depth limit
        """
        video_files = []
        
        # Use a queue-based approach to avoid recursion limits
        # Each item in the queue is a tuple of (directory_path, current_depth)
        queue = [(source_dir, 1)]
        
        while queue:
            current_dir, current_depth = queue.pop(0)
            
            # Skip if we've exceeded the maximum depth
            if current_depth > max_depth:
                continue
                
            try:
                # Iterate through items in the current directory
                for item in current_dir.iterdir():
                    if item.is_file() and self.is_video_file(item):
                        # Found a video file
                        video_files.append(item)
                    elif item.is_dir() and current_depth < max_depth:
                        # Add subdirectory to queue for processing
                        queue.append((item, current_depth + 1))
            except (PermissionError, OSError) as e:
                # Skip directories we can't access
                print(f"  Warning: Cannot access directory {current_dir}: {e}")
                continue
                
        return video_files
    
    def extract_episode_number(self, filename: str) -> Optional[int]:
        """Extract episode number from filename."""
        for pattern in self.episode_patterns:
            match = pattern.search(filename)
            if match:
                try:
                    return int(match.group(1))
                except (ValueError, IndexError):
                    continue
        return None

    def extract_season_episode(self, filename: str) -> Tuple[Optional[int], Optional[int]]:
        """Extract season and episode numbers from filename.

        Uses shared BaseSeasonDetector for season extraction and local patterns for episodes.
        """
        # Extract season using shared module
        season_num, description, matched_text = self.extract_season_info(filename)

        # Extract episode using local patterns
        episode_num = self.extract_episode_number(filename)

        return season_num, episode_num
    
    def generate_unique_filename(self, target_path: Path) -> Path:
        """Generate unique filename if collision exists."""
        if not target_path.exists():
            return target_path
        
        base_name = target_path.stem
        extension = target_path.suffix
        parent = target_path.parent
        counter = 1
        
        while True:
            new_name = f"{base_name}_{counter}{extension}"
            new_path = parent / new_name
            if not new_path.exists():
                return new_path
            counter += 1
    
    def organize_directory(self, show_dir: Path) -> Dict[str, Union[int, List[str]]]:
        """Organize a single TV show directory."""
        stats = {
            'total_files': 0,
            'moved_files': 0,
            'skipped_files': 0,
            'created_seasons': 0,
            'errors': []
        }
        
        if not show_dir.is_dir():
            stats['errors'].append(f"Not a directory: {show_dir}")
            return stats
        
        try:
            # Get all video files up to the specified depth
            video_files = self.find_video_files_with_depth(show_dir, self.depth)
            
            stats['total_files'] = len(video_files)
            
            if not video_files:
                return stats
            
            created_seasons = set()
            
            for video_file in video_files:
                try:
                    season_num, episode_num = self.extract_season_episode(video_file.name)
                    
                    if season_num is None:
                        stats['skipped_files'] += 1
                        if not self.dry_run:
                            print(f"  Skipping (no season pattern): {video_file.name}")
                        continue
                    
                    # Create season directory
                    season_dir_name = f"Season {season_num}"
                    season_dir = show_dir / season_dir_name
                    
                    if not season_dir.exists():
                        if season_dir_name not in created_seasons:
                            if self.dry_run:
                                print(f"  [DRY RUN] Would create: {season_dir_name}")
                            else:
                                season_dir.mkdir(exist_ok=True)
                                print(f"  Created: {season_dir_name}")
                            created_seasons.add(season_dir_name)
                            stats['created_seasons'] += 1
                    
                    # Determine target file path
                    target_file = season_dir / video_file.name
                    
                    # Handle collisions
                    if target_file.exists():
                        original_target = target_file
                        target_file = self.generate_unique_filename(target_file)
                        if not self.dry_run:
                            print(f"  Collision detected: {video_file.name}")
                            print(f"    Renaming to: {target_file.name}")
                    
                    # Move the file
                    if self.dry_run:
                        print(f"  [DRY RUN] Would move: {video_file.name} → {season_dir_name}/{target_file.name}")
                        stats['moved_files'] += 1
                    else:
                        shutil.move(str(video_file), str(target_file))
                        print(f"  Moved: {video_file.name} → {season_dir_name}/{target_file.name}")
                        stats['moved_files'] += 1
                
                except Exception as e:
                    stats['errors'].append(f"Error processing {video_file.name}: {e}")
                    stats['skipped_files'] += 1
        
        except Exception as e:
            stats['errors'].append(f"Error processing directory {show_dir}: {e}")
        
        return stats


class PlexSeasonBatchOrganizer:
    """Main class for batch season organization."""

    def __init__(self, dry_run: bool = False, force: bool = False,
                 max_workers: int = 4, recursive: bool = False, depth: int = 1,
                 enable_cleanup: bool = False, verbose: bool = False):
        self.dry_run = dry_run
        self.force = force
        self.max_workers = max_workers
        self.recursive = recursive
        self.depth = depth
        self.enable_cleanup = enable_cleanup
        self.verbose = verbose
        self.file_lock = FileLock('plex_make_all_seasons')
        self.organizer = SeasonOrganizer(
            dry_run=dry_run,
            depth=depth,
            enable_cleanup=enable_cleanup,
            verbose=verbose
        )
    
    def acquire_lock(self) -> bool:
        """Acquire file lock to prevent multiple instances."""
        return self.file_lock.acquire_lock(self.force)
    
    def release_lock(self) -> None:
        """Release the file lock."""
        self.file_lock.release_lock()
    
    def find_show_directories(self, base_dir: Path) -> List[Path]:
        """Find all show directories to process."""
        show_dirs = []
        
        try:
            if self.recursive:
                # Recursively find directories with video files
                for item in base_dir.rglob('*'):
                    if (item.is_dir() and 
                        any(f.is_file() and self.organizer.is_video_file(f) 
                            for f in item.iterdir())):
                        show_dirs.append(item)
            else:
                # Only immediate subdirectories
                for item in base_dir.iterdir():
                    if item.is_dir():
                        show_dirs.append(item)
        
        except Exception as e:
            print(f"Error scanning directories: {e}")
        
        return sorted(show_dirs)
    
    def process_show_sequential(self, show_dir: Path) -> Tuple[Path, Dict]:
        """Process a single show directory (for sequential processing)."""
        return show_dir, self.organizer.organize_directory(show_dir)
    
    def process_shows_parallel(self, show_dirs: List[Path]) -> List[Tuple[Path, Dict]]:
        """Process multiple show directories in parallel."""
        results = []
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # Submit all tasks
            future_to_dir = {
                executor.submit(self.organizer.organize_directory, show_dir): show_dir 
                for show_dir in show_dirs
            }
            
            # Collect results as they complete
            for future in concurrent.futures.as_completed(future_to_dir):
                show_dir = future_to_dir[future]
                try:
                    stats = future.result()
                    results.append((show_dir, stats))
                except Exception as e:
                    error_stats = {
                        'total_files': 0, 'moved_files': 0, 'skipped_files': 0,
                        'created_seasons': 0, 'errors': [f"Processing error: {e}"]
                    }
                    results.append((show_dir, error_stats))
        
        return results
    
    def print_summary(self, results: List[Tuple[Path, Dict]]) -> None:
        """Print comprehensive summary of processing results."""
        total_stats = {
            'directories_processed': len(results),
            'total_files': 0,
            'moved_files': 0,
            'skipped_files': 0,
            'created_seasons': 0,
            'directories_with_errors': 0,
            'total_errors': 0
        }
        
        print("\n" + "=" * 60)
        print("PROCESSING SUMMARY")
        print("=" * 60)
        
        for show_dir, stats in results:
            total_stats['total_files'] += stats['total_files']
            total_stats['moved_files'] += stats['moved_files']
            total_stats['skipped_files'] += stats['skipped_files']
            total_stats['created_seasons'] += stats['created_seasons']
            
            if stats['errors']:
                total_stats['directories_with_errors'] += 1
                total_stats['total_errors'] += len(stats['errors'])
                print(f"\n❌ {show_dir.name}:")
                for error in stats['errors']:
                    print(f"   Error: {error}")
            elif stats['moved_files'] > 0:
                print(f"\n✅ {show_dir.name}: {stats['moved_files']} files organized into {stats['created_seasons']} seasons")
            elif stats['total_files'] == 0:
                print(f"\n⚪ {show_dir.name}: No video files found")
            else:
                print(f"\n⚠️  {show_dir.name}: {stats['skipped_files']} files skipped (no season pattern)")
        
        print("\n" + "=" * 60)
        print("OVERALL STATISTICS")
        print("=" * 60)
        print(f"Directories processed: {total_stats['directories_processed']}")
        print(f"Total video files found: {total_stats['total_files']}")
        
        if self.dry_run:
            print(f"Files that would be moved: {total_stats['moved_files']}")
            print(f"Seasons that would be created: {total_stats['created_seasons']}")
        else:
            print(f"Files successfully moved: {total_stats['moved_files']}")
            print(f"Season directories created: {total_stats['created_seasons']}")
        
        print(f"Files skipped: {total_stats['skipped_files']}")
        print(f"Directories with errors: {total_stats['directories_with_errors']}")
        print(f"Total errors: {total_stats['total_errors']}")
        
        if total_stats['total_errors'] == 0:
            print("\n🎉 Processing completed successfully!")
        else:
            print("\n⚠️  Processing completed with errors. See details above.")
    
    def handle_confirmation(self, skip_confirmation: bool) -> bool:
        """Handle user confirmation for the operation."""
        # Confirmation prompt for non-dry-run operations
        if not self.dry_run and not skip_confirmation and not is_non_interactive():
            print("\nThis will organize video files into season directories.")
            print("Files will be moved to create proper Plex library structure.")
            try:
                response = input("\nDo you want to proceed? (yes/no): ").strip().lower()
                if response not in ['yes', 'y']:
                    print("Operation cancelled.")
                    return False
            except (EOFError, KeyboardInterrupt):
                print("\nOperation cancelled.")
                return False
        elif not self.dry_run and (skip_confirmation or is_non_interactive()):
            if skip_confirmation:
                print("Proceeding with season organization (--yes flag)...")
            else:
                print("Proceeding with season organization (non-interactive environment)...")
        
        return True

    def process_directories(self, show_dirs: List[Path]) -> List[Tuple[Path, Dict]]:
        """Process the directories either sequentially or in parallel."""
        start_time = time.time()
        
        if self.max_workers == 1:
            # Sequential processing
            results = []
            for i, show_dir in enumerate(show_dirs, 1):
                print(f"[{i}/{len(show_dirs)}] Processing: {show_dir.name}")
                result = self.process_show_sequential(show_dir)
                results.append(result)
        else:
            # Parallel processing
            print(f"Processing {len(show_dirs)} directories in parallel...")
            results = self.process_shows_parallel(show_dirs)
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        # Print summary
        self.print_summary(results)
        print(f"\nProcessing time: {processing_time:.2f} seconds")
        
        return results

    def process_directory(self, base_dir: Path, skip_confirmation: bool = False) -> bool:
        """Process all show directories in the base directory."""
        if not base_dir.exists():
            print(f"Error: Directory '{base_dir}' does not exist.")
            return False
        
        if not base_dir.is_dir():
            print(f"Error: '{base_dir}' is not a directory.")
            return False
        
        print(f"Processing TV shows in: {base_dir}")
        if self.recursive:
            print("RECURSIVE MODE - Processing all subdirectories")
        print(f"Using {self.max_workers} worker threads")

        # System trash cleanup (if enabled)
        if self.enable_cleanup:
            print("\nCleaning system trash files...")
            cleaner = SystemTrashCleaner(verbose=self.verbose, dry_run=self.dry_run)
            cleanup_count = cleaner.clean_directory(base_dir, recursive=True)

            if self.dry_run:
                print(f"Would remove {cleanup_count} trash files\n")
            else:
                print(f"Removed {cleanup_count} trash files\n")
        else:
            print()

        # Handle confirmation
        if not self.handle_confirmation(skip_confirmation):
            return False

        # Find all show directories
        show_dirs = self.find_show_directories(base_dir)
        
        if not show_dirs:
            print("No directories found to process.")
            return True
        
        print(f"Found {len(show_dirs)} directories to process:")
        for show_dir in show_dirs:
            print(f"  - {show_dir.name}")
        print()
        
        # Process directories
        self.process_directories(show_dirs)
        
        return True


def main():
    """Main function with argument parsing and execution."""
    parser = argparse.ArgumentParser(
        description="Plex Season Organizer (Batch) - Organize TV show episodes into season directories",
        epilog="""
Examples:
  %(prog)s /path/to/tv/shows                    # Preview changes (dry-run mode)
  %(prog)s /path/to/tv/shows --execute          # Actually organize files
  %(prog)s /path/to/tv/shows --execute -y       # Execute without confirmation
  %(prog)s /path/to/tv/shows --parallel 8       # Use 8 worker threads
  %(prog)s /path/to/tv/shows --recursive        # Process all subdirectories
  %(prog)s /path/to/tv/shows --depth 2 --execute # Search for files up to 2 levels deep
  %(prog)s /path/to/tv/shows --depth 3 --execute # Search for files up to 3 levels deep
  %(prog)s /path/to/tv/shows --verbose          # Show verbose output
  %(prog)s /path/to/tv/shows --debug            # Show debug output
  %(prog)s /path/to/tv/shows --force            # Force run (bypass lock)
  
Cron Usage:
  # Run daily at 3 AM (non-interactive)
  0 3 * * * /usr/local/bin/plex_make_all_seasons /path/to/tv/shows --execute -y
        """,
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        'directory',
        nargs='?',
        default='.',
        help='Base directory containing TV show directories (default: current directory)'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        default=True,
        help='Show what would be done without making changes (default: true)'
    )
    parser.add_argument(
        '--execute',
        action='store_true',
        help='Actually perform operations (overrides --dry-run)'
    )
    parser.add_argument(
        '-y', '--yes',
        action='store_true',
        help='Skip confirmation prompt (for non-interactive use)'
    )
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='Show verbose output'
    )
    parser.add_argument(
        '--debug',
        action='store_true',
        help='Show detailed debug output'
    )
    parser.add_argument(
        '--cleanup',
        action='store_true',
        help='Clean system trash files (.DS_Store, Thumbs.db, etc.) before processing'
    )
    parser.add_argument(
        '--force',
        action='store_true',
        help='Force execution even if another instance is running'
    )
    parser.add_argument(
        '--parallel', '--workers',
        type=int,
        default=4,
        metavar='N',
        help='Number of worker threads for parallel processing (default: 4, use 1 for sequential)'
    )
    parser.add_argument(
        '--recursive',
        action='store_true',
        help='Recursively process all subdirectories (not just immediate children)'
    )
    parser.add_argument(
        '--no-banner',
        action='store_true',
        help='Suppress banner display'
    )
    parser.add_argument(
        '--depth',
        type=int,
        default=1,
        help='Depth level for searching video files (default: 1). Use 2 or higher to search in subdirectories.'
    )
    parser.add_argument(
        '--version',
        action='version',
        version=f'%(prog)s v{VERSION}'
    )
    
    args = parser.parse_args()
    
    # Handle debug mode (enables verbose)
    if args.debug:
        args.verbose = True
    
    # Read global configuration
    auto_execute = read_global_config_bool('AUTO_EXECUTE', False)
    auto_confirm = read_global_config_bool('AUTO_CONFIRM', False)
    quiet_mode = read_global_config_bool('QUIET_MODE', False)
    
    # Apply global configuration (CLI arguments take precedence)
    if auto_execute and not args.execute:
        args.execute = True  # Set execute flag if AUTO_EXECUTE is set
    if auto_confirm and not args.yes:
        args.yes = True  # Set yes flag if AUTO_CONFIRM is set
    
    # Determine dry-run mode
    if args.execute:
        dry_run_mode = False
    else:
        dry_run_mode = args.dry_run  # This is True by default
    
    # Validate arguments
    if args.parallel < 1:
        print("Error: Number of workers must be at least 1")
        sys.exit(1)
    
    if args.yes and dry_run_mode:
        print("Warning: -y/--yes flag has no effect in dry-run mode", file=sys.stderr)
    
    # Display banner
    display_banner("plex_make_all_seasons", "2.1.0", 
                  "create season directories for TV shows with parallel processing support",
                  args.no_banner, quiet_mode)
    
    if dry_run_mode:
        print("DRY-RUN MODE: No changes will be made")
    else:
        print("EXECUTE MODE: Episodes will be organized")
    
    if args.debug:
        print("Debug: ENABLED")
    elif args.verbose:
        print("Verbose: ENABLED")
    print()
    
    # Create organizer instance
    organizer = PlexSeasonBatchOrganizer(
        dry_run=dry_run_mode,
        force=args.force,
        max_workers=args.parallel,
        recursive=args.recursive,
        depth=args.depth,
        enable_cleanup=args.cleanup,
        verbose=args.verbose or args.debug
    )
    
    try:
        # Acquire lock
        if not organizer.acquire_lock():
            sys.exit(1)
        
        # Process directory
        base_dir = Path(args.directory).resolve()
        success = organizer.process_directory(base_dir, skip_confirmation=args.yes)
        
        sys.exit(0 if success else 1)
        
    except KeyboardInterrupt:
        print("\nOperation cancelled by user.")
        sys.exit(1)
    except Exception as e:
        print(f"Error: {e}")
        sys.exit(1)
    finally:
        organizer.release_lock()


if __name__ == '__main__':
    main()