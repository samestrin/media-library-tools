#!/usr/bin/env python3
"""
Plex Directory Name Corrector

A comprehensive tool for sanitizing and organizing Plex media directory names.
This script processes directory names to ensure they follow Plex naming conventions
by removing unwanted tags, standardizing formats, and organizing files into directories.

Features:
- Enhanced regex patterns for comprehensive tag removal
- System trash cleanup (.DS_Store, Thumbs.db, etc.)
- Standardizes resolution and year formats
- Converts files to directory structure
- File-based locking mechanism
- Dry-run mode for safe testing
- Cron-friendly operation
- Global configuration via .env files

Author: Media Library Tools Project
Version: 2.2.0
"""

import argparse
import os
import re
import shutil
import sys
from pathlib import Path
from typing import List, Optional, Tuple

VERSION = "2.2.0"

# ======================================================

# ======================================================
# INJECTED MODULE - START
# Generated by build.py v3.0.0
# Source: lib/core.py
# ======================================================

"""
Core Utilities Module for Media Library Tools
Version: 1.0

This module contains essential utility functions including:
- Platform detection and environment handling
- Configuration management and global settings
- File locking mechanisms for concurrent execution
- Interactive mode detection for automation support

This is part of the modular library structure that enables selective inclusion
in built tools while maintaining the self-contained principle.
"""

import argparse
import contextlib
import os
import platform
import sys
import tempfile
import threading
import time
from pathlib import Path
from typing import Any, Dict, Optional, Tuple, Union

# Platform-specific imports
try:
    import fcntl  # Unix/Linux/macOS
except ImportError:
    fcntl = None  # Windows

try:
    import msvcrt  # Windows
except ImportError:
    msvcrt = None  # Unix/Linux/macOS


def is_non_interactive() -> bool:
    """
    Detect if running in non-interactive environment (cron, etc.).

    Returns:
        True if non-interactive, False otherwise
    """
    # Check if stdin is not a TTY (common in cron jobs)
    if not sys.stdin.isatty():
        return True

    # Check for common non-interactive environment variables
    non_interactive_vars = ["CRON", "CI", "AUTOMATED", "NON_INTERACTIVE"]
    for var in non_interactive_vars:
        if os.environ.get(var):
            return True

    # Check if TERM is not set or is 'dumb' (common in automated environments)
    term = os.environ.get("TERM", "")
    return bool(not term or term == "dumb")


def read_global_config_bool(var_name: str, default: bool = False) -> bool:
    """
    Read a boolean environment variable with support for .env files.

    DEPRECATED: This function is maintained for backward compatibility.
    New code should use read_config_bool() which supports CLI argument priority.

    Args:
        var_name: Name of the environment variable
        default: Default value if not found

    Returns:
        Boolean value of the environment variable
    """
    # Check environment variable directly
    value = os.environ.get(var_name)
    if value is not None:
        return value.lower() in ("true", "1", "yes", "on")

    # Check local .env file
    env_file = ".env"
    if os.path.exists(env_file):
        try:
            with open(env_file) as f:
                for line in f:
                    line = line.strip()
                    if line.startswith(f"{var_name}="):
                        value = line.split("=", 1)[1].strip()
                        return value.lower() in ("true", "1", "yes", "on")
        except OSError:
            pass

    # Check global .env file
    global_env_path = Path.home() / ".media-library-tools" / ".env"
    if global_env_path.exists():
        try:
            with open(global_env_path) as f:
                for line in f:
                    line = line.strip()
                    if line.startswith(f"{var_name}="):
                        value = line.split("=", 1)[1].strip()
                        return value.lower() in ("true", "1", "yes", "on")
        except OSError:
            pass

    return default


class ConfigCache:
    """
    Thread-safe configuration cache with TTL support.

    Caches configuration values from .env files to avoid repeated file system
    operations. Uses threading locks for thread safety.
    """

    def __init__(self, ttl_seconds: int = 300):
        """
        Initialize configuration cache.

        Args:
            ttl_seconds: Time-to-live for cached values in seconds (default: 300 = 5 minutes)
        """
        self._cache: Dict[str, Dict[str, str]] = {}
        self._cache_times: Dict[str, float] = {}
        self._lock = threading.Lock()
        self._ttl = ttl_seconds

    def get_env_file(self, file_path: str) -> Optional[Dict[str, str]]:
        """
        Get cached .env file contents or read from disk.

        Args:
            file_path: Path to .env file

        Returns:
            Dictionary of key-value pairs from .env file, or None if file doesn't exist
        """
        with self._lock:
            # Check if cached and not expired
            if file_path in self._cache:
                cache_time = self._cache_times.get(file_path, 0)
                if time.time() - cache_time < self._ttl:
                    return self._cache[file_path].copy()

            # Read from disk
            env_dict = self._read_env_file(file_path)
            if env_dict is not None:
                self._cache[file_path] = env_dict
                self._cache_times[file_path] = time.time()

            return env_dict.copy() if env_dict else None

    def _read_env_file(self, file_path: str) -> Optional[Dict[str, str]]:
        """
        Read .env file from disk.

        Args:
            file_path: Path to .env file

        Returns:
            Dictionary of key-value pairs, or None if file doesn't exist
        """
        if not os.path.exists(file_path):
            return None

        env_dict = {}
        try:
            with open(file_path, 'r') as f:
                for line in f:
                    line = line.strip()
                    # Skip empty lines and comments
                    if not line or line.startswith('#'):
                        continue
                    # Parse key=value pairs
                    if '=' in line:
                        key, value = line.split('=', 1)
                        key = key.strip()
                        value = value.strip()
                        # Remove quotes from values
                        if value and value[0] in ('"', "'") and value[-1] == value[0]:
                            value = value[1:-1]
                        env_dict[key] = value
        except OSError:
            return None

        return env_dict

    def clear_cache(self) -> None:
        """Clear all cached configuration values."""
        with self._lock:
            self._cache.clear()
            self._cache_times.clear()


# Global cache instance
_config_cache = ConfigCache()


def read_local_env_file(
    env_path: Optional[str] = None,
    use_cache: bool = True
) -> Dict[str, str]:
    """
    Read local .env file with optional caching.

    Args:
        env_path: Path to .env file (defaults to current directory .env)
        use_cache: Whether to use cache (default: True)

    Returns:
        Dictionary of key-value pairs from .env file
    """
    if env_path is None:
        env_path = ".env"

    if use_cache:
        result = _config_cache.get_env_file(env_path)
        return result if result is not None else {}
    else:
        # Direct read without cache
        result = _config_cache._read_env_file(env_path)
        return result if result is not None else {}


def read_config_value(
    key: str,
    cli_args: Optional[argparse.Namespace] = None,
    default: Optional[Union[str, bool, int]] = None,
    value_type: str = 'str',
    local_env_path: Optional[str] = None
) -> Union[str, bool, int, None]:
    """
    Read configuration value following CLI > ENV > Local .env > Global .env priority.

    Priority order (highest to lowest):
    1. CLI arguments (if cli_args provided and attribute exists)
    2. Environment variables
    3. Local .env file (current directory or specified path)
    4. Global .env file (~/.media-library-tools/.env)

    Args:
        key: Configuration key to read
        cli_args: Parsed CLI arguments namespace
        default: Default value if not found in any source
        value_type: Type conversion ('str', 'bool', 'int')
        local_env_path: Path to local .env file (defaults to current directory)

    Returns:
        Configuration value with proper type conversion, or default if not found

    Examples:
        >>> # Read boolean config with CLI priority
        >>> debug_mode = read_config_value('DEBUG', cli_args=args, default=False, value_type='bool')

        >>> # Read string config without CLI args
        >>> api_key = read_config_value('API_KEY', default='', value_type='str')
    """
    raw_value = None

    # 1. Check CLI arguments (highest priority)
    if cli_args is not None:
        # Try both exact key and lowercase version
        cli_attr = key.lower() if hasattr(cli_args, key.lower()) else key
        if hasattr(cli_args, cli_attr):
            cli_value = getattr(cli_args, cli_attr)
            if cli_value is not None:
                raw_value = str(cli_value)

    # 2. Check environment variable
    if raw_value is None:
        env_value = os.environ.get(key)
        if env_value is not None:
            raw_value = env_value

    # 3. Check local .env file
    if raw_value is None:
        local_env = read_local_env_file(local_env_path)
        if key in local_env:
            raw_value = local_env[key]

    # 4. Check global .env file
    if raw_value is None:
        global_env_path = str(Path.home() / ".media-library-tools" / ".env")
        global_env = read_local_env_file(global_env_path)
        if key in global_env:
            raw_value = global_env[key]

    # Use default if not found anywhere
    if raw_value is None:
        return default

    # Type conversion
    if value_type == 'bool':
        return raw_value.lower() in ('true', '1', 'yes', 'on')
    elif value_type == 'int':
        try:
            return int(raw_value)
        except (ValueError, TypeError):
            return default
    else:  # str
        return raw_value


def read_config_bool(
    key: str,
    cli_args: Optional[argparse.Namespace] = None,
    default: bool = False,
    local_env_path: Optional[str] = None
) -> bool:
    """
    Read boolean configuration value following CLI > ENV > Local .env > Global .env priority.

    Convenience wrapper around read_config_value for boolean values.
    Supports: true/false, yes/no, on/off, 1/0 (case-insensitive)

    Args:
        key: Configuration key to read
        cli_args: Parsed CLI arguments namespace
        default: Default value if not found (default: False)
        local_env_path: Path to local .env file (defaults to current directory)

    Returns:
        Boolean value

    Examples:
        >>> # Read debug flag with CLI priority
        >>> debug = read_config_bool('DEBUG', cli_args=args, default=False)

        >>> # Read auto-confirm setting
        >>> auto_confirm = read_config_bool('AUTO_CONFIRM', default=False)
    """
    result = read_config_value(
        key=key,
        cli_args=cli_args,
        default=default,
        value_type='bool',
        local_env_path=local_env_path
    )
    return bool(result)


def get_config_source(
    key: str,
    cli_args: Optional[argparse.Namespace] = None,
    local_env_path: Optional[str] = None
) -> str:
    """
    Determine which source provides a configuration value.

    Args:
        key: Configuration key to check
        cli_args: Parsed CLI arguments namespace
        local_env_path: Path to local .env file

    Returns:
        Source name: 'cli', 'env', 'local_env', 'global_env', or 'not_found'
    """
    # Check CLI arguments
    if cli_args is not None:
        cli_attr = key.lower() if hasattr(cli_args, key.lower()) else key
        if hasattr(cli_args, cli_attr):
            cli_value = getattr(cli_args, cli_attr)
            if cli_value is not None:
                return 'cli'

    # Check environment variable
    if os.environ.get(key) is not None:
        return 'env'

    # Check local .env
    local_env = read_local_env_file(local_env_path)
    if key in local_env:
        return 'local_env'

    # Check global .env
    global_env_path = str(Path.home() / ".media-library-tools" / ".env")
    global_env = read_local_env_file(global_env_path)
    if key in global_env:
        return 'global_env'

    return 'not_found'


def debug_config_resolution(
    key: str,
    cli_args: Optional[argparse.Namespace] = None,
    local_env_path: Optional[str] = None,
    show_value: bool = False
) -> None:
    """
    Print detailed configuration resolution information for debugging.

    Shows which sources contain the key and which source is being used.

    Args:
        key: Configuration key to debug
        cli_args: Parsed CLI arguments namespace
        local_env_path: Path to local .env file
        show_value: Whether to show actual value (default: False for security)
    """
    print(f"\nConfiguration Debug: {key}")
    print("=" * 60)

    # Check each source
    sources_found = []

    # CLI
    if cli_args is not None:
        cli_attr = key.lower() if hasattr(cli_args, key.lower()) else key
        if hasattr(cli_args, cli_attr):
            cli_value = getattr(cli_args, cli_attr)
            if cli_value is not None:
                sources_found.append('CLI')
                if show_value:
                    print(f"  CLI: {cli_value}")
                else:
                    print(f"  CLI: <set>")

    # ENV
    env_value = os.environ.get(key)
    if env_value is not None:
        sources_found.append('ENV')
        if show_value:
            print(f"  ENV: {env_value}")
        else:
            print(f"  ENV: <set>")

    # Local .env
    local_env = read_local_env_file(local_env_path)
    if key in local_env:
        sources_found.append('Local .env')
        if show_value:
            print(f"  Local .env: {local_env[key]}")
        else:
            print(f"  Local .env: <set>")

    # Global .env
    global_env_path = str(Path.home() / ".media-library-tools" / ".env")
    global_env = read_local_env_file(global_env_path)
    if key in global_env:
        sources_found.append('Global .env')
        if show_value:
            print(f"  Global .env: {global_env[key]}")
        else:
            print(f"  Global .env: <set>")

    # Show resolution
    print(f"\nResolution:")
    if sources_found:
        print(f"  Found in: {', '.join(sources_found)}")
        print(f"  Using: {sources_found[0]} (highest priority)")
    else:
        print(f"  Not found in any source")

    print("=" * 60)


def validate_config_setup() -> Dict[str, Any]:
    """
    Validate configuration setup and check for potential issues.

    Returns:
        Dictionary with validation results including:
        - 'valid': bool indicating overall validity
        - 'warnings': list of warning messages
        - 'info': list of informational messages
        - 'files': dict of file status (local_env, global_env)
    """
    results = {
        'valid': True,
        'warnings': [],
        'info': [],
        'files': {}
    }

    # Check local .env
    local_env_path = ".env"
    if os.path.exists(local_env_path):
        results['files']['local_env'] = 'exists'
        results['info'].append(f"Local .env file found: {os.path.abspath(local_env_path)}")

        # Check readability
        try:
            with open(local_env_path, 'r') as f:
                f.read()
        except OSError as e:
            results['warnings'].append(f"Local .env exists but cannot be read: {e}")
            results['valid'] = False
    else:
        results['files']['local_env'] = 'not_found'
        results['info'].append("No local .env file found")

    # Check global .env
    global_env_path = Path.home() / ".media-library-tools" / ".env"
    if global_env_path.exists():
        results['files']['global_env'] = 'exists'
        results['info'].append(f"Global .env file found: {global_env_path}")

        # Check readability
        try:
            with open(global_env_path, 'r') as f:
                f.read()
        except OSError as e:
            results['warnings'].append(f"Global .env exists but cannot be read: {e}")
            results['valid'] = False
    else:
        results['files']['global_env'] = 'not_found'
        results['info'].append(f"No global .env file found (expected at: {global_env_path})")

    # Check for conflicts (same key in multiple places with different values)
    if results['files']['local_env'] == 'exists' and results['files']['global_env'] == 'exists':
        local_env = read_local_env_file(local_env_path)
        global_env = read_local_env_file(str(global_env_path))

        # Find keys that exist in both
        common_keys = set(local_env.keys()) & set(global_env.keys())
        if common_keys:
            results['info'].append(f"Keys defined in both files: {', '.join(sorted(common_keys))}")
            results['info'].append("(Local .env values will take priority)")

    return results


def is_windows() -> bool:
    """
    Detect if running on Windows platform.

    Returns:
        True if running on Windows, False otherwise
    """
    return platform.system().lower() == "windows"


def should_use_emojis() -> bool:
    """
    Determine if emojis should be used based on platform and environment.

    Returns:
        True if emojis should be used, False otherwise
    """
    # Don't use emojis on Windows to avoid encoding issues
    if is_windows():
        return False

    # Don't use emojis in non-interactive environments
    if is_non_interactive():
        return False

    # Check for explicit emoji suppression
    return not read_global_config_bool("NO_EMOJIS", False)


class FileLock:
    """
    File locking utility class for preventing concurrent executions.
    """

    def __init__(self, lock_prefix: str = "media_library_tool"):
        """
        Initialize file lock.

        Args:
            lock_prefix: Prefix for lock file name
        """
        self.lock_prefix = lock_prefix
        self.lock_file = None

    def acquire_lock(self, force: bool = False) -> bool:
        """
        Acquire file lock to prevent multiple instances.

        Args:
            force: If True, skip locking mechanism

        Returns:
            True if lock acquired successfully, False otherwise
        """
        if force:
            return True

        try:
            with tempfile.NamedTemporaryFile(
                mode="w", prefix=f"{self.lock_prefix}_", suffix=".lock", delete=False
            ) as temp_file:
                self.lock_file = temp_file
                
                # Platform-specific file locking
                if fcntl is not None:  # Unix/Linux/macOS
                    fcntl.flock(self.lock_file.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
                elif msvcrt is not None:  # Windows
                    msvcrt.locking(self.lock_file.fileno(), msvcrt.LK_NBLCK, 1)
                else:
                    # Fallback: no locking available, just proceed
                    pass
                    
                self.lock_file.write(str(os.getpid()))
                self.lock_file.flush()
            return True
        except (OSError, IOError) as e:
            if self.lock_file:
                self.lock_file.close()
                with contextlib.suppress(OSError):
                    os.unlink(self.lock_file.name)
                self.lock_file = None
            print(
                "Error: Another instance is already running. Use --force to override."
            )
            print(f"Lock error: {e}")
            return False

    def release_lock(self) -> None:
        """
        Release the file lock.
        """
        if self.lock_file:
            try:
                # Only unlock if file is still open
                if not self.lock_file.closed:
                    # Platform-specific file unlocking
                    if fcntl is not None:  # Unix/Linux/macOS
                        fcntl.flock(self.lock_file.fileno(), fcntl.LOCK_UN)
                    elif msvcrt is not None:  # Windows
                        msvcrt.locking(self.lock_file.fileno(), msvcrt.LK_UNLCK, 1)
                    # No explicit unlock needed for fallback case
                    
                    self.lock_file.close()
            except (OSError, ValueError, IOError):
                # Handle both file system errors and closed file errors
                pass

            # Always try to remove lock file if it exists
            try:
                if os.path.exists(self.lock_file.name):
                    os.unlink(self.lock_file.name)
            except OSError:
                pass
            finally:
                self.lock_file = None


# Legacy standalone functions for backward compatibility
def acquire_lock(
    lock_prefix: str = "media_library_tool", force: bool = False
) -> Tuple[bool, Optional[FileLock]]:
    """
    Legacy function for acquiring file locks.

    Args:
        lock_prefix: Prefix for lock file name
        force: If True, skip locking mechanism

    Returns:
        Tuple of (success: bool, lock_instance: FileLock or None)
    """
    lock = FileLock(lock_prefix)
    success = lock.acquire_lock(force)
    return success, lock if success else None


def release_lock(lock_instance: FileLock) -> None:
    """
    Legacy function for releasing file locks.

    Args:
        lock_instance: FileLock instance to release
    """
    if lock_instance:
        lock_instance.release_lock()

# ======================================================
# INJECTED MODULE - END
# Source: lib/core.py
# ======================================================


# ======================================================
# INJECTED MODULE - START
# Generated by build.py v3.0.0
# Source: lib/ui.py
# ======================================================

"""
User Interface Module for Media Library Tools
Version: 1.0

This module contains user interface functions including:
- Banner display and application branding
- Size formatting for human-readable output  
- User confirmation prompts

This is part of the modular library structure that enables selective inclusion
in built tools while maintaining the self-contained principle.
"""

import sys
import time
import shutil
import os
from pathlib import Path
from typing import Optional, List, Dict, Set, Callable, Any
from dataclasses import dataclass

# Import dependencies from core module
try:
    from core import is_non_interactive, should_use_emojis
except ImportError:
    # Fallback for when core module is not available
    # This happens when modules are injected together during build
    def is_non_interactive():
        """Fallback implementation - will be overridden by injected core module"""
        return not sys.stdin.isatty()
    
    def should_use_emojis():
        """Fallback implementation - will be overridden by injected core module"""
        return sys.platform != "win32" and not is_non_interactive()


def display_banner(
    script_name: str,
    version: str,
    description: str,
    no_banner_flag: bool = False,
    quiet_mode: bool = False,
) -> None:
    """
    Display standardized banner for media library tools.

    Args:
        script_name: Name of the script
        version: Version string
        description: Brief description of the script
        no_banner_flag: If True, suppress banner display
        quiet_mode: If True, suppress banner display
    """
    # Check suppression conditions (highest to lowest priority)
    if no_banner_flag or quiet_mode or is_non_interactive():
        return

    try:
        # Display standardized ASCII art
        print("┏┳┓┏━╸╺┳┓╻┏━┓╻  ╻┏┓ ┏━┓┏━┓┏━┓╻ ╻╺┳╸┏━┓┏━┓╻  ┏━┓")
        print("┃┃┃┣╸  ┃┃┃┣━┫┃  ┃┣┻┓┣┳┛┣━┫┣┳┛┗┳┛ ┃ ┃ ┃┃ ┃┃  ┗━┓")
        print("╹ ╹┗━╸╺┻┛╹╹ ╹┗━╸╹┗━┛╹┗╸╹ ╹╹┗╸ ╹  ╹ ┗━┛┗━┛┗━╸┗━┛")
        print(f"{script_name} v{version}: {description}")
        print()  # Blank line for separation
    except Exception:
        # Banner display errors should not prevent script execution
        pass


def format_size(size_bytes: int) -> str:
    """
    Format size in bytes to human readable format.

    Args:
        size_bytes: Size in bytes

    Returns:
        Human readable size string
    """
    for unit in ["B", "K", "M", "G", "T"]:
        if size_bytes < 1024.0:
            if unit == "B":
                return f"{size_bytes:.0f}{unit}"
            else:
                return f"{size_bytes:.1f}{unit}"
        size_bytes /= 1024.0
    return f"{size_bytes:.1f}P"


def confirm_action(message: str, skip_confirmation: bool = False) -> bool:
    """
    Ask for user confirmation unless skipped.

    Args:
        message: Confirmation message to display
        skip_confirmation: If True, automatically confirm

    Returns:
        True if confirmed, False otherwise
    """
    if skip_confirmation:
        return True

    try:
        response = input(f"{message} (y/N): ").strip().lower()
        return response in ["y", "yes"]
    except (EOFError, KeyboardInterrupt):
        print("\nOperation cancelled.")
        return False


def format_status_message(
    message: str, emoji: str = "", fallback_prefix: str = ""
) -> str:
    """
    Format a status message with optional emoji or fallback prefix.

    Args:
        message: The message to format
        emoji: Emoji to use if emojis are supported
        fallback_prefix: Text prefix to use if emojis are not supported

    Returns:
        Formatted message string
    """
    if emoji and should_use_emojis():
        return f"{emoji} {message}"
    elif fallback_prefix:
        return f"{fallback_prefix}: {message}"
    else:
        return message


def display_item_list(items, title: str = None, numbered: bool = False, 
                     show_count: bool = True, indent: str = "  ") -> None:
    """
    Display a list of items with consistent formatting.
    
    Args:
        items: List of items to display (strings or objects with __str__)
        title: Optional title to display above the list
        numbered: Whether to number the items (default: False for bullet points)
        show_count: Whether to show total count in title (default: True)
        indent: Indentation string for list items (default: "  ")
    
    Example:
        display_item_list(['file1.mp4', 'file2.mkv'], 'Files to process', numbered=True)
        # Output:
        # Files to process (2):
        #   1. file1.mp4
        #   2. file2.mkv
    """
    if not items:
        if title:
            print(f"{title}: None found")
        return
    
    # Display title with optional count
    if title:
        count_text = f" ({len(items)})" if show_count else ""
        print(f"{title}{count_text}:")
    
    # Display items
    for i, item in enumerate(items, 1):
        if numbered:
            print(f"{indent}{i}. {item}")
        else:
            print(f"{indent}- {item}")


def display_summary_list(summary_data: dict, title: str = None) -> None:
    """
    Display a summary with categorized counts and totals.
    
    Args:
        summary_data: Dictionary with category names as keys and counts as values
        title: Optional title to display above the summary
    
    Example:
        display_summary_list({
            'Files processed': 15,
            'Files skipped': 3,
            'Errors encountered': 1
        }, 'Processing Summary')
        # Output:
        # Processing Summary:
        #   Files processed: 15
        #   Files skipped: 3
        #   Errors encountered: 1
    """
    if title:
        print(f"{title}:")
    
    # Find the longest key for alignment
    max_key_length = max(len(str(key)) for key in summary_data.keys()) if summary_data else 0
    
    for key, value in summary_data.items():
        print(f"  {str(key).ljust(max_key_length)}: {value}")


def display_progress_item(current: int, total: int, item_name: str, 
                         prefix: str = "Processing") -> None:
    """
    Display current progress for an item being processed.
    
    Args:
        current: Current item number (1-based)
        total: Total number of items
        item_name: Name of the current item being processed
        prefix: Prefix text (default: "Processing")
    
    Example:
        display_progress_item(3, 10, 'movie.mp4')
        # Output: [3/10] Processing: movie.mp4
    """
    print(f"[{current}/{total}] {prefix}: {item_name}")


def display_stats_table(stats: dict, title: str = None, 
                       value_formatter=None) -> None:
    """
    Display statistics in a formatted table with aligned columns.
    
    Args:
        stats: Dictionary with statistic names as keys and values
        title: Optional title to display above the table
        value_formatter: Optional function to format values (e.g., format_size for bytes)
    
    Example:
        display_stats_table({
            'Total files': 1250,
            'Total size': 15728640,
            'Average size': 12582
        }, 'File Statistics', format_size)
    """
    if not stats:
        return
    
    if title:
        print(f"\n{title}:")
    
    # Find the longest key for alignment
    max_key_length = max(len(str(key)) for key in stats.keys())
    
    for key, value in stats.items():
        formatted_value = value_formatter(value) if value_formatter else str(value)
        print(f"  {str(key).ljust(max_key_length)}: {formatted_value}")


@dataclass
class ColumnConfig:
    """
    Configuration for table column rendering.

    Attributes:
        align: Column alignment ('left', 'right', 'center')
        formatter: Optional function to format cell values
        max_width: Maximum width for this column (None for auto)
    """
    align: str = 'left'
    formatter: Optional[Callable[[Any], str]] = None
    max_width: Optional[int] = None


def display_results_table(data: list, headers: list, title: str = None,
                         max_width: int = 80, column_config: Optional[List[ColumnConfig]] = None,
                         sort_by: Optional[int] = None, reverse: bool = False,
                         show_totals: bool = False, border_style: str = 'ascii') -> None:
    """
    Display structured data in a formatted table with advanced configuration.

    Features:
    - Column alignment control (left, right, center)
    - Automatic width calculation based on content
    - Row sorting by column
    - Column-specific formatters (size, date, percentage)
    - Footer rows for totals/summaries
    - Maximum width enforcement with truncation
    - Border style options (ASCII, Unicode, minimal)

    Args:
        data: List of lists/tuples containing row data
        headers: List of column headers
        title: Optional title to display above the table
        max_width: Maximum width for the table (default: 80)
        column_config: Optional list of ColumnConfig objects for each column
        sort_by: Optional column index to sort by
        reverse: Reverse sort order (default: False)
        show_totals: Show totals row for numeric columns (default: False)
        border_style: Border style ('ascii', 'unicode', 'minimal')

    Example:
        from lib.ui import display_results_table, ColumnConfig

        display_results_table([
            ['file1.mp4', 1234567890, 'Processed'],
            ['file2.mkv', 987654321, 'Skipped']
        ], ['Filename', 'Size', 'Status'],
        column_config=[
            ColumnConfig(align='left'),
            ColumnConfig(align='right', formatter=format_size),
            ColumnConfig(align='center')
        ],
        sort_by=1, reverse=True, border_style='unicode')
    """
    if not data or not headers:
        if title:
            print(f"{title}: No data to display")
        return

    # Default column config if not provided
    if column_config is None:
        column_config = [ColumnConfig() for _ in headers]
    elif len(column_config) < len(headers):
        # Extend with defaults if needed
        column_config = list(column_config) + [ColumnConfig() for _ in range(len(headers) - len(column_config))]

    # Sort data if requested
    if sort_by is not None and 0 <= sort_by < len(headers):
        data = sorted(data, key=lambda row: row[sort_by] if sort_by < len(row) else '', reverse=reverse)

    # Apply formatters to data
    formatted_data = []
    for row in data:
        formatted_row = []
        for i, cell in enumerate(row):
            if i < len(column_config) and column_config[i].formatter:
                formatted_row.append(column_config[i].formatter(cell))
            else:
                formatted_row.append(str(cell))
        formatted_data.append(formatted_row)

    # Calculate column widths
    col_widths = []
    for i, header in enumerate(headers):
        # Start with header width
        max_col_width = len(header)

        # Check data column widths
        for row in formatted_data:
            if i < len(row):
                max_col_width = max(max_col_width, len(row[i]))

        # Apply column-specific max width if set
        if i < len(column_config) and column_config[i].max_width:
            max_col_width = min(max_col_width, column_config[i].max_width)
        else:
            # Apply global max width
            max_col_width = min(max_col_width, max_width // len(headers))

        col_widths.append(max_col_width)

    # Choose border characters
    if border_style == 'unicode':
        sep = " │ "
        top_left, top_mid, top_right = "┌", "┬", "┐"
        mid_left, mid_mid, mid_right = "├", "┼", "┤"
        bot_left, bot_mid, bot_right = "└", "┴", "┘"
        horiz = "─"
    elif border_style == 'minimal':
        sep = "  "
        top_left = top_mid = top_right = ""
        mid_left = mid_mid = mid_right = ""
        bot_left = bot_mid = bot_right = ""
        horiz = " "
    else:  # ascii
        sep = " | "
        top_left = top_mid = top_right = ""
        mid_left = mid_mid = mid_right = ""
        bot_left = bot_mid = bot_right = ""
        horiz = "-"

    def align_cell(cell: str, width: int, alignment: str) -> str:
        """Align cell content according to specified alignment."""
        if len(cell) > width:
            cell = cell[:width-3] + "..."
        if alignment == 'right':
            return cell.rjust(width)
        elif alignment == 'center':
            return cell.center(width)
        else:  # left
            return cell.ljust(width)

    # Display title
    if title:
        print(f"\n{title}:")

    # Build and print header
    header_cells = []
    for i, header in enumerate(headers):
        alignment = column_config[i].align if i < len(column_config) else 'left'
        header_cells.append(align_cell(header, col_widths[i], alignment))

    header_row = "  " + sep.join(header_cells)
    print(header_row)

    # Print separator
    if border_style == 'unicode':
        separator = "  " + mid_left + horiz * col_widths[0]
        for i in range(1, len(col_widths)):
            separator += mid_mid + horiz * col_widths[i]
        separator += mid_right
        print(separator)
    else:
        print("  " + horiz * (len(header_row) - 2))

    # Print data rows
    for row in formatted_data:
        row_cells = []
        for i in range(len(headers)):
            cell = row[i] if i < len(row) else ""
            alignment = column_config[i].align if i < len(column_config) else 'left'
            row_cells.append(align_cell(cell, col_widths[i], alignment))

        print("  " + sep.join(row_cells))

    # Show totals if requested
    if show_totals and data:
        # Calculate totals for numeric columns
        totals = []
        has_total = False
        for i in range(len(headers)):
            try:
                # Try to sum numeric values from original data (before formatting)
                col_values = [row[i] for row in data if i < len(row) and isinstance(row[i], (int, float))]
                if col_values:
                    total = sum(col_values)
                    # Apply formatter if available
                    if i < len(column_config) and column_config[i].formatter:
                        totals.append(column_config[i].formatter(total))
                    else:
                        totals.append(str(total))
                    has_total = True
                else:
                    totals.append("")
            except (TypeError, ValueError):
                totals.append("")

        if has_total:
            # Print separator before totals
            if border_style != 'minimal':
                print("  " + horiz * (len(header_row) - 2))

            # Print totals row
            total_cells = []
            for i in range(len(headers)):
                if i == 0 and not totals[0]:
                    cell = "TOTAL"
                else:
                    cell = totals[i] if i < len(totals) else ""
                alignment = column_config[i].align if i < len(column_config) else 'left'
                total_cells.append(align_cell(cell, col_widths[i], alignment))

            print("  " + sep.join(total_cells))

    print()  # Blank line after table


class ProgressBar:
    """
    Real-time progress bar with ETA calculation and rate display.

    Features:
    - Configurable width and style
    - ETA calculation based on current rate
    - Dynamic updates without line spam
    - Rate display (items/sec, MB/sec)
    - Memory-efficient for large operations
    - TTY detection with fallback for non-interactive environments

    Usage:
        with ProgressBar(total=1000, desc="Processing files") as pb:
            for item in items:
                process_item(item)
                pb.update(1)
    """

    def __init__(self, total: int, desc: str = "", width: int = 50,
                 unit: str = "items", show_rate: bool = True):
        """
        Initialize progress bar.

        Args:
            total: Total number of items to process
            desc: Description to display before progress bar
            width: Width of progress bar in characters (default: 50)
            unit: Unit name for rate display (default: "items")
            show_rate: Whether to show processing rate (default: True)
        """
        self.total = total
        self.desc = desc
        self.width = width
        self.unit = unit
        self.show_rate = show_rate
        self.current = 0
        self.start_time = time.time()
        self.last_update_time = self.start_time
        self.last_print_length = 0
        self.is_tty = sys.stdout.isatty() and not is_non_interactive()
        self.update_interval = 0.1  # Update display every 0.1 seconds minimum
        self.completed = False

    def update(self, increment: int = 1) -> None:
        """
        Update progress by specified increment.

        Args:
            increment: Number of items to add to progress (default: 1)
        """
        self.current = min(self.current + increment, self.total)
        current_time = time.time()

        # Only update display if enough time has passed or we're complete
        if (current_time - self.last_update_time >= self.update_interval or
            self.current >= self.total):
            self._display()
            self.last_update_time = current_time

    def _display(self) -> None:
        """Display current progress state."""
        if self.total == 0:
            return

        # Calculate metrics
        elapsed = time.time() - self.start_time
        percentage = (self.current / self.total) * 100

        # Build progress bar
        if self.is_tty:
            filled = int(self.width * self.current / self.total)
            bar = "█" * filled + "░" * (self.width - filled)

            # Calculate ETA
            if self.current > 0 and elapsed > 0:
                rate = self.current / elapsed
                remaining = self.total - self.current
                eta_seconds = remaining / rate if rate > 0 else 0
                eta_str = self._format_time(eta_seconds)

                # Build status line
                status_parts = [
                    f"{self.desc}: " if self.desc else "",
                    f"[{bar}] ",
                    f"{self.current}/{self.total} ",
                    f"({percentage:.1f}%)"
                ]

                if self.show_rate and rate > 0:
                    status_parts.append(f" - {rate:.1f} {self.unit}/sec")

                if self.current < self.total:
                    status_parts.append(f" - ETA: {eta_str}")
                else:
                    status_parts.append(" - Complete")

                status = "".join(status_parts)
            else:
                status = f"{self.desc}: [{bar}] {self.current}/{self.total} ({percentage:.1f}%)"

            # Clear previous line and print new status
            print(f"\r{' ' * self.last_print_length}\r{status}", end="", flush=True)
            self.last_print_length = len(status)

            # Print newline when complete
            if self.current >= self.total and not self.completed:
                print()
                self.completed = True
        else:
            # Non-TTY mode: only print at milestones (0%, 25%, 50%, 75%, 100%)
            milestones = [0, 25, 50, 75, 100]
            current_milestone = int(percentage / 25) * 25

            if not hasattr(self, '_last_milestone'):
                self._last_milestone = -1

            if current_milestone > self._last_milestone and current_milestone in milestones:
                prefix = f"{self.desc}: " if self.desc else ""
                print(f"{prefix}Progress: {self.current}/{self.total} ({percentage:.1f}%)")
                self._last_milestone = current_milestone

    def _format_time(self, seconds: float) -> str:
        """
        Format seconds into human-readable time string.

        Args:
            seconds: Time in seconds

        Returns:
            Formatted time string (e.g., "2m 30s")
        """
        if seconds < 60:
            return f"{int(seconds)}s"
        elif seconds < 3600:
            minutes = int(seconds / 60)
            secs = int(seconds % 60)
            return f"{minutes}m {secs}s"
        else:
            hours = int(seconds / 3600)
            minutes = int((seconds % 3600) / 60)
            return f"{hours}h {minutes}m"

    def __enter__(self):
        """Context manager entry."""
        return self

    def __exit__(self, *args):
        """Context manager exit - ensure final display."""
        if not self.completed:
            self.current = self.total
            self._display()
            if self.is_tty:
                print()


class PhaseProgressTracker:
    """
    Multi-phase operation tracking with individual progress bars.

    Features:
    - Track multiple named phases (e.g., Consolidation, Organization, Archive)
    - Per-phase progress with individual progress bars
    - Overall completion percentage
    - Phase timing and duration display
    - Phase status tracking (pending, in-progress, completed, failed)

    Usage:
        tracker = PhaseProgressTracker([
            "Phase 1: Consolidation",
            "Phase 2: Organization",
            "Phase 3: Archive"
        ])

        tracker.start_phase(0, total_items=500)
        # ... process items ...
        tracker.update_phase(0, increment=1)
        tracker.complete_phase(0)

        tracker.display_summary()
    """

    def __init__(self, phase_names: List[str]):
        """
        Initialize phase progress tracker.

        Args:
            phase_names: List of phase names in order
        """
        self.phase_names = phase_names
        self.phases: Dict[int, Dict] = {}
        self.current_phase_index: Optional[int] = None
        self.is_tty = sys.stdout.isatty() and not is_non_interactive()

        # Initialize phase data
        for i in range(len(phase_names)):
            self.phases[i] = {
                'name': phase_names[i],
                'status': 'pending',  # pending, in-progress, completed, failed
                'total': 0,
                'current': 0,
                'start_time': None,
                'end_time': None,
                'progress_bar': None
            }

    def start_phase(self, phase_index: int, total_items: int = 0) -> None:
        """
        Start a specific phase.

        Args:
            phase_index: Index of the phase to start (0-based)
            total_items: Total number of items for this phase
        """
        if phase_index not in self.phases:
            return

        self.current_phase_index = phase_index
        phase = self.phases[phase_index]
        phase['status'] = 'in-progress'
        phase['total'] = total_items
        phase['current'] = 0
        phase['start_time'] = time.time()

        # Display phase start
        print(f"\n{phase['name']}")
        if total_items > 0:
            phase['progress_bar'] = ProgressBar(
                total=total_items,
                desc="  Progress",
                width=40,
                unit="items"
            )

    def update_phase(self, phase_index: int, increment: int = 1) -> None:
        """
        Update progress for a specific phase.

        Args:
            phase_index: Index of the phase to update
            increment: Number of items to add to progress
        """
        if phase_index not in self.phases:
            return

        phase = self.phases[phase_index]
        if phase['status'] != 'in-progress':
            return

        phase['current'] = min(phase['current'] + increment, phase['total'])

        if phase['progress_bar']:
            phase['progress_bar'].update(increment)

    def complete_phase(self, phase_index: int, status: str = 'completed') -> None:
        """
        Mark a phase as complete.

        Args:
            phase_index: Index of the phase to complete
            status: Final status ('completed' or 'failed')
        """
        if phase_index not in self.phases:
            return

        phase = self.phases[phase_index]
        phase['status'] = status
        phase['end_time'] = time.time()

        # Ensure progress bar is complete
        if phase['progress_bar'] and phase['current'] < phase['total']:
            phase['progress_bar'].current = phase['total']
            phase['progress_bar']._display()
            if phase['progress_bar'].is_tty:
                print()

        # Display phase completion
        if phase['start_time']:
            duration = phase['end_time'] - phase['start_time']
            duration_str = self._format_duration(duration)
            status_text = "Complete" if status == 'completed' else "FAILED"
            print(f"  {status_text} - Duration: {duration_str}\n")

    def fail_phase(self, phase_index: int, error_message: str = "") -> None:
        """
        Mark a phase as failed.

        Args:
            phase_index: Index of the phase that failed
            error_message: Optional error message to display
        """
        if error_message:
            print(f"  Error: {error_message}")
        self.complete_phase(phase_index, status='failed')

    def display_summary(self) -> None:
        """Display summary of all phases."""
        print("\n" + "=" * 60)
        print("PHASE SUMMARY")
        print("=" * 60)

        total_duration = 0
        for i in range(len(self.phase_names)):
            phase = self.phases[i]
            status_symbol = {
                'pending': '[ ]',
                'in-progress': '[~]',
                'completed': '[✓]' if not is_non_interactive() else '[x]',
                'failed': '[✗]' if not is_non_interactive() else '[!]'
            }.get(phase['status'], '[ ]')

            duration_str = ""
            if phase['start_time'] and phase['end_time']:
                duration = phase['end_time'] - phase['start_time']
                duration_str = f" - {self._format_duration(duration)}"
                total_duration += duration

            progress_str = ""
            if phase['total'] > 0:
                progress_str = f" ({phase['current']}/{phase['total']} items)"

            print(f"{status_symbol} {phase['name']}{progress_str}{duration_str}")

        if total_duration > 0:
            print(f"\nTotal Duration: {self._format_duration(total_duration)}")
        print("=" * 60 + "\n")

    def get_overall_progress(self) -> float:
        """
        Get overall progress percentage across all phases.

        Returns:
            Overall progress percentage (0-100)
        """
        completed_phases = sum(1 for p in self.phases.values() if p['status'] == 'completed')
        return (completed_phases / len(self.phase_names)) * 100 if self.phase_names else 0

    def _format_duration(self, seconds: float) -> str:
        """
        Format duration in seconds to human-readable string.

        Args:
            seconds: Duration in seconds

        Returns:
            Formatted duration string
        """
        if seconds < 1:
            return f"{int(seconds * 1000)}ms"
        elif seconds < 60:
            return f"{seconds:.1f}s"
        elif seconds < 3600:
            minutes = int(seconds / 60)
            secs = int(seconds % 60)
            return f"{minutes}m {secs}s"
        else:
            hours = int(seconds / 3600)
            minutes = int((seconds % 3600) / 60)
            return f"{hours}h {minutes}m"


def display_directory_tree(root_path: str, max_depth: int = 3,
                          show_sizes: bool = True,
                          highlight_patterns: Optional[List[str]] = None,
                          use_unicode: Optional[bool] = None) -> None:
    """
    Display directory structure as a tree with optional size information.

    Features:
    - Configurable depth limit
    - File size display
    - Path highlighting for specific patterns
    - Unicode or ASCII symbols
    - Efficient traversal with depth limiting

    Args:
        root_path: Root directory to visualize
        max_depth: Maximum depth to traverse (default: 3)
        show_sizes: Whether to show file/directory sizes (default: True)
        highlight_patterns: List of patterns to highlight (e.g., ["Season *"])
        use_unicode: Use Unicode symbols (default: auto-detect based on platform)

    Example:
        display_directory_tree("/media/TV Shows/Show Name", max_depth=3,
                             highlight_patterns=["Season *"])
    """
    root = Path(root_path)
    if not root.exists():
        print(f"Error: Path does not exist: {root_path}")
        return

    # Auto-detect unicode support
    if use_unicode is None:
        use_unicode = sys.platform != "win32" and not is_non_interactive()

    # Tree symbols
    if use_unicode:
        PIPE = "│   "
        TEE = "├── "
        ELBOW = "└── "
        BLANK = "    "
    else:
        PIPE = "|   "
        TEE = "|-- "
        ELBOW = "`-- "
        BLANK = "    "

    # Compile highlight patterns if provided
    highlight_set: Set[str] = set()
    if highlight_patterns:
        for pattern in highlight_patterns:
            highlight_set.add(pattern.lower())

    # Track statistics
    total_size = 0
    file_count = 0
    dir_count = 0

    def should_highlight(path: Path) -> bool:
        """Check if path matches any highlight patterns."""
        if not highlight_patterns:
            return False
        path_str = path.name.lower()
        for pattern in highlight_patterns:
            pattern_lower = pattern.lower().replace("*", "")
            if pattern_lower in path_str:
                return True
        return False

    def get_size(path: Path) -> int:
        """Get size of file or directory."""
        try:
            if path.is_file():
                return path.stat().st_size
            elif path.is_dir():
                # For directories, sum all file sizes
                total = 0
                try:
                    for item in path.rglob('*'):
                        if item.is_file():
                            try:
                                total += item.stat().st_size
                            except (OSError, PermissionError):
                                pass
                except (OSError, PermissionError):
                    pass
                return total
        except (OSError, PermissionError):
            return 0
        return 0

    def format_entry(path: Path, is_last: bool, prefix: str, depth: int) -> str:
        """Format a single tree entry."""
        nonlocal total_size, file_count, dir_count

        # Choose connector
        connector = ELBOW if is_last else TEE

        # Get name and size
        name = path.name
        if path.is_dir():
            name += "/"
            dir_count += 1
        else:
            file_count += 1

        # Check for highlighting
        highlighted = should_highlight(path)
        if highlighted and use_unicode:
            name = f"→ {name}"

        # Add size if requested
        size_str = ""
        if show_sizes:
            size = get_size(path)
            total_size += size
            if size > 0:
                size_str = f" ({format_size(size)})"

        return f"{prefix}{connector}{name}{size_str}"

    def walk_tree(path: Path, prefix: str = "", depth: int = 0):
        """Recursively walk directory tree."""
        if depth > max_depth:
            return

        try:
            entries = sorted(path.iterdir(), key=lambda p: (not p.is_dir(), p.name.lower()))
        except PermissionError:
            print(f"{prefix}{TEE}[Permission Denied]")
            return
        except OSError as e:
            print(f"{prefix}{TEE}[Error: {e}]")
            return

        # Filter out hidden files for cleaner display
        entries = [e for e in entries if not e.name.startswith('.')]

        for i, entry in enumerate(entries):
            is_last = (i == len(entries) - 1)

            # Print entry
            print(format_entry(entry, is_last, prefix, depth))

            # Recurse into directories
            if entry.is_dir() and depth < max_depth:
                extension = BLANK if is_last else PIPE
                walk_tree(entry, prefix + extension, depth + 1)

    # Display root
    print(f"\n{root}/")

    # Walk tree
    walk_tree(root, "", 0)

    # Display summary
    if show_sizes and (file_count > 0 or dir_count > 0):
        print(f"\nTotal: {format_size(total_size)} across {file_count} files in {dir_count} directories")
    print()

# ======================================================
# INJECTED MODULE - END
# Source: lib/ui.py
# ======================================================


# ======================================================
# INJECTED MODULE - START
# Generated by build.py v3.0.0
# Source: lib/cleanup.py
# ======================================================

"""
System Trash File Cleanup Module

Centralized cleanup utilities for removing system-generated trash files
that commonly cause issues with media library tools, especially files
transferred via rsync or network shares.

Common Issues Solved:
- .DS_Store files from macOS causing directory conflicts
- Thumbs.db files from Windows
- ._ AppleDouble files from macOS resource forks
- Desktop.ini files from Windows
- Other hidden system files

Author: Media Library Tools Project
Version: 1.0.0
"""

import os
from pathlib import Path
from typing import List, Optional, Set


class SystemTrashCleaner:
    """
    Handles detection and removal of system-generated trash files.

    These files are commonly created by operating systems and can cause
    conflicts during media library operations, especially after rsync
    transfers or network share access.
    """

    # System trash file patterns
    TRASH_FILES = {
        '.DS_Store',        # macOS Finder metadata
        'Thumbs.db',        # Windows thumbnail cache
        'Desktop.ini',      # Windows folder settings
        '.Spotlight-V100',  # macOS Spotlight index
        '.Trashes',         # macOS trash folder
        '.fseventsd',       # macOS file system events
        '.TemporaryItems',  # macOS temporary items
        '.localized',       # macOS localization
        'desktop.ini',      # Windows (lowercase variant)
        'thumbs.db',        # Windows (lowercase variant)
    }

    # Patterns for prefixed trash files
    TRASH_PREFIXES = {
        '._',               # macOS AppleDouble resource fork files
        '.~',               # Temporary/backup files
    }

    # Patterns for suffixed trash files
    TRASH_SUFFIXES = {
        '.tmp',             # Temporary files
        '.temp',            # Temporary files (variant)
        '~',                # Backup files
    }

    def __init__(self, verbose: bool = False, dry_run: bool = False):
        """
        Initialize the trash cleaner.

        Args:
            verbose: Enable verbose output
            dry_run: Preview mode - don't actually delete files
        """
        self.verbose = verbose
        self.dry_run = dry_run
        self.removed_files: List[Path] = []
        self.failed_removals: List[tuple] = []

    def is_trash_file(self, file_path: Path) -> bool:
        """
        Determine if a file is system trash.

        Args:
            file_path: Path to check

        Returns:
            True if file matches trash patterns
        """
        filename = file_path.name

        # Check exact matches
        if filename in self.TRASH_FILES:
            return True

        # Check prefixes
        for prefix in self.TRASH_PREFIXES:
            if filename.startswith(prefix):
                return True

        # Check suffixes
        for suffix in self.TRASH_SUFFIXES:
            if filename.endswith(suffix):
                return True

        return False

    def clean_directory(self, directory: Path, recursive: bool = False) -> int:
        """
        Clean trash files from a directory.

        Args:
            directory: Directory to clean
            recursive: Also clean subdirectories

        Returns:
            Number of files removed
        """
        if not directory.exists() or not directory.is_dir():
            if self.verbose:
                print(f"Directory does not exist or is not a directory: {directory}")
            return 0

        removed_count = 0

        try:
            if recursive:
                # Walk entire directory tree
                for root, dirs, files in os.walk(directory):
                    root_path = Path(root)

                    # Clean files in this directory
                    for filename in files:
                        file_path = root_path / filename
                        if self.is_trash_file(file_path):
                            if self._remove_file(file_path):
                                removed_count += 1

                    # Clean trash directories
                    for dirname in dirs[:]:  # Copy list to allow modification
                        dir_path = root_path / dirname
                        if dirname in self.TRASH_FILES:
                            if self._remove_directory(dir_path):
                                removed_count += 1
                                dirs.remove(dirname)  # Don't descend into removed dir
            else:
                # Only clean current directory
                for item in directory.iterdir():
                    if item.is_file() and self.is_trash_file(item):
                        if self._remove_file(item):
                            removed_count += 1
                    elif item.is_dir() and item.name in self.TRASH_FILES:
                        if self._remove_directory(item):
                            removed_count += 1

        except PermissionError as e:
            if self.verbose:
                print(f"Permission denied accessing {directory}: {e}")
        except Exception as e:
            if self.verbose:
                print(f"Error cleaning {directory}: {e}")

        return removed_count

    def _remove_file(self, file_path: Path) -> bool:
        """
        Remove a single trash file.

        Args:
            file_path: File to remove

        Returns:
            True if removed successfully
        """
        if self.dry_run:
            if self.verbose:
                print(f"[DRY RUN] Would remove: {file_path}")
            self.removed_files.append(file_path)
            return True

        try:
            os.remove(file_path)
            self.removed_files.append(file_path)
            if self.verbose:
                print(f"Removed: {file_path}")
            return True
        except OSError as e:
            self.failed_removals.append((file_path, str(e)))
            if self.verbose:
                print(f"Error removing {file_path}: {e}")
            return False

    def _remove_directory(self, dir_path: Path) -> bool:
        """
        Remove a trash directory.

        Args:
            dir_path: Directory to remove

        Returns:
            True if removed successfully
        """
        if self.dry_run:
            if self.verbose:
                print(f"[DRY RUN] Would remove directory: {dir_path}")
            self.removed_files.append(dir_path)
            return True

        try:
            import shutil
            shutil.rmtree(dir_path)
            self.removed_files.append(dir_path)
            if self.verbose:
                print(f"Removed directory: {dir_path}")
            return True
        except OSError as e:
            self.failed_removals.append((dir_path, str(e)))
            if self.verbose:
                print(f"Error removing directory {dir_path}: {e}")
            return False

    def get_stats(self) -> dict:
        """
        Get cleanup statistics.

        Returns:
            Dictionary with cleanup stats
        """
        return {
            'files_removed': len(self.removed_files),
            'failed_removals': len(self.failed_removals),
            'removed_list': [str(p) for p in self.removed_files],
            'failed_list': [(str(p), e) for p, e in self.failed_removals]
        }

    def print_summary(self) -> None:
        """Print cleanup summary."""
        stats = self.get_stats()

        if self.dry_run:
            print(f"\n[DRY RUN] Would remove {stats['files_removed']} trash files")
        else:
            print(f"\nRemoved {stats['files_removed']} trash files")

        if stats['failed_removals'] > 0:
            print(f"Failed to remove {stats['failed_removals']} files")
            if self.verbose:
                print("\nFailed removals:")
                for path, error in stats['failed_list']:
                    print(f"  {path}: {error}")


def quick_clean(directory: Path, recursive: bool = False,
                verbose: bool = False, dry_run: bool = False) -> int:
    """
    Quick cleanup function for simple use cases.

    Args:
        directory: Directory to clean
        recursive: Clean subdirectories
        verbose: Show detailed output
        dry_run: Preview mode

    Returns:
        Number of files removed

    Example:
        >>> from pathlib import Path
        >>> import lib.cleanup as cleanup
        >>> removed = cleanup.quick_clean(Path('.'), recursive=True, verbose=True)
    """
    cleaner = SystemTrashCleaner(verbose=verbose, dry_run=dry_run)
    count = cleaner.clean_directory(directory, recursive=recursive)

    if verbose:
        cleaner.print_summary()

    return count



# ======================================================
# INJECTED MODULE - END
# Source: lib/cleanup.py
# ======================================================


# ======================================================


class PlexDirectoryCorrector:
    """Main class for correcting Plex directory names."""

    def __init__(self, dry_run: bool = False, force: bool = False, max_items: int = 5,
                 verbose: bool = False, debug: bool = False, enable_cleanup: bool = False):
        self.dry_run = dry_run
        self.force = force
        self.max_items = max_items if dry_run else float('inf')
        self.verbose = verbose
        self.debug = debug
        self.enable_cleanup = enable_cleanup
        self.processed_count = 0
        self.file_lock = FileLock('plex_correct_dirs')

        # Enhanced regex patterns for comprehensive tag removal
        self.patterns = {
            # Resolution patterns - enclose in brackets
            'resolution': re.compile(r'(?<!\[)(\b\d{3,4}p\b)(?=(\W|$))', re.IGNORECASE),

            # Year patterns - enclose in parentheses
            'year': re.compile(r'(?<!\()(\b(19|20)\d{2}\b)(?!\))', re.IGNORECASE),

            # 4K to 2160p conversion
            'four_k': re.compile(r'\[4k\]', re.IGNORECASE),

            # Release group tags
            'release_groups': re.compile(
                r'\[(YTS\.[A-Z]{2,3}|RARBG|YIFY|FGT|ION10|STUTTERSHIT|RMTEAM|PSA|KOGi|'
                r'SPARKS|DEFLATE|BLOW|Scene|CMRG|EVO|FXG|MiGHTY|QOQ|SiNNERS|UTR|'
                r'YAWNiNG|SAMPA|ION265|BONSAI|YTS|MeGusta|LAMA|SUBSCRiBE|RAWR|NOW|'
                r'ETRG|AMIABLE|GALAXY|GECKOS|HONE|KILLERS|ROVERS|SWTYBLZ|TGx|'
                r'TORRENTGALAXY|VARYG|YIFY|ZMNT)\]', re.IGNORECASE
            ),

            # Video source/quality tags
            'video_quality': re.compile(
                r'\[(BluRay|BDRip|WEBRip|DVDRip|BRRip|HDRip|WEB-DL|WEB|HDTV|CAM|TS|'
                r'TC|SCR|R5|DVDScr|HDCAM|HDTS|WORKPRINT|TELECINE|TELESYNC|'
                r'SCREENER|DVDSCREENER|BDRIP|BRRIP|HDRIP|WEBRIP|WEBDL)\]', re.IGNORECASE
            ),

            # Audio format tags
            'audio_format': re.compile(
                r'\[(5\.1|7\.1|2\.0|AC3|AAC|DTS|DOLBY|Atmos|DTS-HD|AAC2\.0|'
                r'DD5\.1|DD7\.1|TrueHD|FLAC|MP3|OGG|PCM|LPCM)\]', re.IGNORECASE
            ),

            # Codec tags
            'codec': re.compile(
                r'\[(H\.264|H\.265|x264|x265|HEVC|AVC|XviD|DivX|VP9|AV1|'
                r'MPEG2|MPEG4)\]', re.IGNORECASE
            ),

            # HDR and enhancement tags
            'enhancement': re.compile(
                r'\[(HDR|HDR10|HDR10\+|DV|DOLBY.VISION|IMAX|REMASTERED|UNRATED|'
                r'DC|EXTENDED|DIRECTOR.S.CUT|THEATRICAL|ULTIMATE|SPECIAL.EDITION|'
                r'CRITERION|ANNIVERSARY)\]', re.IGNORECASE
            ),

            # Streaming service tags
            'streaming': re.compile(
                r'\[(AMZN|NFLX|HULU|DSNP|ATVP|HMAX|PCOK|PMTP|STAN|CRAV|'
                r'AMAZON|NETFLIX|DISNEY|APPLE|HBO|PEACOCK|PARAMOUNT)\]', re.IGNORECASE
            ),

            # Technical tags
            'technical': re.compile(
                r'\[(10bit|8bit|12bit|HDR|WEB|INTERNAL|PROPER|REPACK|READ\.NFO|'
                r'RERiP|SUBBED|DUBBED|MULTI|DUAL|REMUX|HYBRID)\]', re.IGNORECASE
            ),

            # Dots to spaces
            'dots': re.compile(r'\.'),

            # Duplicate resolution tags
            'duplicate_resolution': re.compile(r'\[2160p\]\s*\[2160p\]'),

            # Empty brackets
            'empty_brackets': re.compile(r'\[\s*\]'),

            # Multiple spaces
            'multiple_spaces': re.compile(r'[ \t]+'),

            # Leading/trailing whitespace and punctuation
            'trim': re.compile(r'^[\s\.\-_]+|[\s\.\-_]+$')
        }

    def log_verbose(self, msg: str):
        """Log verbose message."""
        if self.verbose or self.debug:
            print(f"[VERBOSE] {msg}", file=sys.stderr)

    def log_debug(self, msg: str):
        """Log debug message."""
        if self.debug:
            print(f"[DEBUG] {msg}", file=sys.stderr)

    def acquire_lock(self) -> bool:
        """Acquire file lock to prevent multiple instances."""
        return self.file_lock.acquire_lock(self.force)

    def release_lock(self) -> None:
        """Release the file lock."""
        self.file_lock.release_lock()

    def sanitize_name(self, name: str) -> str:
        """Sanitize directory name using enhanced regex patterns."""
        result = name

        # Step 1: Enclose resolutions in brackets
        result = self.patterns['resolution'].sub(r'[\1]', result)

        # Step 2: Enclose years in parentheses
        result = self.patterns['year'].sub(r'(\1)', result)

        # Step 3: Convert [4K] to [2160p]
        result = self.patterns['four_k'].sub('[2160p]', result)

        # Step 4: Remove unwanted tags (before dot replacement)
        for pattern_name in ['release_groups', 'video_quality', 'audio_format',
                           'codec', 'enhancement', 'streaming', 'technical']:
            result = self.patterns[pattern_name].sub('', result)

        # Step 5: Replace dots with spaces
        result = self.patterns['dots'].sub(' ', result)

        # Step 6: Remove duplicate resolution tags
        result = self.patterns['duplicate_resolution'].sub('[2160p]', result)

        # Step 7: Remove remaining unwanted terms after resolution/year
        # Split on resolution or year markers and clean suffix
        match = re.search(r'(.*(?:\(\d{4}\)|\[\d{3,4}p\]))(.*)', result, re.DOTALL)
        if match:
            prefix, suffix = match.groups()
            # Remove remaining unwanted terms from suffix
            suffix = re.sub(
                r'(AMZN|NFLX|HULU|DSNP|ATVP|HMAX|PCOK|PMTP|STAN|10bit|8bit|HDR|'
                r'WEB|INTERNAL|PROPER|REPACK|READ\.NFO|RERiP)', '', suffix, flags=re.IGNORECASE
            )
            suffix = re.sub(r'^[\s\.\-_]+|[\s\.\-_]+$', '', suffix)
            result = prefix + suffix

        # Step 8: Remove empty brackets
        result = self.patterns['empty_brackets'].sub('', result)

        # Step 9: Final cleanup
        result = self.patterns['multiple_spaces'].sub(' ', result)
        result = self.patterns['trim'].sub('', result)

        return result

    def process_entry(self, entry_path: Path) -> Tuple[bool, str]:
        """Process a single file or directory entry."""
        if self.processed_count >= self.max_items:
            return False, "Dry-run limit reached"

        original_path = entry_path

        # If it's a file, create directory and move file into it
        if entry_path.is_file():
            base_name = entry_path.stem  # filename without extension
            new_dir = entry_path.parent / base_name

            if self.dry_run:
                print(f"Would create directory '{new_dir}' and move file '{entry_path}' into it.")
            else:
                new_dir.mkdir(exist_ok=True)
                shutil.move(str(entry_path), str(new_dir / entry_path.name))
                print(f"Created directory '{new_dir}' and moved file '{entry_path}' into it.")

            entry_path = new_dir  # Update to process the new directory

        # Process directory renaming
        if entry_path.is_dir():
            base_name = entry_path.name
            sanitized_name = self.sanitize_name(base_name)
            sanitized_path = entry_path.parent / sanitized_name

            if base_name == sanitized_name:
                print(f"No renaming needed for '{entry_path}'.")
            elif sanitized_path.exists():
                print(f"Error: A directory with the sanitized name '{sanitized_name}' already exists. Skipping '{entry_path}'.")
            else:
                if self.dry_run:
                    print(f"Would rename directory '{entry_path}' to '{sanitized_name}'")
                else:
                    entry_path.rename(sanitized_path)
                    print(f"Renamed directory '{entry_path}' to '{sanitized_name}'")

        self.processed_count += 1
        return True, "Success"

    def process_directory(self, input_dir: Path) -> bool:
        """Process all entries in the specified directory."""
        if not input_dir.exists():
            print(f"Error: Directory '{input_dir}' does not exist.")
            return False

        if not input_dir.is_dir():
            print(f"Error: '{input_dir}' is not a directory.")
            return False

        print(f"Processing directory: {input_dir}")
        if self.dry_run:
            print(f"DRY-RUN MODE - Limited to {self.max_items} items")
        print()

        # System trash cleanup (if enabled)
        if self.enable_cleanup:
            if self.verbose:
                print("Cleaning system trash files...")

            cleaner = SystemTrashCleaner(verbose=self.verbose, dry_run=self.dry_run)
            cleanup_count = cleaner.clean_directory(input_dir, recursive=True)

            if self.verbose:
                if self.dry_run:
                    print(f"Would remove {cleanup_count} trash files\n")
                else:
                    print(f"Removed {cleanup_count} trash files\n")

        # Get immediate child entries (files and directories)
        entries = list(input_dir.iterdir())

        # Filter out trash files if cleanup is enabled
        if self.enable_cleanup:
            cleaner = SystemTrashCleaner(verbose=False, dry_run=self.dry_run)
            entries = [e for e in entries if not cleaner.is_trash_file(e)]

        for entry in entries:
            success, message = self.process_entry(entry)
            if not success and "limit reached" in message:
                print(f"Dry-run limit of {self.max_items} items reached. Exiting.")
                break

        print(f"\nProcessed {self.processed_count} items.")
        return True


def main():
    """Main function with argument parsing and execution."""
    parser = argparse.ArgumentParser(
        description="Plex Directory Name Corrector - Sanitize and organize Plex media directory names",
        epilog="""
Examples:
  %(prog)s                                   # Process current directory (interactive)
  %(prog)s /path/to/media                    # Process specific directory (interactive)
  %(prog)s --dry-run                         # Preview changes in current directory
  %(prog)s /path/to/media --dry-run          # Preview changes in specific directory
  %(prog)s -y                                # Process current directory without confirmation
  %(prog)s /path/to/media -y                 # Process specific directory without confirmation
  %(prog)s --cleanup --execute               # Clean trash files and execute
  %(prog)s --verbose --cleanup --execute     # Show verbose output with cleanup
  %(prog)s --force                           # Force run in current directory (bypass lock)
  %(prog)s --debug                           # Show detailed debug output

Global Configuration:
  Set AUTO_CONFIRM=true to skip confirmation prompts automatically
  Set AUTO_CLEANUP=true to enable cleanup by default
  Set QUIET_MODE=true to suppress banner display

Cron Usage:
  # Run daily at 2 AM with cleanup (non-interactive)
  0 2 * * * /usr/local/bin/plex_correct_dirs /path/to/media --cleanup -y
        """,
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument(
        'directory',
        nargs='?',
        default='.',
        help='Directory to process (default: current directory)'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        default=True,
        help='Show what would be done without making changes (limited to 5 items)'
    )
    parser.add_argument(
        '--execute',
        action='store_true',
        help='Actually perform the directory corrections (overrides --dry-run)'
    )
    parser.add_argument(
        '-y', '--yes',
        action='store_true',
        help='Skip confirmation prompt (for non-interactive use)'
    )
    parser.add_argument(
        '--force',
        action='store_true',
        help='Force execution even if another instance is running'
    )
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='Show verbose output'
    )
    parser.add_argument(
        '--debug',
        action='store_true',
        help='Show detailed debug output'
    )
    parser.add_argument(
        '--cleanup',
        action='store_true',
        help='Clean system trash files (.DS_Store, Thumbs.db, etc.) before processing'
    )
    parser.add_argument(
        '--no-banner',
        action='store_true',
        help='Suppress banner display'
    )
    parser.add_argument(
        '--max-items',
        type=int,
        default=5,
        help='Maximum items to process in dry-run mode (default: 5)'
    )
    parser.add_argument(
        '--version',
        action='version',
        version=f'%(prog)s v{VERSION}'
    )

    args = parser.parse_args()

    # Handle execute flag (overrides dry-run default)
    if args.execute:
        args.dry_run = False

    # Handle debug mode
    if args.debug:
        args.verbose = True

    # Read configuration with CLI > ENV > Local .env > Global .env priority
    auto_execute = read_config_bool('AUTO_EXECUTE', cli_args=args, default=False)
    auto_confirm = read_config_bool('AUTO_CONFIRM', cli_args=args, default=False)
    auto_cleanup = read_config_bool('AUTO_CLEANUP', cli_args=args, default=False)
    quiet_mode = read_config_bool('QUIET_MODE', cli_args=args, default=False)

    # Apply configuration (CLI arguments already have highest priority via read_config_bool)
    if auto_confirm and not args.yes:
        args.yes = True  # Set yes flag if AUTO_CONFIRM is set
    if auto_cleanup and not args.cleanup:
        args.cleanup = True  # Enable cleanup if AUTO_CLEANUP is set

    # Display banner (respecting suppression flags)
    display_banner(
        "Plex Directory Name Corrector",
        VERSION,
        "Sanitize and organize Plex media directory names",
        args.no_banner,
        quiet_mode
    )

    # Validate arguments
    if args.yes and args.dry_run:
        print("Warning: -y/--yes flag has no effect in dry-run mode", file=sys.stderr)

    # Create corrector instance
    corrector = PlexDirectoryCorrector(
        dry_run=args.dry_run,
        force=args.force,
        max_items=args.max_items,
        verbose=args.verbose,
        debug=args.debug,
        enable_cleanup=args.cleanup
    )

    try:
        # Acquire lock
        if not corrector.acquire_lock():
            sys.exit(1)

        # Get confirmation for non-dry-run operations
        if not args.dry_run and not args.yes and not is_non_interactive():
            print("\nThis will modify directory names and file locations.")
            print("Consider running with --dry-run first to preview changes.")
            try:
                response = input("\nDo you want to proceed? (yes/no): ").strip().lower()
            except (EOFError, KeyboardInterrupt):
                print("\nOperation cancelled.")
                sys.exit(0)

            if response not in ['yes', 'y']:
                print("Operation cancelled.")
                sys.exit(0)
        elif not args.dry_run and (args.yes or is_non_interactive()):
            if args.yes:
                print("Proceeding with directory processing (--yes flag)...")
            else:
                print("Proceeding with directory processing (non-interactive environment)...")

        # Process directory
        input_dir = Path(args.directory).resolve()
        success = corrector.process_directory(input_dir)

        sys.exit(0 if success else 1)

    except KeyboardInterrupt:
        print("\nOperation cancelled by user.")
        sys.exit(1)
    except Exception as e:
        print(f"Error: {e}")
        sys.exit(1)
    finally:
        corrector.release_lock()


if __name__ == '__main__':
    main()